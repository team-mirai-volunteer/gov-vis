#!/usr/bin/env python3
"""
åŸºæœ¬å½¢AI/ï¼¡ï¼©ãŒä½¿ã‚ã‚ŒãŸäº‹æ¥­ã®ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆä½œæˆ
ã™ã¹ã¦ã®å¤‰æ•°ã‚’å«ã‚€å®Œå…¨ãªãƒ‡ãƒ¼ã‚¿ã‚’å‡ºåŠ›
"""
import pandas as pd
import json
import re
from pathlib import Path
from typing import Dict, List, Set, Any
from collections import defaultdict
import time


class AIBasicFormSpreadsheetGenerator:
    """åŸºæœ¬å½¢AIäº‹æ¥­ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆç”Ÿæˆã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, feather_dir: str = "data/normalized_feather"):
        self.feather_dir = Path(feather_dir)
        self.output_dir = Path("data/ai_basic_form_spreadsheet")
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # åŸºæœ¬å½¢AIãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆçµ±è¨ˆçµæœã‹ã‚‰ï¼‰
        self.basic_ai_patterns = [
            r'\bAI\b',     # åŠè§’AIï¼ˆå˜èªå¢ƒç•Œã‚ã‚Šï¼‰
            r'\bï¼¡ï¼©\b',    # å…¨è§’AIï¼ˆå˜èªå¢ƒç•Œã‚ã‚Šï¼‰
            r'(?<![a-zA-Z])AI(?![a-zA-Z])',  # ã‚ˆã‚Šç²¾å¯†ãªåŠè§’AI
            r'(?<![ï½-ï½šï¼¡-ï¼º])ï¼¡ï¼©(?![ï½-ï½šï¼¡-ï¼º])'  # ã‚ˆã‚Šç²¾å¯†ãªå…¨è§’AI
        ]
        
        self.tables_data = {}
        self.search_config = {}
        self.load_metadata()
    
    def load_metadata(self):
        """ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿"""
        metadata_path = self.feather_dir / 'ai_search_metadata.json'
        if metadata_path.exists():
            with open(metadata_path, 'r', encoding='utf-8') as f:
                metadata = json.load(f)
            self.search_config = metadata.get('ai_search_fields', {})
        else:
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š
            self.search_config = {
                'projects': ['äº‹æ¥­å', 'äº‹æ¥­ã®ç›®çš„', 'äº‹æ¥­ã®æ¦‚è¦', 'ç¾çŠ¶ãƒ»èª²é¡Œ'],
                'expenditure_info': ['æ”¯å‡ºå…ˆå', 'å¥‘ç´„æ¦‚è¦', 'è²»ç›®', 'ä½¿é€”'],
                'goals_performance': ['ã‚¢ã‚¯ãƒ†ã‚£ãƒ“ãƒ†ã‚£ï¼æ´»å‹•ç›®æ¨™ï¼æˆæœç›®æ¨™', 'æ´»å‹•æŒ‡æ¨™ï¼æˆæœæŒ‡æ¨™'],
                'expenditure_connections': ['æ”¯å‡ºå…ˆã®æ”¯å‡ºå…ˆãƒ–ãƒ­ãƒƒã‚¯å', 'è³‡é‡‘ã®æµã‚Œã®è£œè¶³æƒ…å ±'],
                'contracts': ['å¥‘ç´„å…ˆåï¼ˆå›½åº«å‚µå‹™è² æ‹…è¡Œç‚ºç­‰ã«ã‚ˆã‚‹å¥‘ç´„ï¼‰', 'å¥‘ç´„æ¦‚è¦ï¼ˆå¥‘ç´„åï¼‰ï¼ˆå›½åº«å‚µå‹™è² æ‹…è¡Œç‚ºç­‰ã«ã‚ˆã‚‹å¥‘ç´„ï¼‰']
            }
    
    def load_feather_tables(self):
        """Featherãƒ†ãƒ¼ãƒ–ãƒ«èª­ã¿è¾¼ã¿"""
        print("Loading Feather tables...")
        
        for table_name in ['projects', 'expenditure_info', 'goals_performance', 'expenditure_connections', 'contracts']:
            feather_path = self.feather_dir / f"{table_name}.feather"
            if feather_path.exists():
                print(f"  Loading: {table_name}")
                try:
                    df = pd.read_feather(feather_path)
                    self.tables_data[table_name] = df
                    print(f"    Records: {len(df):,}, Columns: {len(df.columns)}")
                    print(f"    Columns: {list(df.columns)}")
                except Exception as e:
                    print(f"    Error loading {table_name}: {e}")
            else:
                print(f"  Warning: {feather_path} not found")
        
        print(f"Loaded {len(self.tables_data)} tables")
    
    def is_basic_ai_match(self, text: str) -> List[Dict]:
        """åŸºæœ¬å½¢AIãƒãƒƒãƒã‚’ãƒã‚§ãƒƒã‚¯"""
        if not text or pd.isna(text):
            return []
        
        text_str = str(text)
        matches = []
        
        for pattern in self.basic_ai_patterns:
            try:
                found = re.finditer(pattern, text_str, re.IGNORECASE)
                for match in found:
                    matched_text = match.group()
                    # åŸºæœ¬å½¢ã®ã¿ã‚’ãƒ•ã‚£ãƒ«ã‚¿ï¼ˆAIã¾ãŸã¯ï¼¡ï¼©ã®ã¿ï¼‰
                    if matched_text.upper() in ['AI', 'ï¼¡ï¼©']:
                        matches.append({
                            'pattern': pattern,
                            'matched_text': matched_text,
                            'position': f"{match.start()}-{match.end()}"
                        })
            except re.error:
                continue
        
        return matches
    
    def find_basic_ai_projects(self) -> Set[int]:
        """åŸºæœ¬å½¢AIã‚’å«ã‚€äº‹æ¥­IDã‚’ç‰¹å®š"""
        print("Finding projects with basic AI forms...")
        
        basic_ai_projects = set()
        search_summary = defaultdict(int)
        
        for table_name, df in self.tables_data.items():
            print(f"  Searching in {table_name}...")
            
            search_fields = self.search_config.get(table_name, [])
            available_fields = [f for f in search_fields if f in df.columns]
            
            if not available_fields:
                print(f"    No searchable fields in {table_name}")
                continue
            
            table_matches = 0
            
            for idx, record in df.iterrows():
                project_id = record.get('äºˆç®—äº‹æ¥­ID')
                if pd.isna(project_id):
                    continue
                
                project_id = int(project_id)
                
                for field in available_fields:
                    text = record.get(field, '')
                    matches = self.is_basic_ai_match(text)
                    
                    if matches:
                        basic_ai_projects.add(project_id)
                        table_matches += 1
                        search_summary[table_name] += 1
                        break  # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã”ã¨ã«ä¸€åº¦ã‚«ã‚¦ãƒ³ãƒˆ
            
            print(f"    Found {table_matches} records with basic AI")
        
        print(f"\\nBasic AI Search Summary:")
        for table, count in search_summary.items():
            print(f"  {table}: {count} records")
        print(f"  Total unique projects: {len(basic_ai_projects)}")
        
        return basic_ai_projects
    
    def collect_complete_project_data(self, project_ids: Set[int]) -> pd.DataFrame:
        """åŸºæœ¬å½¢AIäº‹æ¥­ã®å®Œå…¨ãªãƒ‡ãƒ¼ã‚¿ã‚’åé›†"""
        print(f"Collecting complete data for {len(project_ids)} projects...")
        
        all_project_data = []
        
        for project_id in sorted(project_ids):
            project_record = {
                'äºˆç®—äº‹æ¥­ID': project_id,
                'AI_æ¤œå‡º_è©³ç´°': '',
                'AI_ãƒãƒƒãƒ_æ•°': 0
            }
            
            ai_matches_detail = []
            total_ai_matches = 0
            
            # å„ãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰ãƒ‡ãƒ¼ã‚¿ã‚’åé›†
            for table_name, df in self.tables_data.items():
                # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆIDã§ãƒ•ã‚£ãƒ«ã‚¿
                project_df = df[df['äºˆç®—äº‹æ¥­ID'] == project_id]
                
                if project_df.empty:
                    continue
                
                # ãƒ†ãƒ¼ãƒ–ãƒ«ã®å…¨ã‚«ãƒ©ãƒ ã‚’è¿½åŠ 
                for col in df.columns:
                    if col == 'äºˆç®—äº‹æ¥­ID':
                        continue
                    
                    # ã‚«ãƒ©ãƒ åã«ãƒ†ãƒ¼ãƒ–ãƒ«åã‚’ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹
                    prefixed_col = f"{table_name}_{col}"
                    
                    # è¤‡æ•°ãƒ¬ã‚³ãƒ¼ãƒ‰ãŒã‚ã‚‹å ´åˆã¯çµåˆ
                    values = project_df[col].dropna().astype(str).unique()
                    if len(values) > 0:
                        # ç©ºæ–‡å­—åˆ—ã‚„'nan'ã‚’é™¤å¤–
                        clean_values = [v for v in values if v and v != 'nan']
                        if clean_values:
                            project_record[prefixed_col] = ' | '.join(clean_values)
                        else:
                            project_record[prefixed_col] = ''
                    else:
                        project_record[prefixed_col] = ''
                
                # AIãƒãƒƒãƒãƒ³ã‚°è©³ç´°ã®åé›†
                search_fields = self.search_config.get(table_name, [])
                available_fields = [f for f in search_fields if f in df.columns]
                
                for idx, record in project_df.iterrows():
                    for field in available_fields:
                        text = record.get(field, '')
                        matches = self.is_basic_ai_match(text)
                        
                        if matches:
                            for match in matches:
                                ai_matches_detail.append(f"{table_name}.{field}: {match['matched_text']}")
                                total_ai_matches += 1
            
            # AIæ¤œå‡ºè©³ç´°ã‚’è¿½åŠ 
            project_record['AI_æ¤œå‡º_è©³ç´°'] = ' | '.join(ai_matches_detail)
            project_record['AI_ãƒãƒƒãƒ_æ•°'] = total_ai_matches
            
            all_project_data.append(project_record)
        
        # DataFrameã«å¤‰æ›
        df_complete = pd.DataFrame(all_project_data)
        
        # ã‚«ãƒ©ãƒ ã‚’æ•´ç†ï¼ˆäºˆç®—äº‹æ¥­IDã€AIé–¢é€£ã€ãã®ä»–ã®é †ï¼‰
        ai_cols = ['äºˆç®—äº‹æ¥­ID', 'AI_æ¤œå‡º_è©³ç´°', 'AI_ãƒãƒƒãƒ_æ•°']
        other_cols = [col for col in df_complete.columns if col not in ai_cols]
        ordered_cols = ai_cols + sorted(other_cols)
        
        df_complete = df_complete[ordered_cols]
        
        print(f"Collected complete data: {len(df_complete)} projects, {len(df_complete.columns)} columns")
        
        return df_complete
    
    def generate_data_summary(self, df: pd.DataFrame) -> Dict:
        """ãƒ‡ãƒ¼ã‚¿ã‚µãƒãƒªãƒ¼ã‚’ç”Ÿæˆ"""
        print("Generating data summary...")
        
        # åŸºæœ¬çµ±è¨ˆ
        total_projects = len(df)
        total_columns = len(df.columns)
        
        # AIé–¢é€£çµ±è¨ˆ
        total_ai_matches = df['AI_ãƒãƒƒãƒ_æ•°'].sum()
        avg_ai_matches = df['AI_ãƒãƒƒãƒ_æ•°'].mean()
        max_ai_matches = df['AI_ãƒãƒƒãƒ_æ•°'].max()
        
        # åºœçœåºåˆ¥çµ±è¨ˆï¼ˆprojectsãƒ†ãƒ¼ãƒ–ãƒ«ã‹ã‚‰ï¼‰
        ministry_col = 'projects_åºœçœåº'
        if ministry_col in df.columns:
            ministry_stats = df[ministry_col].value_counts().head(20).to_dict()
        else:
            ministry_stats = {}
        
        # æ¤œå‡ºãƒ†ãƒ¼ãƒ–ãƒ«åˆ¥çµ±è¨ˆ
        table_detection_stats = {}
        for table_name in self.tables_data.keys():
            count = df['AI_æ¤œå‡º_è©³ç´°'].str.contains(f'{table_name}\\.', na=False).sum()
            table_detection_stats[table_name] = count
        
        # ãƒ‡ãƒ¼ã‚¿å“è³ªçµ±è¨ˆ
        non_empty_cols = {}
        for col in df.columns:
            if col.startswith(('projects_', 'expenditure_', 'goals_', 'contracts_')):
                non_empty_count = df[col].notna().sum()
                non_empty_cols[col] = non_empty_count
        
        summary = {
            'basic_statistics': {
                'total_projects': total_projects,
                'total_columns': total_columns,
                'total_ai_matches': total_ai_matches,
                'average_ai_matches_per_project': round(avg_ai_matches, 2),
                'max_ai_matches_per_project': max_ai_matches
            },
            'ministry_distribution': ministry_stats,
            'table_detection_stats': table_detection_stats,
            'data_coverage': {
                'columns_with_data': len([col for col, count in non_empty_cols.items() if count > 0]),
                'top_populated_columns': dict(sorted(non_empty_cols.items(), key=lambda x: x[1], reverse=True)[:20])
            }
        }
        
        return summary
    
    def save_spreadsheet_and_summary(self, df: pd.DataFrame, summary: Dict):
        """ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã¨ã‚µãƒãƒªãƒ¼ã‚’ä¿å­˜"""
        print("Saving spreadsheet and summary...")
        
        # Excelå½¢å¼ã§ä¿å­˜
        excel_path = self.output_dir / 'ai_basic_form_complete_data.xlsx'
        with pd.ExcelWriter(excel_path, engine='openpyxl') as writer:
            # ãƒ¡ã‚¤ãƒ³ãƒ‡ãƒ¼ã‚¿
            df.to_excel(writer, sheet_name='AIåŸºæœ¬å½¢äº‹æ¥­ãƒ‡ãƒ¼ã‚¿', index=False)
            
            # ã‚µãƒãƒªãƒ¼ã‚·ãƒ¼ãƒˆ
            summary_df = pd.DataFrame([
                ['ç·äº‹æ¥­æ•°', summary['basic_statistics']['total_projects']],
                ['ç·ã‚«ãƒ©ãƒ æ•°', summary['basic_statistics']['total_columns']],
                ['ç·AIãƒãƒƒãƒæ•°', summary['basic_statistics']['total_ai_matches']],
                ['1äº‹æ¥­ã‚ãŸã‚Šå¹³å‡ãƒãƒƒãƒæ•°', summary['basic_statistics']['average_ai_matches_per_project']],
                ['æœ€å¤§ãƒãƒƒãƒæ•°', summary['basic_statistics']['max_ai_matches_per_project']]
            ], columns=['é …ç›®', 'å€¤'])
            summary_df.to_excel(writer, sheet_name='ãƒ‡ãƒ¼ã‚¿ã‚µãƒãƒªãƒ¼', index=False)
            
            # åºœçœåºåˆ¥çµ±è¨ˆ
            if summary['ministry_distribution']:
                ministry_df = pd.DataFrame(list(summary['ministry_distribution'].items()), columns=['åºœçœåº', 'äº‹æ¥­æ•°'])
                ministry_df.to_excel(writer, sheet_name='åºœçœåºåˆ¥çµ±è¨ˆ', index=False)
        
        print(f"  Excel saved: {excel_path}")
        
        # CSVå½¢å¼ã§ã‚‚ä¿å­˜
        csv_path = self.output_dir / 'ai_basic_form_complete_data.csv'
        df.to_csv(csv_path, index=False, encoding='utf-8-sig')
        print(f"  CSV saved: {csv_path}")
        
        # JSONå½¢å¼ã®ã‚µãƒãƒªãƒ¼
        summary_path = self.output_dir / 'ai_basic_form_summary.json'
        with open(summary_path, 'w', encoding='utf-8') as f:
            json.dump(summary, f, ensure_ascii=False, indent=2, default=str)
        print(f"  Summary saved: {summary_path}")
        
        # HTMLãƒ¬ãƒãƒ¼ãƒˆ
        self.generate_html_report(summary, len(df), len(df.columns))
    
    def generate_html_report(self, summary: Dict, total_rows: int, total_cols: int):
        """HTMLãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        
        html_content = f"""<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <title>åŸºæœ¬å½¢AIäº‹æ¥­ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆ ãƒ¬ãƒãƒ¼ãƒˆ</title>
    <style>
        body {{ font-family: 'Segoe UI', Arial, sans-serif; margin: 20px; line-height: 1.6; }}
        h1 {{ color: #28a745; text-align: center; border-bottom: 3px solid #28a745; padding-bottom: 10px; }}
        .summary {{ background-color: #e8f5e9; padding: 20px; border-radius: 8px; margin: 20px 0; }}
        .metric {{ font-size: 1.5em; font-weight: bold; text-align: center; margin: 10px 0; color: #2e7d32; }}
        table {{ border-collapse: collapse; width: 100%; margin: 20px 0; }}
        th, td {{ border: 1px solid #ddd; padding: 8px; text-align: left; }}
        th {{ background-color: #f2f2f2; }}
        .highlight {{ background-color: #fff3cd; }}
        ul {{ padding-left: 20px; }}
        li {{ margin: 5px 0; }}
    </style>
</head>
<body>
    <h1>ğŸ“Š åŸºæœ¬å½¢AIäº‹æ¥­ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆ ãƒ¬ãƒãƒ¼ãƒˆ</h1>
    
    <div class="summary">
        <h2>ğŸ“‹ ãƒ‡ãƒ¼ã‚¿æ¦‚è¦</h2>
        <div class="metric">äº‹æ¥­æ•°: {total_rows:,}è¡Œ</div>
        <div class="metric">å¤‰æ•°æ•°: {total_cols:,}åˆ—</div>
        <div class="metric">ç·AIãƒãƒƒãƒ: {summary['basic_statistics']['total_ai_matches']:,}ä»¶</div>
    </div>
    
    <h2>ğŸ“ˆ åŸºæœ¬çµ±è¨ˆ</h2>
    <table>
        <tr>
            <th>é …ç›®</th>
            <th>å€¤</th>
        </tr>
        <tr class="highlight">
            <td><strong>ç·äº‹æ¥­æ•°</strong></td>
            <td>{summary['basic_statistics']['total_projects']:,}äº‹æ¥­</td>
        </tr>
        <tr class="highlight">
            <td><strong>ç·å¤‰æ•°æ•°</strong></td>
            <td>{summary['basic_statistics']['total_columns']:,}åˆ—</td>
        </tr>
        <tr>
            <td>ç·AIãƒãƒƒãƒæ•°</td>
            <td>{summary['basic_statistics']['total_ai_matches']:,}ä»¶</td>
        </tr>
        <tr>
            <td>1äº‹æ¥­ã‚ãŸã‚Šå¹³å‡ãƒãƒƒãƒæ•°</td>
            <td>{summary['basic_statistics']['average_ai_matches_per_project']}</td>
        </tr>
        <tr>
            <td>æœ€å¤§ãƒãƒƒãƒæ•°</td>
            <td>{summary['basic_statistics']['max_ai_matches_per_project']}</td>
        </tr>
    </table>
    
    <h2>ğŸ¢ åºœçœåºåˆ¥åˆ†å¸ƒ</h2>
    <table>
        <tr><th>åºœçœåº</th><th>äº‹æ¥­æ•°</th></tr>"""
        
        for ministry, count in list(summary['ministry_distribution'].items())[:15]:
            html_content += f"        <tr><td>{ministry}</td><td>{count}</td></tr>\\n"
        
        html_content += f"""
    </table>
    
    <h2>ğŸ“ ãƒ‡ãƒ¼ã‚¿æ¤œå‡ºãƒ†ãƒ¼ãƒ–ãƒ«åˆ¥çµ±è¨ˆ</h2>
    <table>
        <tr><th>ãƒ†ãƒ¼ãƒ–ãƒ«</th><th>AIæ¤œå‡ºäº‹æ¥­æ•°</th></tr>"""
        
        for table, count in summary['table_detection_stats'].items():
            html_content += f"        <tr><td>{table}</td><td>{count}</td></tr>\\n"
        
        html_content += f"""
    </table>
    
    <h2>ğŸ“‹ å‡ºåŠ›ãƒ•ã‚¡ã‚¤ãƒ«</h2>
    <ul>
        <li><strong>ai_basic_form_complete_data.xlsx</strong> - Excelå½¢å¼ã®å®Œå…¨ãªã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆ</li>
        <li><strong>ai_basic_form_complete_data.csv</strong> - CSVå½¢å¼ã®å®Œå…¨ãªã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆ</li>
        <li><strong>ai_basic_form_summary.json</strong> - JSONå½¢å¼ã®ã‚µãƒãƒªãƒ¼çµ±è¨ˆ</li>
    </ul>
    
    <h2>ğŸ’¡ ãƒ‡ãƒ¼ã‚¿ã®ç‰¹å¾´</h2>
    <ul>
        <li>åŸºæœ¬å½¢ã€ŒAIã€ã€Œï¼¡ï¼©ã€ã®ã¿ã‚’å¯¾è±¡ï¼ˆè¤‡åˆèªã¯é™¤å¤–ï¼‰</li>
        <li>å…¨5ãƒ†ãƒ¼ãƒ–ãƒ«ã®å®Œå…¨ãªãƒ‡ãƒ¼ã‚¿ã‚’çµ±åˆ</li>
        <li>ãƒ†ãƒ¼ãƒ–ãƒ«åã‚’ãƒ—ãƒ¬ãƒ•ã‚£ãƒƒã‚¯ã‚¹ã¨ã—ãŸå¤‰æ•°å</li>
        <li>AIæ¤œå‡ºè©³ç´°ã¨ãƒãƒƒãƒæ•°ã‚’è¿½åŠ </li>
        <li>è¤‡æ•°ãƒ¬ã‚³ãƒ¼ãƒ‰ã¯ã€Œ|ã€ã§çµåˆ</li>
    </ul>
    
    <div style="margin-top: 40px; text-align: center; color: #666;">
        Generated by AI Basic Form Spreadsheet Generator
    </div>
</body>
</html>"""
        
        html_path = self.output_dir / 'ai_basic_form_report.html'
        with open(html_path, 'w', encoding='utf-8') as f:
            f.write(html_content)
        print(f"  HTML report saved: {html_path}")
    
    def run(self):
        """åŸºæœ¬å½¢AIã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆç”Ÿæˆãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ"""
        print("=" * 60)
        print("ğŸ“Š åŸºæœ¬å½¢AIäº‹æ¥­ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆç”Ÿæˆ")
        print("=" * 60)
        
        start_time = time.time()
        
        # 1. ãƒ†ãƒ¼ãƒ–ãƒ«èª­ã¿è¾¼ã¿
        self.load_feather_tables()
        
        if not self.tables_data:
            print("No tables loaded. Exiting.")
            return None
        
        # 2. åŸºæœ¬å½¢AIäº‹æ¥­IDç‰¹å®š
        basic_ai_projects = self.find_basic_ai_projects()
        
        if not basic_ai_projects:
            print("No basic AI projects found. Exiting.")
            return None
        
        # 3. å®Œå…¨ãªãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒ‡ãƒ¼ã‚¿åé›†
        complete_data = self.collect_complete_project_data(basic_ai_projects)
        
        # 4. ãƒ‡ãƒ¼ã‚¿ã‚µãƒãƒªãƒ¼ç”Ÿæˆ
        summary = self.generate_data_summary(complete_data)
        
        # 5. ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆä¿å­˜
        self.save_spreadsheet_and_summary(complete_data, summary)
        
        elapsed = time.time() - start_time
        
        # æœ€çµ‚çµæœè¡¨ç¤º
        print(f"\\n{'='*60}")
        print("ğŸ‰ ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆç”Ÿæˆå®Œäº†!")
        print(f"{'='*60}")
        print(f"ğŸ“Š äº‹æ¥­æ•°: {len(complete_data):,}è¡Œ")
        print(f"ğŸ“‹ å¤‰æ•°æ•°: {len(complete_data.columns):,}åˆ—")
        print(f"ğŸ¯ AIãƒãƒƒãƒ: {summary['basic_statistics']['total_ai_matches']:,}ä»¶")
        print(f"â±ï¸  å®Ÿè¡Œæ™‚é–“: {elapsed:.1f}ç§’")
        print(f"ğŸ“ å‡ºåŠ›å…ˆ: {self.output_dir}")
        print(f"{'='*60}")
        
        return complete_data, summary


if __name__ == "__main__":
    generator = AIBasicFormSpreadsheetGenerator()
    generator.run()