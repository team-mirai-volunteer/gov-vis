#!/usr/bin/env python3
"""
RSã‚·ã‚¹ãƒ†ãƒ å…¬å¼AIæ¤œç´¢çµæœã¨ã®ç…§åˆæ¤œè¨¼ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
152äº‹æ¥­ãŒä»Šå›ä½œæˆã—ãŸãƒ‡ãƒ¼ã‚¿ã«å«ã¾ã‚Œã¦ã„ã‚‹ã‹ã‚’æ¤œè¨¼
"""
import pandas as pd
import json
import re
from pathlib import Path
from typing import Dict, List, Set, Any, Tuple
from collections import defaultdict, Counter
import time
from difflib import SequenceMatcher


class RSOfficalVerificationEngine:
    """RSã‚·ã‚¹ãƒ†ãƒ å…¬å¼çµæœã¨ã®ç…§åˆæ¤œè¨¼ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.official_list_path = Path("data/ai_investigation/AI_record_list.txt")
        self.improved_search_path = Path("data/improved_ai_search/ai_exact_improved.json")
        self.basic_form_path = Path("data/ai_basic_form_spreadsheet/ai_basic_form_complete_data.csv")
        self.feather_dir = Path("data/normalized_feather")
        self.output_dir = Path("data/rs_official_verification")
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # ãƒ‡ãƒ¼ã‚¿æ ¼ç´
        self.official_projects = []
        self.improved_search_data = {}
        self.basic_form_data = None
        self.feather_tables = {}
    
    def load_official_ai_list(self) -> List[str]:
        """RSã‚·ã‚¹ãƒ†ãƒ å…¬å¼AIæ¤œç´¢çµæœ152äº‹æ¥­ã‚’èª­ã¿è¾¼ã¿"""
        print("Loading RS System official AI search results...")
        
        if not self.official_list_path.exists():
            print(f"Error: Official list not found at {self.official_list_path}")
            return []
        
        with open(self.official_list_path, 'r', encoding='utf-8') as f:
            lines = f.readlines()
        
        # äº‹æ¥­åã‚’ã‚¯ãƒªãƒ¼ãƒ³ã‚¢ãƒƒãƒ—
        projects = []
        for line in lines:
            project_name = line.strip()
            if project_name:  # ç©ºè¡Œã‚’é™¤å¤–
                projects.append(project_name)
        
        print(f"  Loaded {len(projects)} official AI projects")
        self.official_projects = projects
        return projects
    
    def load_improved_search_data(self) -> Dict:
        """æ”¹å–„ã•ã‚ŒãŸAIæ¤œç´¢çµæœã‚’èª­ã¿è¾¼ã¿"""
        print("Loading improved AI search results...")
        
        if not self.improved_search_path.exists():
            print(f"Error: Improved search data not found at {self.improved_search_path}")
            return {}
        
        with open(self.improved_search_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        
        print(f"  Loaded {len(data)} improved AI search projects")
        self.improved_search_data = data
        return data
    
    def load_basic_form_data(self) -> pd.DataFrame:
        """åŸºæœ¬å½¢AIã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã‚’èª­ã¿è¾¼ã¿"""
        print("Loading basic form AI spreadsheet...")
        
        if not self.basic_form_path.exists():
            print(f"Error: Basic form data not found at {self.basic_form_path}")
            return pd.DataFrame()
        
        df = pd.read_csv(self.basic_form_path, encoding='utf-8')
        print(f"  Loaded {len(df)} basic form AI projects")
        self.basic_form_data = df
        return df
    
    def load_feather_tables(self):
        """å¿…è¦ã«å¿œã˜ã¦Featherãƒ†ãƒ¼ãƒ–ãƒ«ã‚’èª­ã¿è¾¼ã¿"""
        print("Loading Feather tables for detailed verification...")
        
        projects_path = self.feather_dir / "projects.feather"
        if projects_path.exists():
            self.feather_tables['projects'] = pd.read_feather(projects_path)
            print(f"  Loaded projects table: {len(self.feather_tables['projects'])} records")
    
    def fuzzy_match_project_name(self, official_name: str, candidate_name: str, threshold: float = 0.8) -> float:
        """äº‹æ¥­åã®ãƒ•ã‚¡ã‚¸ãƒ¼ãƒãƒƒãƒãƒ³ã‚°"""
        if not official_name or not candidate_name:
            return 0.0
        
        # åŸºæœ¬çš„ãªé¡ä¼¼åº¦
        similarity = SequenceMatcher(None, official_name, candidate_name).ratio()
        
        # éƒ¨åˆ†ä¸€è‡´ã®ç¢ºèª
        if official_name in candidate_name or candidate_name in official_name:
            similarity = max(similarity, 0.9)
        
        return similarity
    
    def extract_project_names_from_improved_search(self) -> Dict[int, str]:
        """æ”¹å–„ã•ã‚ŒãŸAIæ¤œç´¢çµæœã‹ã‚‰äº‹æ¥­åã‚’æŠ½å‡º"""
        project_names = {}
        
        for project_id, data in self.improved_search_data.items():
            master_info = data.get('master_info', {})
            project_name = master_info.get('äº‹æ¥­å', '')
            if project_name:
                project_names[int(project_id)] = project_name
        
        return project_names
    
    def extract_project_names_from_basic_form(self) -> Dict[int, str]:
        """åŸºæœ¬å½¢ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã‹ã‚‰äº‹æ¥­åã‚’æŠ½å‡º"""
        project_names = {}
        
        if self.basic_form_data is not None and 'projects_äº‹æ¥­å' in self.basic_form_data.columns:
            for idx, row in self.basic_form_data.iterrows():
                project_id = row.get('äºˆç®—äº‹æ¥­ID')
                project_name = row.get('projects_äº‹æ¥­å', '')
                if project_id and project_name:
                    project_names[int(project_id)] = project_name
        
        return project_names
    
    def perform_comprehensive_matching(self) -> Dict:
        """åŒ…æ‹¬çš„ãªäº‹æ¥­åãƒãƒƒãƒãƒ³ã‚°ã‚’å®Ÿè¡Œ"""
        print("Performing comprehensive project name matching...")
        
        # å„ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹ã‹ã‚‰äº‹æ¥­åã‚’æŠ½å‡º
        improved_names = self.extract_project_names_from_improved_search()
        basic_form_names = self.extract_project_names_from_basic_form()
        
        # å…¨äº‹æ¥­åã®ãƒªã‚¹ãƒˆï¼ˆé‡è¤‡é™¤å»ï¼‰
        all_project_names = {}
        all_project_names.update(improved_names)
        if basic_form_names:
            all_project_names.update(basic_form_names)
        
        print(f"  Total projects in our data: {len(all_project_names)}")
        
        # ãƒãƒƒãƒãƒ³ã‚°çµæœ
        matching_results = {
            'exact_matches': {},
            'fuzzy_matches': {},
            'no_matches': [],
            'statistics': {}
        }
        
        exact_count = 0
        fuzzy_count = 0
        no_match_count = 0
        
        # å„å…¬å¼äº‹æ¥­åã«ã¤ã„ã¦æ¤œç´¢
        for official_name in self.official_projects:
            best_match = None
            best_similarity = 0.0
            best_project_id = None
            
            # å®Œå…¨ä¸€è‡´ãƒã‚§ãƒƒã‚¯
            exact_found = False
            for project_id, project_name in all_project_names.items():
                if official_name == project_name:
                    matching_results['exact_matches'][official_name] = {
                        'project_id': project_id,
                        'matched_name': project_name,
                        'similarity': 1.0,
                        'in_improved_search': project_id in improved_names,
                        'in_basic_form': project_id in basic_form_names
                    }
                    exact_found = True
                    exact_count += 1
                    break
            
            if exact_found:
                continue
            
            # ãƒ•ã‚¡ã‚¸ãƒ¼ãƒãƒƒãƒãƒ³ã‚°
            for project_id, project_name in all_project_names.items():
                similarity = self.fuzzy_match_project_name(official_name, project_name)
                if similarity > best_similarity:
                    best_similarity = similarity
                    best_match = project_name
                    best_project_id = project_id
            
            # é–¾å€¤ä»¥ä¸Šã®ãƒãƒƒãƒãŒã‚ã‚‹ã‹
            if best_similarity >= 0.7:  # 70%ä»¥ä¸Šã®é¡ä¼¼åº¦
                matching_results['fuzzy_matches'][official_name] = {
                    'project_id': best_project_id,
                    'matched_name': best_match,
                    'similarity': best_similarity,
                    'in_improved_search': best_project_id in improved_names,
                    'in_basic_form': best_project_id in basic_form_names
                }
                fuzzy_count += 1
            else:
                matching_results['no_matches'].append({
                    'official_name': official_name,
                    'best_candidate': best_match,
                    'best_similarity': best_similarity
                })
                no_match_count += 1
        
        # çµ±è¨ˆæƒ…å ±
        matching_results['statistics'] = {
            'total_official_projects': len(self.official_projects),
            'exact_matches': exact_count,
            'fuzzy_matches': fuzzy_count,
            'no_matches': no_match_count,
            'match_rate_exact': (exact_count / len(self.official_projects)) * 100,
            'match_rate_total': ((exact_count + fuzzy_count) / len(self.official_projects)) * 100,
            'coverage_analysis': {
                'in_improved_search': sum(1 for m in {**matching_results['exact_matches'], **matching_results['fuzzy_matches']}.values() if m['in_improved_search']),
                'in_basic_form': sum(1 for m in {**matching_results['exact_matches'], **matching_results['fuzzy_matches']}.values() if m['in_basic_form'])
            }
        }
        
        print(f"  Matching completed:")
        print(f"    Exact matches: {exact_count}")
        print(f"    Fuzzy matches: {fuzzy_count}")
        print(f"    No matches: {no_match_count}")
        print(f"    Total match rate: {matching_results['statistics']['match_rate_total']:.1f}%")
        
        return matching_results
    
    def analyze_missing_projects(self, matching_results: Dict) -> Dict:
        """è¦‹ã¤ã‹ã‚‰ãªã„äº‹æ¥­ã®è©³ç´°åˆ†æ"""
        print("Analyzing missing projects...")
        
        missing_projects = matching_results['no_matches']
        if not missing_projects:
            print("  No missing projects found!")
            return {'missing_analysis': [], 'recommendations': []}
        
        print(f"  Analyzing {len(missing_projects)} missing projects...")
        
        missing_analysis = []
        
        # å„æ¬ è½äº‹æ¥­ã«ã¤ã„ã¦è©³ç´°åˆ†æ
        for missing in missing_projects:
            official_name = missing['official_name']
            
            # AIé–¢é€£ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ã®æœ‰ç„¡ã‚’ãƒã‚§ãƒƒã‚¯
            ai_keywords = ['AI', 'ï¼¡ï¼©', 'A.I.', 'äººå·¥çŸ¥èƒ½', 'æ©Ÿæ¢°å­¦ç¿’', 'ç”ŸæˆAI', 'ç”Ÿæˆï¼¡ï¼©']
            found_keywords = [kw for kw in ai_keywords if kw in official_name]
            
            # å¯èƒ½ãªåŸå› ã‚’æ¨å®š
            possible_causes = []
            if not found_keywords:
                possible_causes.append("äº‹æ¥­åã«AIé–¢é€£ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰ãŒå«ã¾ã‚Œã¦ã„ãªã„")
            if len(official_name) > 50:
                possible_causes.append("äº‹æ¥­åãŒé•·ãã€éƒ¨åˆ†ä¸€è‡´ã§æ¤œå‡ºå›°é›£")
            if 'ï¼ˆ' in official_name or 'ï¼‰' in official_name:
                possible_causes.append("æ‹¬å¼§å†…ã®è©³ç´°æƒ…å ±ã«ã‚ˆã‚Šå®Œå…¨ä¸€è‡´å›°é›£")
            
            missing_analysis.append({
                'official_name': official_name,
                'ai_keywords_found': found_keywords,
                'possible_causes': possible_causes,
                'name_length': len(official_name)
            })
        
        # æ”¹å–„ææ¡ˆ
        recommendations = []
        if missing_projects:
            recommendations.extend([
                "äº‹æ¥­åä»¥å¤–ã®ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ï¼ˆäº‹æ¥­æ¦‚è¦ã€ç›®çš„ç­‰ï¼‰ã§ã®AIæ¤œç´¢ã‚’å¼·åŒ–",
                "ã‚ˆã‚ŠæŸ”è»Ÿãªéƒ¨åˆ†ä¸€è‡´æ¤œç´¢ãƒ‘ã‚¿ãƒ¼ãƒ³ã®å°å…¥",
                "æ‹¬å¼§å†…æƒ…å ±ã‚’é™¤å¤–ã—ãŸäº‹æ¥­åã§ã®æ¤œç´¢",
                "åŒç¾©èªãƒ»é¡ä¼¼èªè¾æ›¸ã®æ´»ç”¨"
            ])
        
        return {
            'missing_analysis': missing_analysis,
            'recommendations': recommendations
        }
    
    def generate_verification_report(self, matching_results: Dict, missing_analysis: Dict):
        """æ¤œè¨¼ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆãƒ»ä¿å­˜"""
        print("Generating verification report...")
        
        # è©³ç´°çµæœã‚’JSONä¿å­˜
        full_report = {
            'verification_summary': {
                'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),
                'official_projects_count': len(self.official_projects),
                'our_data_projects_count': len(self.improved_search_data),
                'basic_form_projects_count': len(self.basic_form_data) if self.basic_form_data is not None else 0
            },
            'matching_results': matching_results,
            'missing_analysis': missing_analysis
        }
        
        json_path = self.output_dir / 'rs_official_verification_report.json'
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(full_report, f, ensure_ascii=False, indent=2, default=str)
        print(f"  Full report saved: {json_path}")
        
        # HTMLãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        self.generate_html_verification_report(matching_results, missing_analysis)
        
        # ç°¡æ½”ãªã‚µãƒãƒªãƒ¼CSV
        self.generate_summary_csv(matching_results)
    
    def generate_summary_csv(self, matching_results: Dict):
        """æ¤œè¨¼çµæœã‚µãƒãƒªãƒ¼CSVã‚’ç”Ÿæˆ"""
        summary_data = []
        
        # å®Œå…¨ä¸€è‡´
        for official_name, match_data in matching_results['exact_matches'].items():
            summary_data.append({
                'å…¬å¼äº‹æ¥­å': official_name,
                'ãƒãƒƒãƒã‚¿ã‚¤ãƒ—': 'å®Œå…¨ä¸€è‡´',
                'äº‹æ¥­ID': match_data['project_id'],
                'ãƒãƒƒãƒã—ãŸäº‹æ¥­å': match_data['matched_name'],
                'é¡ä¼¼åº¦': match_data['similarity'],
                'æ”¹å–„æ¤œç´¢ã«å«ã¾ã‚Œã‚‹': match_data['in_improved_search'],
                'åŸºæœ¬å½¢ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã«å«ã¾ã‚Œã‚‹': match_data['in_basic_form']
            })
        
        # ãƒ•ã‚¡ã‚¸ãƒ¼ãƒãƒƒãƒ
        for official_name, match_data in matching_results['fuzzy_matches'].items():
            summary_data.append({
                'å…¬å¼äº‹æ¥­å': official_name,
                'ãƒãƒƒãƒã‚¿ã‚¤ãƒ—': 'ãƒ•ã‚¡ã‚¸ãƒ¼ãƒãƒƒãƒ',
                'äº‹æ¥­ID': match_data['project_id'],
                'ãƒãƒƒãƒã—ãŸäº‹æ¥­å': match_data['matched_name'],
                'é¡ä¼¼åº¦': match_data['similarity'],
                'æ”¹å–„æ¤œç´¢ã«å«ã¾ã‚Œã‚‹': match_data['in_improved_search'],
                'åŸºæœ¬å½¢ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã«å«ã¾ã‚Œã‚‹': match_data['in_basic_form']
            })
        
        # ãƒãƒƒãƒãªã—
        for missing in matching_results['no_matches']:
            summary_data.append({
                'å…¬å¼äº‹æ¥­å': missing['official_name'],
                'ãƒãƒƒãƒã‚¿ã‚¤ãƒ—': 'ãƒãƒƒãƒãªã—',
                'äº‹æ¥­ID': '',
                'ãƒãƒƒãƒã—ãŸäº‹æ¥­å': missing.get('best_candidate', ''),
                'é¡ä¼¼åº¦': missing.get('best_similarity', 0),
                'æ”¹å–„æ¤œç´¢ã«å«ã¾ã‚Œã‚‹': False,
                'åŸºæœ¬å½¢ã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆã«å«ã¾ã‚Œã‚‹': False
            })
        
        df_summary = pd.DataFrame(summary_data)
        csv_path = self.output_dir / 'verification_summary.csv'
        df_summary.to_csv(csv_path, index=False, encoding='utf-8-sig')
        print(f"  Summary CSV saved: {csv_path}")
    
    def generate_html_verification_report(self, matching_results: Dict, missing_analysis: Dict):
        """HTMLæ¤œè¨¼ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        stats = matching_results['statistics']
        
        html_content = f"""<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <title>RSã‚·ã‚¹ãƒ†ãƒ å…¬å¼AIæ¤œç´¢çµæœ ç…§åˆæ¤œè¨¼ãƒ¬ãƒãƒ¼ãƒˆ</title>
    <style>
        body {{ font-family: 'Segoe UI', Arial, sans-serif; margin: 20px; line-height: 1.6; }}
        h1 {{ color: #2c5aa0; text-align: center; border-bottom: 3px solid #2c5aa0; padding-bottom: 10px; }}
        .summary {{ background-color: #e8f4f8; padding: 20px; border-radius: 8px; margin: 20px 0; }}
        .metric {{ font-size: 1.5em; font-weight: bold; text-align: center; margin: 10px 0; }}
        .success {{ color: #28a745; }}
        .warning {{ color: #ffc107; }}
        .danger {{ color: #dc3545; }}
        table {{ border-collapse: collapse; width: 100%; margin: 20px 0; }}
        th, td {{ border: 1px solid #ddd; padding: 8px; text-align: left; }}
        th {{ background-color: #f2f2f2; }}
        .match-exact {{ background-color: #d4edda; }}
        .match-fuzzy {{ background-color: #fff3cd; }}
        .match-none {{ background-color: #f8d7da; }}
        ul {{ padding-left: 20px; }}
        li {{ margin: 5px 0; }}
    </style>
</head>
<body>
    <h1>ğŸ” RSã‚·ã‚¹ãƒ†ãƒ å…¬å¼AIæ¤œç´¢çµæœ ç…§åˆæ¤œè¨¼ãƒ¬ãƒãƒ¼ãƒˆ</h1>
    
    <div class="summary">
        <h2>ğŸ“Š æ¤œè¨¼çµæœã‚µãƒãƒªãƒ¼</h2>
        <div class="metric success">å®Œå…¨ä¸€è‡´: {stats['exact_matches']}ä»¶</div>
        <div class="metric warning">ãƒ•ã‚¡ã‚¸ãƒ¼ãƒãƒƒãƒ: {stats['fuzzy_matches']}ä»¶</div>
        <div class="metric danger">ãƒãƒƒãƒãªã—: {stats['no_matches']}ä»¶</div>
        <div class="metric">ç·ãƒãƒƒãƒç‡: {stats['match_rate_total']:.1f}%</div>
    </div>
    
    <h2>ğŸ“ˆ è©³ç´°çµ±è¨ˆ</h2>
    <table>
        <tr>
            <th>é …ç›®</th>
            <th>ä»¶æ•°</th>
            <th>å‰²åˆ</th>
        </tr>
        <tr class="match-exact">
            <td><strong>å®Œå…¨ä¸€è‡´</strong></td>
            <td>{stats['exact_matches']}</td>
            <td>{stats['match_rate_exact']:.1f}%</td>
        </tr>
        <tr class="match-fuzzy">
            <td><strong>ãƒ•ã‚¡ã‚¸ãƒ¼ãƒãƒƒãƒ</strong></td>
            <td>{stats['fuzzy_matches']}</td>
            <td>{(stats['fuzzy_matches']/stats['total_official_projects']*100):.1f}%</td>
        </tr>
        <tr class="match-none">
            <td><strong>ãƒãƒƒãƒãªã—</strong></td>
            <td>{stats['no_matches']}</td>
            <td>{(stats['no_matches']/stats['total_official_projects']*100):.1f}%</td>
        </tr>
        <tr>
            <td><strong>å…¬å¼äº‹æ¥­ç·æ•°</strong></td>
            <td>{stats['total_official_projects']}</td>
            <td>100.0%</td>
        </tr>
    </table>
    
    <h2>ğŸ¯ ãƒ‡ãƒ¼ã‚¿ã‚«ãƒãƒ¬ãƒƒã‚¸åˆ†æ</h2>
    <table>
        <tr>
            <th>ãƒ‡ãƒ¼ã‚¿ã‚½ãƒ¼ã‚¹</th>
            <th>ãƒãƒƒãƒã—ãŸäº‹æ¥­æ•°</th>
            <th>ã‚«ãƒãƒ¬ãƒƒã‚¸</th>
        </tr>
        <tr>
            <td>æ”¹å–„ã•ã‚ŒãŸAIæ¤œç´¢çµæœ</td>
            <td>{stats['coverage_analysis']['in_improved_search']}</td>
            <td>{(stats['coverage_analysis']['in_improved_search']/stats['total_official_projects']*100):.1f}%</td>
        </tr>
        <tr>
            <td>åŸºæœ¬å½¢AIã‚¹ãƒ—ãƒ¬ãƒƒãƒ‰ã‚·ãƒ¼ãƒˆ</td>
            <td>{stats['coverage_analysis']['in_basic_form']}</td>
            <td>{(stats['coverage_analysis']['in_basic_form']/stats['total_official_projects']*100):.1f}%</td>
        </tr>
    </table>
"""
        
        # è¦‹ã¤ã‹ã‚‰ãªã„äº‹æ¥­ã®åˆ†æ
        if missing_analysis['missing_analysis']:
            html_content += f"""
    <h2>âš ï¸ è¦‹ã¤ã‹ã‚‰ãªã„äº‹æ¥­ã®åˆ†æ</h2>
    <table>
        <tr>
            <th>å…¬å¼äº‹æ¥­å</th>
            <th>äº‹æ¥­åã®é•·ã•</th>
            <th>AIé–¢é€£ã‚­ãƒ¼ãƒ¯ãƒ¼ãƒ‰</th>
            <th>æ¨å®šåŸå› </th>
        </tr>"""
            
            for missing in missing_analysis['missing_analysis'][:20]:  # æœ€åˆã®20ä»¶
                keywords = ', '.join(missing['ai_keywords_found']) if missing['ai_keywords_found'] else 'ãªã—'
                causes = ', '.join(missing['possible_causes']) if missing['possible_causes'] else 'ä¸æ˜'
                html_content += f"""
        <tr class="match-none">
            <td>{missing['official_name']}</td>
            <td>{missing['name_length']}</td>
            <td>{keywords}</td>
            <td>{causes}</td>
        </tr>"""
            
            html_content += """
    </table>"""
        
        # æ”¹å–„ææ¡ˆ
        if missing_analysis['recommendations']:
            html_content += """
    <h2>ğŸ’¡ æ”¹å–„ææ¡ˆ</h2>
    <ul>"""
            for rec in missing_analysis['recommendations']:
                html_content += f"        <li>{rec}</li>\n"
            html_content += """
    </ul>"""
        
        html_content += """
    <div style="margin-top: 40px; text-align: center; color: #666;">
        Generated by RS Official Verification Engine
    </div>
</body>
</html>"""
        
        html_path = self.output_dir / 'rs_verification_report.html'
        with open(html_path, 'w', encoding='utf-8') as f:
            f.write(html_content)
        print(f"  HTML report saved: {html_path}")
    
    def run(self):
        """æ¤œè¨¼ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ"""
        print("=" * 60)
        print("ğŸ” RS Official AI Search Verification")
        print("=" * 60)
        
        start_time = time.time()
        
        # 1. ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
        self.load_official_ai_list()
        self.load_improved_search_data()
        self.load_basic_form_data()
        self.load_feather_tables()
        
        if not self.official_projects:
            print("No official projects loaded. Exiting.")
            return None
        
        # 2. åŒ…æ‹¬çš„ãƒãƒƒãƒãƒ³ã‚°
        matching_results = self.perform_comprehensive_matching()
        
        # 3. æ¬ è½äº‹æ¥­åˆ†æ
        missing_analysis = self.analyze_missing_projects(matching_results)
        
        # 4. æ¤œè¨¼ãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        self.generate_verification_report(matching_results, missing_analysis)
        
        elapsed = time.time() - start_time
        
        # æœ€çµ‚çµæœè¡¨ç¤º
        stats = matching_results['statistics']
        print(f"\n{'='*60}")
        print("ğŸ‰ æ¤œè¨¼å®Œäº†!")
        print(f"{'='*60}")
        print(f"ğŸ“Š å…¬å¼äº‹æ¥­æ•°: {stats['total_official_projects']}ä»¶")
        print(f"âœ… å®Œå…¨ä¸€è‡´: {stats['exact_matches']}ä»¶ ({stats['match_rate_exact']:.1f}%)")
        print(f"ğŸ”„ ãƒ•ã‚¡ã‚¸ãƒ¼ãƒãƒƒãƒ: {stats['fuzzy_matches']}ä»¶")
        print(f"âŒ ãƒãƒƒãƒãªã—: {stats['no_matches']}ä»¶")
        print(f"ğŸ¯ ç·ãƒãƒƒãƒç‡: {stats['match_rate_total']:.1f}%")
        print(f"â±ï¸  å®Ÿè¡Œæ™‚é–“: {elapsed:.1f}ç§’")
        print(f"ğŸ“ å‡ºåŠ›å…ˆ: {self.output_dir}")
        print(f"{'='*60}")
        
        return matching_results, missing_analysis


if __name__ == "__main__":
    verifier = RSOfficalVerificationEngine()
    verifier.run()