#!/usr/bin/env python3
"""
AI exact matchæ¤œç´¢ã®åŸå› èª¿æŸ»ã‚¹ã‚¯ãƒªãƒ—ãƒˆ
ç¾åœ¨57ä»¶ã—ã‹è¦‹ã¤ã‹ã‚‰ãªã„åŸå› ã‚’è©³ç´°åˆ†æ
"""
import pandas as pd
import json
import re
from pathlib import Path
from typing import Dict, List, Set, Any
from collections import defaultdict, Counter
import time


class AIMatchInvestigator:
    """AIæ¤œç´¢ãƒãƒƒãƒãƒ³ã‚°å•é¡Œã®èª¿æŸ»ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, feather_dir: str = "data/normalized_feather"):
        self.feather_dir = Path(feather_dir)
        self.output_dir = Path("data/ai_investigation")
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # ç¾åœ¨ã®æ¤œç´¢ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆå•é¡Œã®ã‚ã‚‹ã‚‚ã®ï¼‰
        self.current_pattern = r'\bAI\b'
        
        # æ”¹å–„ã•ã‚ŒãŸæ¤œç´¢ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆãƒ†ã‚¹ãƒˆç”¨ï¼‰
        self.improved_patterns = [
            r'AI',  # å˜ç´”ãªAIï¼ˆå¢ƒç•Œãªã—ï¼‰
            r'ï¼¡ï¼©',  # å…¨è§’AI
            r'A\.I\.',  # A.I.
            r'ï¼¡\.ï¼©\.',  # å…¨è§’A.I.
        ]
        
        # AIé–¢é€£è¤‡åˆèªãƒ‘ã‚¿ãƒ¼ãƒ³
        self.compound_patterns = [
            r'ç”ŸæˆAI', r'ç”Ÿæˆï¼¡ï¼©',
            r'AI[ã‚¢-ãƒ³\w]*', r'ï¼¡ï¼©[ã‚¢-ãƒ³\w]*',  # AI+ä½•ã‹
            r'[ã‚¢-ãƒ³\w]*AI', r'[ã‚¢-ãƒ³\w]*ï¼¡ï¼©',  # ä½•ã‹+AI
        ]
        
        self.tables_data = {}
        self.search_config = {}
        self.load_metadata()
    
    def load_metadata(self):
        """ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿"""
        metadata_path = self.feather_dir / 'ai_search_metadata.json'
        if metadata_path.exists():
            with open(metadata_path, 'r', encoding='utf-8') as f:
                metadata = json.load(f)
            self.search_config = metadata.get('ai_search_fields', {})
        else:
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š
            self.search_config = {
                'projects': ['äº‹æ¥­å', 'äº‹æ¥­ã®ç›®çš„', 'äº‹æ¥­ã®æ¦‚è¦', 'ç¾çŠ¶ãƒ»èª²é¡Œ'],
                'expenditure_info': ['æ”¯å‡ºå…ˆå', 'å¥‘ç´„æ¦‚è¦', 'è²»ç›®', 'ä½¿é€”'],
                'goals_performance': ['ã‚¢ã‚¯ãƒ†ã‚£ãƒ“ãƒ†ã‚£ï¼æ´»å‹•ç›®æ¨™ï¼æˆæœç›®æ¨™', 'æ´»å‹•æŒ‡æ¨™ï¼æˆæœæŒ‡æ¨™'],
                'expenditure_connections': ['æ”¯å‡ºå…ˆã®æ”¯å‡ºå…ˆãƒ–ãƒ­ãƒƒã‚¯å', 'è³‡é‡‘ã®æµã‚Œã®è£œè¶³æƒ…å ±'],
                'contracts': ['å¥‘ç´„å…ˆåï¼ˆå›½åº«å‚µå‹™è² æ‹…è¡Œç‚ºç­‰ã«ã‚ˆã‚‹å¥‘ç´„ï¼‰', 'å¥‘ç´„æ¦‚è¦ï¼ˆå¥‘ç´„åï¼‰ï¼ˆå›½åº«å‚µå‹™è² æ‹…è¡Œç‚ºç­‰ã«ã‚ˆã‚‹å¥‘ç´„ï¼‰']
            }
    
    def load_feather_tables(self):
        """Featherãƒ†ãƒ¼ãƒ–ãƒ«èª­ã¿è¾¼ã¿"""
        print("Loading Feather tables for investigation...")
        
        for table_name in self.search_config.keys():
            feather_path = self.feather_dir / f"{table_name}.feather"
            if feather_path.exists():
                print(f"  Loading: {table_name}")
                try:
                    df = pd.read_feather(feather_path)
                    self.tables_data[table_name] = df
                    print(f"    Records: {len(df):,}, Columns: {len(df.columns)}")
                except Exception as e:
                    print(f"    Error loading {table_name}: {e}")
            else:
                print(f"  Warning: {feather_path} not found")
    
    def search_pattern_in_text(self, text: str, pattern: str) -> List[str]:
        """ãƒ†ã‚­ã‚¹ãƒˆå†…ã§ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œç´¢"""
        if not text or pd.isna(text):
            return []
        
        text_str = str(text)
        try:
            matches = re.findall(pattern, text_str, re.IGNORECASE)
            return matches
        except re.error:
            return []
    
    def analyze_current_pattern_limitations(self) -> Dict:
        """ç¾åœ¨ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã®åˆ¶é™ã‚’åˆ†æ"""
        print("\n=== Analyzing Current Pattern Limitations ===")
        
        current_matches = defaultdict(list)
        improved_matches = defaultdict(list)
        compound_matches = defaultdict(list)
        
        total_records_checked = 0
        
        for table_name, df in self.tables_data.items():
            print(f"\nAnalyzing table: {table_name}")
            search_fields = self.search_config.get(table_name, [])
            available_fields = [f for f in search_fields if f in df.columns]
            
            if not available_fields:
                continue
            
            for idx, record in df.iterrows():
                project_id = record.get('äºˆç®—äº‹æ¥­ID', f'unknown_{idx}')
                
                for field in available_fields:
                    text = record.get(field, '')
                    if not text or pd.isna(text):
                        continue
                    
                    text_str = str(text)
                    total_records_checked += 1
                    
                    # ç¾åœ¨ã®ãƒ‘ã‚¿ãƒ¼ãƒ³
                    current = self.search_pattern_in_text(text_str, self.current_pattern)
                    if current:
                        current_matches[project_id].append({
                            'table': table_name,
                            'field': field,
                            'text': text_str[:200],
                            'matches': current
                        })
                    
                    # æ”¹å–„ã•ã‚ŒãŸãƒ‘ã‚¿ãƒ¼ãƒ³
                    for pattern in self.improved_patterns:
                        improved = self.search_pattern_in_text(text_str, pattern)
                        if improved:
                            improved_matches[project_id].append({
                                'table': table_name,
                                'field': field,
                                'text': text_str[:200],
                                'pattern': pattern,
                                'matches': improved
                            })
                    
                    # è¤‡åˆèªãƒ‘ã‚¿ãƒ¼ãƒ³
                    for pattern in self.compound_patterns:
                        compound = self.search_pattern_in_text(text_str, pattern)
                        if compound:
                            compound_matches[project_id].append({
                                'table': table_name,
                                'field': field,
                                'text': text_str[:200],
                                'pattern': pattern,
                                'matches': compound
                            })
        
        analysis = {
            'total_records_checked': total_records_checked,
            'current_pattern_matches': len(current_matches),
            'improved_pattern_matches': len(improved_matches),
            'compound_pattern_matches': len(compound_matches),
            'current_pattern_projects': list(current_matches.keys()),
            'improved_pattern_projects': list(improved_matches.keys()),
            'compound_pattern_projects': list(compound_matches.keys()),
            'current_matches_detail': dict(current_matches),
            'improved_matches_detail': dict(improved_matches),
            'compound_matches_detail': dict(compound_matches)
        }
        
        print(f"\nAnalysis Results:")
        print(f"  Current pattern (\\bAI\\b): {analysis['current_pattern_matches']} projects")
        print(f"  Improved patterns: {analysis['improved_pattern_matches']} projects")
        print(f"  Compound patterns: {analysis['compound_pattern_matches']} projects")
        
        return analysis
    
    def find_missed_ai_instances(self, analysis: Dict) -> Dict:
        """è¦‹è½ã¨ã•ã‚ŒãŸAIã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ã‚’ç‰¹å®š"""
        print("\n=== Finding Missed AI Instances ===")
        
        current_projects = set(analysis['current_pattern_projects'])
        improved_projects = set(analysis['improved_pattern_projects'])
        compound_projects = set(analysis['compound_pattern_projects'])
        
        # è¦‹è½ã¨ã•ã‚ŒãŸãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆ
        missed_by_current = improved_projects - current_projects
        missed_compounds = compound_projects - current_projects
        
        # å…·ä½“ä¾‹ã®åé›†
        missed_examples = []
        
        # æ”¹å–„ã•ã‚ŒãŸãƒ‘ã‚¿ãƒ¼ãƒ³ã§è¦‹ã¤ã‹ã£ãŸãŒç¾åœ¨ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã§è¦‹è½ã¨ã•ã‚ŒãŸä¾‹
        for project_id in list(missed_by_current)[:10]:  # æœ€åˆã®10ä»¶
            if project_id in analysis['improved_matches_detail']:
                for match in analysis['improved_matches_detail'][project_id][:3]:  # å„ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®æœ€åˆã®3ä»¶
                    missed_examples.append({
                        'type': 'improved_pattern',
                        'project_id': project_id,
                        'table': match['table'],
                        'field': match['field'],
                        'text': match['text'],
                        'pattern': match['pattern'],
                        'matches': match['matches']
                    })
        
        # è¤‡åˆèªã§è¦‹ã¤ã‹ã£ãŸãŒç¾åœ¨ã®ãƒ‘ã‚¿ãƒ¼ãƒ³ã§è¦‹è½ã¨ã•ã‚ŒãŸä¾‹
        for project_id in list(missed_compounds)[:10]:  # æœ€åˆã®10ä»¶
            if project_id in analysis['compound_matches_detail']:
                for match in analysis['compound_matches_detail'][project_id][:3]:  # å„ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆã®æœ€åˆã®3ä»¶
                    missed_examples.append({
                        'type': 'compound_pattern',
                        'project_id': project_id,
                        'table': match['table'],
                        'field': match['field'],
                        'text': match['text'],
                        'pattern': match['pattern'],
                        'matches': match['matches']
                    })
        
        missed_analysis = {
            'missed_by_improved_patterns': len(missed_by_current),
            'missed_by_compound_patterns': len(missed_compounds),
            'total_unique_missed': len(missed_by_current | missed_compounds),
            'missed_examples': missed_examples,
            'potential_total': len(current_projects | improved_projects | compound_projects)
        }
        
        print(f"Missed AI Instances:")
        print(f"  Missed by improved patterns: {missed_analysis['missed_by_improved_patterns']}")
        print(f"  Missed by compound patterns: {missed_analysis['missed_by_compound_patterns']}")
        print(f"  Total unique missed: {missed_analysis['total_unique_missed']}")
        print(f"  Potential total: {missed_analysis['potential_total']}")
        
        return missed_analysis
    
    def generate_detailed_statistics(self, analysis: Dict, missed_analysis: Dict) -> Dict:
        """è©³ç´°çµ±è¨ˆã‚’ç”Ÿæˆ"""
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ¥çµ±è¨ˆ
        pattern_stats = Counter()
        for matches in analysis['improved_matches_detail'].values():
            for match in matches:
                pattern_stats[match['pattern']] += 1
        
        compound_stats = Counter()
        for matches in analysis['compound_matches_detail'].values():
            for match in matches:
                compound_stats[match['pattern']] += 1
        
        # ãƒ†ãƒ¼ãƒ–ãƒ«åˆ¥çµ±è¨ˆ
        table_stats = Counter()
        for matches in analysis['improved_matches_detail'].values():
            for match in matches:
                table_stats[match['table']] += 1
        
        statistics = {
            'summary': {
                'current_method_projects': analysis['current_pattern_matches'],
                'improved_method_projects': analysis['improved_pattern_matches'],
                'compound_method_projects': analysis['compound_pattern_matches'],
                'total_potential_projects': missed_analysis['potential_total'],
                'improvement_absolute': missed_analysis['total_unique_missed'],
                'improvement_percentage': (missed_analysis['total_unique_missed'] / analysis['current_pattern_matches'] * 100) if analysis['current_pattern_matches'] > 0 else 0
            },
            'pattern_frequency': dict(pattern_stats.most_common()),
            'compound_frequency': dict(compound_stats.most_common()),
            'table_distribution': dict(table_stats.most_common()),
            'problem_analysis': {
                'word_boundary_issue': analysis['current_pattern_matches'] < analysis['improved_pattern_matches'],
                'compound_term_issue': analysis['compound_pattern_matches'] > 0,
                'full_width_issue': pattern_stats.get('ï¼¡ï¼©', 0) > 0
            }
        }
        
        return statistics
    
    def save_investigation_results(self, analysis: Dict, missed_analysis: Dict, statistics: Dict):
        """èª¿æŸ»çµæœã‚’ä¿å­˜"""
        print("\nSaving investigation results...")
        
        # å®Œå…¨ãªèª¿æŸ»çµæœ
        full_report = {
            'investigation_summary': {
                'timestamp': time.strftime('%Y-%m-%d %H:%M:%S'),
                'current_pattern': self.current_pattern,
                'improved_patterns': self.improved_patterns,
                'compound_patterns': self.compound_patterns
            },
            'pattern_analysis': analysis,
            'missed_instances': missed_analysis,
            'statistics': statistics
        }
        
        # JSONä¿å­˜
        json_path = self.output_dir / 'ai_match_investigation_report.json'
        with open(json_path, 'w', encoding='utf-8') as f:
            json.dump(full_report, f, ensure_ascii=False, indent=2, default=str)
        print(f"  Full report saved: {json_path}")
        
        # ç°¡æ½”ãªã‚µãƒãƒªãƒ¼ä¿å­˜
        summary = {
            'current_matches': analysis['current_pattern_matches'],
            'potential_matches': missed_analysis['potential_total'],
            'missed_count': missed_analysis['total_unique_missed'],
            'improvement_needed': missed_analysis['total_unique_missed'] > 0,
            'key_issues': {
                'word_boundary_restrictive': analysis['improved_pattern_matches'] > analysis['current_pattern_matches'],
                'compound_terms_missed': analysis['compound_pattern_matches'] > 0,
                'full_width_missed': 'ï¼¡ï¼©' in str(analysis['improved_matches_detail'])
            },
            'recommended_patterns': self.improved_patterns + self.compound_patterns
        }
        
        summary_path = self.output_dir / 'ai_investigation_summary.json'
        with open(summary_path, 'w', encoding='utf-8') as f:
            json.dump(summary, f, ensure_ascii=False, indent=2)
        print(f"  Summary saved: {summary_path}")
        
        # HTMLãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        self.generate_html_report(statistics, missed_analysis)
    
    def generate_html_report(self, statistics: Dict, missed_analysis: Dict):
        """HTMLèª¿æŸ»ãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        
        html_content = f"""<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <title>AIæ¤œç´¢ãƒãƒƒãƒãƒ³ã‚°å•é¡Œèª¿æŸ»ãƒ¬ãƒãƒ¼ãƒˆ</title>
    <style>
        body {{ font-family: 'Segoe UI', Arial, sans-serif; margin: 20px; line-height: 1.6; }}
        h1 {{ color: #dc3545; text-align: center; border-bottom: 3px solid #dc3545; padding-bottom: 10px; }}
        h2 {{ color: #333; border-bottom: 2px solid #ddd; padding-bottom: 5px; }}
        .alert {{ background-color: #fff3cd; border: 1px solid #ffeaa7; padding: 15px; border-radius: 5px; margin: 15px 0; }}
        .success {{ background-color: #d4edda; border: 1px solid #c3e6cb; }}
        .error {{ background-color: #f8d7da; border: 1px solid #f5c6cb; }}
        .metric {{ font-size: 1.5em; font-weight: bold; text-align: center; margin: 10px 0; }}
        .current {{ color: #dc3545; }}
        .potential {{ color: #28a745; }}
        .missed {{ color: #fd7e14; }}
        table {{ border-collapse: collapse; width: 100%; margin: 20px 0; }}
        th, td {{ border: 1px solid #ddd; padding: 8px; text-align: left; }}
        th {{ background-color: #f2f2f2; }}
        .example {{ background-color: #f8f9fa; padding: 10px; margin: 10px 0; border-left: 4px solid #007bff; }}
        .code {{ font-family: monospace; background-color: #f8f9fa; padding: 2px 4px; }}
    </style>
</head>
<body>
    <h1>ğŸ” AIæ¤œç´¢ãƒãƒƒãƒãƒ³ã‚°å•é¡Œèª¿æŸ»ãƒ¬ãƒãƒ¼ãƒˆ</h1>
    
    <div class="alert error">
        <h3>âš ï¸ å•é¡Œã®æ¦‚è¦</h3>
        <p>ç¾åœ¨ã®æ¤œç´¢ãƒ‘ã‚¿ãƒ¼ãƒ³ <span class="code">\\bAI\\b</span> ã§ã¯<strong>{statistics['summary']['current_method_projects']}ä»¶</strong>ã—ã‹è¦‹ã¤ã‹ã‚‰ãªã„ãŒã€
        æ”¹å–„ã•ã‚ŒãŸãƒ‘ã‚¿ãƒ¼ãƒ³ã§ã¯<strong>{statistics['summary']['total_potential_projects']}ä»¶</strong>ã®å¯èƒ½æ€§ãŒã‚ã‚Šã¾ã™ã€‚</p>
        <div class="metric missed">è¦‹è½ã¨ã—: +{statistics['summary']['improvement_absolute']}ä»¶ ({statistics['summary']['improvement_percentage']:.1f}%æ”¹å–„)</div>
    </div>
    
    <h2>ğŸ“Š æ¤œç´¢çµæœæ¯”è¼ƒ</h2>
    <table>
        <tr>
            <th>æ¤œç´¢æ–¹æ³•</th>
            <th>ãƒãƒƒãƒæ•°</th>
            <th>ç‰¹å¾´</th>
        </tr>
        <tr>
            <td><strong>ç¾åœ¨ã®ãƒ‘ã‚¿ãƒ¼ãƒ³</strong><br><span class="code">\\bAI\\b</span></td>
            <td class="current">{statistics['summary']['current_method_projects']}ä»¶</td>
            <td>å˜èªå¢ƒç•Œã‚ã‚Šãƒ»è¤‡åˆèªé™¤å¤–</td>
        </tr>
        <tr>
            <td><strong>æ”¹å–„ã•ã‚ŒãŸãƒ‘ã‚¿ãƒ¼ãƒ³</strong><br><span class="code">AI|ï¼¡ï¼©|A\\.I\\.</span></td>
            <td class="potential">{statistics['summary']['improved_method_projects']}ä»¶</td>
            <td>å¢ƒç•Œåˆ¶é™ç·©å’Œãƒ»å…¨è§’å¯¾å¿œ</td>
        </tr>
        <tr>
            <td><strong>è¤‡åˆèªãƒ‘ã‚¿ãƒ¼ãƒ³</strong><br><span class="code">ç”ŸæˆAI|AIæ­è¼‰</span></td>
            <td class="potential">{statistics['summary']['compound_method_projects']}ä»¶</td>
            <td>è¤‡åˆèªãƒ»æ´¾ç”Ÿèªå¯¾å¿œ</td>
        </tr>
        <tr class="success">
            <td><strong>çµ±åˆçµæœ</strong></td>
            <td class="potential">{statistics['summary']['total_potential_projects']}ä»¶</td>
            <td>åŒ…æ‹¬çš„AIæ¤œç´¢</td>
        </tr>
    </table>
    
    <h2>ğŸ¯ ç™ºè¦‹ã•ã‚ŒãŸå•é¡Œ</h2>
    
    <div class="alert">
        <h4>1. å˜èªå¢ƒç•Œåˆ¶é™ã®å•é¡Œ</h4>
        <p>ç¾åœ¨ã® <span class="code">\\bAI\\b</span> ãƒ‘ã‚¿ãƒ¼ãƒ³ã¯ä»¥ä¸‹ã‚’é™¤å¤–ï¼š</p>
        <ul>
            <li>ã€Œç”ŸæˆAIã€ã€ŒAIã‚·ã‚¹ãƒ†ãƒ ã€ãªã©ã®è¤‡åˆèª</li>
            <li>ã€ŒAIæ­è¼‰ã€ã€ŒAIæ´»ç”¨ã€ãªã©ã®é€£ç¶šè¡¨è¨˜</li>
            <li>æ–‡ã®é€”ä¸­ã§ã®è‡ªç„¶ãªä½¿ç”¨</li>
        </ul>
    </div>
    
    <div class="alert">
        <h4>2. å…¨è§’æ–‡å­—ã®æœªå¯¾å¿œ</h4>
        <p>æ—¥æœ¬èªæ–‡æ›¸ã§ã‚ˆãä½¿ã‚ã‚Œã‚‹å…¨è§’ã€Œï¼¡ï¼©ã€ãŒæ¤œç´¢å¯¾è±¡å¤–</p>
    </div>
    
    <div class="alert">
        <h4>3. è¡¨è¨˜ãƒãƒªã‚¨ãƒ¼ã‚·ãƒ§ãƒ³ã®è¦‹è½ã¨ã—</h4>
        <p>ã€ŒA.I.ã€ã€Œï¼¡.ï¼©.ã€ãªã©ã®ç•¥è¨˜è¡¨è¨˜ãŒæœªå¯¾å¿œ</p>
    </div>
    
    <h2>ğŸ“ è¦‹è½ã¨ã—ä¾‹ï¼ˆã‚µãƒ³ãƒ—ãƒ«ï¼‰</h2>
"""

        # è¦‹è½ã¨ã—ä¾‹ã‚’è¿½åŠ 
        if missed_analysis.get('missed_examples'):
            for i, example in enumerate(missed_analysis['missed_examples'][:5]):
                html_content += f"""
    <div class="example">
        <strong>ä¾‹ {i+1}: {example['type']}</strong><br>
        <strong>ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆID:</strong> {example['project_id']}<br>
        <strong>ãƒ†ãƒ¼ãƒ–ãƒ«:</strong> {example['table']}<br>
        <strong>ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰:</strong> {example['field']}<br>
        <strong>ãƒãƒƒãƒãƒ‘ã‚¿ãƒ¼ãƒ³:</strong> <span class="code">{example['pattern']}</span><br>
        <strong>ãƒ†ã‚­ã‚¹ãƒˆ:</strong> {example['text'][:150]}...<br>
        <strong>ãƒãƒƒãƒ:</strong> {', '.join(example['matches'])}
    </div>
"""

        html_content += f"""
    <h2>ğŸ”§ æ¨å¥¨æ”¹å–„æ¡ˆ</h2>
    
    <div class="alert success">
        <h4>æ–°ã—ã„æ¤œç´¢ãƒ‘ã‚¿ãƒ¼ãƒ³</h4>
        <ul>
            <li><span class="code">AI|ï¼¡ï¼©</span> - åŸºæœ¬å½¢ãƒ»å…¨è§’å¯¾å¿œ</li>
            <li><span class="code">A\\.I\\.|ï¼¡\\.ï¼©\\.</span> - ç•¥è¨˜å¯¾å¿œ</li>
            <li><span class="code">ç”ŸæˆAI|AIã‚·ã‚¹ãƒ†ãƒ |AIæ´»ç”¨</span> - è¤‡åˆèªå¯¾å¿œ</li>
        </ul>
        <p><strong>æœŸå¾…åŠ¹æœ:</strong> {statistics['summary']['total_potential_projects']}ä»¶ï¼ˆ+{statistics['summary']['improvement_absolute']}ä»¶ï¼‰</p>
    </div>
    
    <div style="margin-top: 40px; text-align: center; color: #666; font-size: 0.9em;">
        Generated by AI Match Investigator
    </div>
</body>
</html>"""
        
        html_path = self.output_dir / 'ai_investigation_report.html'
        with open(html_path, 'w', encoding='utf-8') as f:
            f.write(html_content)
        print(f"  HTML report saved: {html_path}")
    
    def run(self):
        """èª¿æŸ»ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ"""
        print("=" * 60)
        print("ğŸ” AI Exact Match Investigation")
        print("=" * 60)
        
        start_time = time.time()
        
        # 1. ãƒ†ãƒ¼ãƒ–ãƒ«èª­ã¿è¾¼ã¿
        self.load_feather_tables()
        
        if not self.tables_data:
            print("No tables loaded. Exiting.")
            return None
        
        # 2. ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ¶é™åˆ†æ
        analysis = self.analyze_current_pattern_limitations()
        
        # 3. è¦‹è½ã¨ã—ã‚¤ãƒ³ã‚¹ã‚¿ãƒ³ã‚¹ç‰¹å®š
        missed_analysis = self.find_missed_ai_instances(analysis)
        
        # 4. è©³ç´°çµ±è¨ˆç”Ÿæˆ
        statistics = self.generate_detailed_statistics(analysis, missed_analysis)
        
        # 5. çµæœä¿å­˜
        self.save_investigation_results(analysis, missed_analysis, statistics)
        
        elapsed = time.time() - start_time
        
        # çµæœè¡¨ç¤º
        print(f"\n{'='*60}")
        print("ğŸ¯ èª¿æŸ»çµæœã‚µãƒãƒªãƒ¼")
        print(f"{'='*60}")
        print(f"ç¾åœ¨ã®ãƒãƒƒãƒæ•°: {statistics['summary']['current_method_projects']}ä»¶")
        print(f"æ½œåœ¨çš„ãƒãƒƒãƒæ•°: {statistics['summary']['total_potential_projects']}ä»¶")
        print(f"è¦‹è½ã¨ã—: +{statistics['summary']['improvement_absolute']}ä»¶ ({statistics['summary']['improvement_percentage']:.1f}%)")
        print(f"å®Ÿè¡Œæ™‚é–“: {elapsed:.1f}ç§’")
        print(f"å‡ºåŠ›å…ˆ: {self.output_dir}")
        print(f"{'='*60}")
        
        return analysis, missed_analysis, statistics


if __name__ == "__main__":
    investigator = AIMatchInvestigator()
    investigator.run()