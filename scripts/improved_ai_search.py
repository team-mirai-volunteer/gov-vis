#!/usr/bin/env python3
"""
æ”¹å–„ã•ã‚ŒãŸAIæ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ 
èª¿æŸ»çµæœã«åŸºã¥ãåŒ…æ‹¬çš„ãªAIé–¢é€£äº‹æ¥­æ¤œç´¢
"""
import pandas as pd
import json
import re
from pathlib import Path
from typing import Dict, List, Set, Any
from collections import defaultdict, Counter
import time


class ImprovedAISearcher:
    """æ”¹å–„ã•ã‚ŒãŸAIæ¤œç´¢ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, feather_dir: str = "data/normalized_feather"):
        self.feather_dir = Path(feather_dir)
        self.output_dir = Path("data/improved_ai_search")
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # æ”¹å–„ã•ã‚ŒãŸAIæ¤œç´¢ãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆèª¿æŸ»çµæœã«åŸºã¥ãï¼‰
        self.ai_exact_patterns = [
            r'AI',           # åŸºæœ¬å½¢ï¼ˆå¢ƒç•Œåˆ¶é™ãªã—ï¼‰
            r'ï¼¡ï¼©',          # å…¨è§’
            r'A\.I\.',       # ç•¥è¨˜ï¼ˆåŠè§’ï¼‰
            r'ï¼¡\.ï¼©\.'       # ç•¥è¨˜ï¼ˆå…¨è§’ï¼‰
        ]
        
        # AIè¤‡åˆèªãƒ»æ´¾ç”Ÿèªãƒ‘ã‚¿ãƒ¼ãƒ³
        self.ai_compound_patterns = [
            r'ç”ŸæˆAI', r'ç”Ÿæˆï¼¡ï¼©',
            r'AI[ã‚¢-ãƒ³\w]*',  # AI+ä½•ã‹ï¼ˆAIæ­è¼‰ã€AIæ´»ç”¨ç­‰ï¼‰
            r'ï¼¡ï¼©[ã‚¢-ãƒ³\w]*',  # å…¨è§’ç‰ˆ
            r'[ã‚¢-ãƒ³\w]*AI',  # ä½•ã‹+AI
            r'[ã‚¢-ãƒ³\w]*ï¼¡ï¼©'   # å…¨è§’ç‰ˆ
        ]
        
        # å®Œå…¨ãªAIãƒ‘ã‚¿ãƒ¼ãƒ³ï¼ˆexact + compoundï¼‰
        self.all_ai_patterns = self.ai_exact_patterns + self.ai_compound_patterns
        
        self.tables_data = {}
        self.search_config = {}
        self.load_metadata()
    
    def load_metadata(self):
        """ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿"""
        metadata_path = self.feather_dir / 'ai_search_metadata.json'
        if metadata_path.exists():
            with open(metadata_path, 'r', encoding='utf-8') as f:
                metadata = json.load(f)
            self.search_config = metadata.get('ai_search_fields', {})
        else:
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š
            self.search_config = {
                'projects': ['äº‹æ¥­å', 'äº‹æ¥­ã®ç›®çš„', 'äº‹æ¥­ã®æ¦‚è¦', 'ç¾çŠ¶ãƒ»èª²é¡Œ'],
                'expenditure_info': ['æ”¯å‡ºå…ˆå', 'å¥‘ç´„æ¦‚è¦', 'è²»ç›®', 'ä½¿é€”'],
                'goals_performance': ['ã‚¢ã‚¯ãƒ†ã‚£ãƒ“ãƒ†ã‚£ï¼æ´»å‹•ç›®æ¨™ï¼æˆæœç›®æ¨™', 'æ´»å‹•æŒ‡æ¨™ï¼æˆæœæŒ‡æ¨™'],
                'expenditure_connections': ['æ”¯å‡ºå…ˆã®æ”¯å‡ºå…ˆãƒ–ãƒ­ãƒƒã‚¯å', 'è³‡é‡‘ã®æµã‚Œã®è£œè¶³æƒ…å ±'],
                'contracts': ['å¥‘ç´„å…ˆåï¼ˆå›½åº«å‚µå‹™è² æ‹…è¡Œç‚ºç­‰ã«ã‚ˆã‚‹å¥‘ç´„ï¼‰', 'å¥‘ç´„æ¦‚è¦ï¼ˆå¥‘ç´„åï¼‰ï¼ˆå›½åº«å‚µå‹™è² æ‹…è¡Œç‚ºç­‰ã«ã‚ˆã‚‹å¥‘ç´„ï¼‰']
            }
    
    def load_feather_tables(self):
        """Featherãƒ†ãƒ¼ãƒ–ãƒ«èª­ã¿è¾¼ã¿"""
        print("Loading Feather tables...")
        
        for table_name in self.search_config.keys():
            feather_path = self.feather_dir / f"{table_name}.feather"
            if feather_path.exists():
                print(f"  Loading: {table_name}")
                try:
                    df = pd.read_feather(feather_path)
                    self.tables_data[table_name] = df
                    print(f"    Records: {len(df):,}, Columns: {len(df.columns)}")
                except Exception as e:
                    print(f"    Error loading {table_name}: {e}")
            else:
                print(f"  Warning: {feather_path} not found")
        
        print(f"Loaded {len(self.tables_data)} tables")
    
    def compile_search_patterns(self, patterns: List[str]) -> List[re.Pattern]:
        """æ¤œç´¢ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«"""
        compiled_patterns = []
        for pattern in patterns:
            try:
                compiled = re.compile(pattern, re.IGNORECASE)
                compiled_patterns.append((pattern, compiled))
            except re.error as e:
                print(f"Warning: Invalid regex pattern '{pattern}': {e}")
        return compiled_patterns
    
    def search_text_with_patterns(self, text: str, compiled_patterns: List[tuple]) -> List[Dict]:
        """ãƒ†ã‚­ã‚¹ãƒˆå†…ã§ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’æ¤œç´¢ï¼ˆãƒãƒƒãƒè©³ç´°ä»˜ãï¼‰"""
        if not text or pd.isna(text):
            return []
        
        text_str = str(text)
        found_matches = []
        
        for pattern_name, pattern in compiled_patterns:
            matches = pattern.finditer(text_str)
            for match in matches:
                found_matches.append({
                    'pattern': pattern_name,
                    'matched_text': match.group(),
                    'start': match.start(),
                    'end': match.end()
                })
        
        return found_matches
    
    def search_table_for_ai(self, table_name: str, df: pd.DataFrame, compiled_patterns: List[tuple]) -> Dict[int, Dict]:
        """ãƒ†ãƒ¼ãƒ–ãƒ«å†…ã§AIé–¢é€£ç”¨èªã‚’æ¤œç´¢"""
        print(f"  Searching in {table_name}...")
        start_time = time.time()
        
        search_fields = self.search_config.get(table_name, [])
        available_fields = [f for f in search_fields if f in df.columns]
        
        if not available_fields:
            print(f"    No searchable fields in {table_name}")
            return {}
        
        results = {}
        processed_records = 0
        
        # äºˆç®—äº‹æ¥­IDã§ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã—ã¦æ¤œç´¢
        if 'äºˆç®—äº‹æ¥­ID' in df.columns:
            for project_id, group in df.groupby('äºˆç®—äº‹æ¥­ID'):
                project_matches = {}
                total_matches = 0
                all_found_patterns = set()
                all_matched_texts = set()
                
                # ã‚°ãƒ«ãƒ¼ãƒ—å†…ã®å„ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’æ¤œç´¢
                for idx, record in group.iterrows():
                    for field in available_fields:
                        text = record.get(field, '')
                        found_matches = self.search_text_with_patterns(text, compiled_patterns)
                        
                        if found_matches:
                            if field not in project_matches:
                                project_matches[field] = []
                            
                            for match in found_matches:
                                project_matches[field].append({
                                    'text': str(text)[:300],  # æœ€åˆã®300æ–‡å­—
                                    'pattern': match['pattern'],
                                    'matched_text': match['matched_text'],
                                    'record_index': idx,
                                    'position': f"{match['start']}-{match['end']}"
                                })
                                
                                all_found_patterns.add(match['pattern'])
                                all_matched_texts.add(match['matched_text'])
                                total_matches += 1
                
                if project_matches:
                    results[int(project_id)] = {
                        'project_id': int(project_id),
                        'table_name': table_name,
                        'matches': project_matches,
                        'total_matches': total_matches,
                        'matched_fields': list(project_matches.keys()),
                        'all_found_patterns': list(all_found_patterns),
                        'all_matched_texts': list(all_matched_texts),
                        'record_count': len(group)
                    }
                
                processed_records += len(group)
        
        elapsed = time.time() - start_time
        print(f"    Found {len(results)} projects with AI terms in {elapsed:.2f}s")
        
        return results
    
    def comprehensive_ai_search(self, compiled_patterns: List[tuple]) -> Dict[int, Dict]:
        """å…¨ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’å¯¾è±¡ã¨ã—ãŸåŒ…æ‹¬çš„AIæ¤œç´¢"""
        print("\\nComprehensive improved AI search across all tables...")
        
        all_results = defaultdict(lambda: {
            'project_id': 0,
            'tables_found': [],
            'total_matches': 0,
            'all_found_patterns': set(),
            'all_matched_texts': set(),
            'table_details': {}
        })
        
        # å„ãƒ†ãƒ¼ãƒ–ãƒ«ã§æ¤œç´¢
        for table_name, df in self.tables_data.items():
            table_results = self.search_table_for_ai(table_name, df, compiled_patterns)
            
            for project_id, result in table_results.items():
                # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆçµæœã‚’çµ±åˆ
                all_results[project_id]['project_id'] = project_id
                all_results[project_id]['tables_found'].append(table_name)
                all_results[project_id]['total_matches'] += result['total_matches']
                all_results[project_id]['all_found_patterns'].update(result['all_found_patterns'])
                all_results[project_id]['all_matched_texts'].update(result['all_matched_texts'])
                all_results[project_id]['table_details'][table_name] = result
        
        # set ã‚’ list ã«å¤‰æ›
        for project_id in all_results:
            all_results[project_id]['all_found_patterns'] = list(all_results[project_id]['all_found_patterns'])
            all_results[project_id]['all_matched_texts'] = list(all_results[project_id]['all_matched_texts'])
        
        return dict(all_results)
    
    def merge_with_project_master(self, search_results: Dict[int, Dict]) -> Dict[int, Dict]:
        """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒã‚¹ã‚¿ãƒ¼æƒ…å ±ã¨çµ±åˆ"""
        print("Merging with project master data...")
        
        if 'projects' not in self.tables_data:
            print("  Warning: Projects master table not available")
            return search_results
        
        projects_df = self.tables_data['projects']
        
        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’äºˆç®—äº‹æ¥­IDã«è¨­å®š
        if 'äºˆç®—äº‹æ¥­ID' in projects_df.columns:
            projects_indexed = projects_df.set_index('äºˆç®—äº‹æ¥­ID')
        else:
            projects_indexed = projects_df
        
        enhanced_results = {}
        
        for project_id, result in search_results.items():
            enhanced_result = result.copy()
            
            # ãƒã‚¹ã‚¿ãƒ¼æƒ…å ±ã‚’è¿½åŠ 
            if project_id in projects_indexed.index:
                master_info = projects_indexed.loc[project_id]
                enhanced_result['master_info'] = {
                    'äº‹æ¥­å': master_info.get('äº‹æ¥­å', ''),
                    'åºœçœåº': master_info.get('åºœçœåº', ''),
                    'å±€ãƒ»åº': master_info.get('å±€ãƒ»åº', ''),
                    'äº‹æ¥­ã®ç›®çš„': master_info.get('äº‹æ¥­ã®ç›®çš„', ''),
                    'äº‹æ¥­ã®æ¦‚è¦': master_info.get('äº‹æ¥­ã®æ¦‚è¦', ''),
                    'ç¾çŠ¶ãƒ»èª²é¡Œ': master_info.get('ç¾çŠ¶ãƒ»èª²é¡Œ', '')
                }
            else:
                enhanced_result['master_info'] = {}
            
            enhanced_results[project_id] = enhanced_result
        
        return enhanced_results
    
    def generate_search_statistics(self, exact_results: Dict, compound_results: Dict, all_results: Dict) -> Dict:
        """æ¤œç´¢çµ±è¨ˆã‚’ç”Ÿæˆ"""
        print("Generating improved search statistics...")
        
        # åŸºæœ¬çµ±è¨ˆ
        total_projects = len(self.tables_data.get('projects', pd.DataFrame()))
        
        # åºœçœåºåˆ¥çµ±è¨ˆ
        ministry_stats_exact = Counter()
        ministry_stats_compound = Counter()
        ministry_stats_all = Counter()
        
        for result in exact_results.values():
            ministry = result.get('master_info', {}).get('åºœçœåº', 'ä¸æ˜')
            ministry_stats_exact[ministry] += 1
        
        for result in compound_results.values():
            ministry = result.get('master_info', {}).get('åºœçœåº', 'ä¸æ˜')
            ministry_stats_compound[ministry] += 1
        
        for result in all_results.values():
            ministry = result.get('master_info', {}).get('åºœçœåº', 'ä¸æ˜')
            ministry_stats_all[ministry] += 1
        
        # ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ¥çµ±è¨ˆ
        pattern_stats_exact = Counter()
        pattern_stats_compound = Counter()
        pattern_stats_all = Counter()
        
        for result in exact_results.values():
            for pattern in result['all_found_patterns']:
                pattern_stats_exact[pattern] += 1
        
        for result in compound_results.values():
            for pattern in result['all_found_patterns']:
                pattern_stats_compound[pattern] += 1
        
        for result in all_results.values():
            for pattern in result['all_found_patterns']:
                pattern_stats_all[pattern] += 1
        
        # ãƒãƒƒãƒãƒ†ã‚­ã‚¹ãƒˆçµ±è¨ˆ
        matched_text_stats = Counter()
        for result in all_results.values():
            for text in result['all_matched_texts']:
                matched_text_stats[text] += 1
        
        statistics = {
            'summary': {
                'total_projects': total_projects,
                'ai_exact_projects': len(exact_results),
                'ai_compound_projects': len(compound_results),
                'ai_all_projects': len(all_results),
                'ai_exact_percentage': (len(exact_results) / total_projects * 100) if total_projects > 0 else 0,
                'ai_compound_percentage': (len(compound_results) / total_projects * 100) if total_projects > 0 else 0,
                'ai_all_percentage': (len(all_results) / total_projects * 100) if total_projects > 0 else 0
            },
            'ministry_distribution': {
                'ai_exact': dict(ministry_stats_exact.most_common(20)),
                'ai_compound': dict(ministry_stats_compound.most_common(20)),
                'ai_all': dict(ministry_stats_all.most_common(20))
            },
            'pattern_frequency': {
                'ai_exact': dict(pattern_stats_exact.most_common()),
                'ai_compound': dict(pattern_stats_compound.most_common()),
                'ai_all': dict(pattern_stats_all.most_common())
            },
            'matched_text_frequency': dict(matched_text_stats.most_common(50)),
            'improvement_analysis': {
                'old_exact_count': 57,  # èª¿æŸ»çµæœã‹ã‚‰
                'new_exact_count': len(exact_results),
                'improvement_absolute': len(exact_results) - 57,
                'improvement_percentage': ((len(exact_results) - 57) / 57 * 100) if 57 > 0 else 0
            }
        }
        
        return statistics
    
    def save_results(self, exact_results: Dict, compound_results: Dict, all_results: Dict, statistics: Dict):
        """çµæœã‚’ä¿å­˜"""
        print("Saving improved search results...")
        
        # AI exactæ¤œç´¢çµæœ
        exact_path = self.output_dir / 'ai_exact_improved.json'
        with open(exact_path, 'w', encoding='utf-8') as f:
            json.dump(exact_results, f, ensure_ascii=False, indent=2, default=str)
        print(f"  Saved: {exact_path} ({len(exact_results):,} projects)")
        
        # AIè¤‡åˆèªæ¤œç´¢çµæœ
        compound_path = self.output_dir / 'ai_compound_improved.json'
        with open(compound_path, 'w', encoding='utf-8') as f:
            json.dump(compound_results, f, ensure_ascii=False, indent=2, default=str)
        print(f"  Saved: {compound_path} ({len(compound_results):,} projects)")
        
        # AIåŒ…æ‹¬æ¤œç´¢çµæœ
        all_path = self.output_dir / 'ai_all_improved.json'
        with open(all_path, 'w', encoding='utf-8') as f:
            json.dump(all_results, f, ensure_ascii=False, indent=2, default=str)
        print(f"  Saved: {all_path} ({len(all_results):,} projects)")
        
        # çµ±è¨ˆãƒ¬ãƒãƒ¼ãƒˆ
        stats_path = self.output_dir / 'improved_search_statistics.json'
        with open(stats_path, 'w', encoding='utf-8') as f:
            json.dump(statistics, f, ensure_ascii=False, indent=2, default=str)
        print(f"  Saved: {stats_path}")
        
        # HTMLãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        self.generate_html_report(statistics)
    
    def generate_html_report(self, statistics: Dict):
        """HTMLãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        html_content = f"""<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <title>æ”¹å–„ã•ã‚ŒãŸAIæ¤œç´¢çµæœãƒ¬ãƒãƒ¼ãƒˆ</title>
    <style>
        body {{ font-family: 'Segoe UI', Arial, sans-serif; margin: 20px; line-height: 1.6; }}
        h1 {{ color: #28a745; text-align: center; border-bottom: 3px solid #28a745; padding-bottom: 10px; }}
        h2 {{ color: #333; border-bottom: 2px solid #ddd; padding-bottom: 5px; }}
        .improvement {{ background-color: #d4edda; border: 1px solid #c3e6cb; padding: 20px; border-radius: 8px; margin: 20px 0; }}
        .metric {{ font-size: 1.5em; font-weight: bold; text-align: center; margin: 10px 0; }}
        .success {{ color: #28a745; }}
        .old {{ color: #dc3545; }}
        table {{ border-collapse: collapse; width: 100%; margin: 20px 0; }}
        th, td {{ border: 1px solid #ddd; padding: 8px; text-align: left; }}
        th {{ background-color: #f2f2f2; }}
        .term-tag {{ background-color: #e1ecf4; padding: 2px 8px; border-radius: 12px; margin: 2px; display: inline-block; }}
        .highlight {{ background-color: #fff3cd; }}
    </style>
</head>
<body>
    <h1>ğŸš€ æ”¹å–„ã•ã‚ŒãŸAIæ¤œç´¢çµæœãƒ¬ãƒãƒ¼ãƒˆ</h1>
    
    <div class="improvement">
        <h2>ğŸ“ˆ æ¤œç´¢æ”¹å–„çµæœ</h2>
        <div class="metric old">æ—§ãƒ‘ã‚¿ãƒ¼ãƒ³: 57ä»¶</div>
        <div class="metric success">æ–°ãƒ‘ã‚¿ãƒ¼ãƒ³: {statistics['summary']['ai_exact_projects']}ä»¶</div>
        <div class="metric success">æ”¹å–„: +{statistics['improvement_analysis']['improvement_absolute']}ä»¶ ({statistics['improvement_analysis']['improvement_percentage']:.1f}%)</div>
    </div>
    
    <h2>ğŸ“Š æ¤œç´¢çµæœã‚µãƒãƒªãƒ¼</h2>
    <table>
        <tr>
            <th>æ¤œç´¢ã‚«ãƒ†ã‚´ãƒª</th>
            <th>äº‹æ¥­æ•°</th>
            <th>å‰²åˆ</th>
            <th>èª¬æ˜</th>
        </tr>
        <tr class="highlight">
            <td><strong>AI Exact</strong></td>
            <td class="success">{statistics['summary']['ai_exact_projects']}</td>
            <td class="success">{statistics['summary']['ai_exact_percentage']:.2f}%</td>
            <td>AIã€ï¼¡ï¼©ã€A.I.ç­‰ã®åŸºæœ¬å½¢</td>
        </tr>
        <tr>
            <td><strong>AIè¤‡åˆèª</strong></td>
            <td>{statistics['summary']['ai_compound_projects']}</td>
            <td>{statistics['summary']['ai_compound_percentage']:.2f}%</td>
            <td>ç”ŸæˆAIã€AIæ­è¼‰ç­‰ã®è¤‡åˆèª</td>
        </tr>
        <tr>
            <td><strong>AIå…¨ä½“</strong></td>
            <td>{statistics['summary']['ai_all_projects']}</td>
            <td>{statistics['summary']['ai_all_percentage']:.2f}%</td>
            <td>ã™ã¹ã¦ã®AIé–¢é€£ãƒ‘ã‚¿ãƒ¼ãƒ³</td>
        </tr>
    </table>
    
    <h2>ğŸ¢ åºœçœåºåˆ¥åˆ†å¸ƒï¼ˆAI Exactï¼‰</h2>
    <table>
        <tr><th>åºœçœåº</th><th>äº‹æ¥­æ•°</th></tr>"""
        
        for ministry, count in list(statistics['ministry_distribution']['ai_exact'].items())[:15]:
            html_content += f"        <tr><td>{ministry}</td><td>{count}</td></tr>\\n"
        
        html_content += f"""
    </table>
    
    <h2>ğŸ” æ¤œå‡ºãƒ‘ã‚¿ãƒ¼ãƒ³é »åº¦</h2>
    <div style="display: flex; flex-wrap: wrap; gap: 5px;">"""
        
        for pattern, count in list(statistics['pattern_frequency']['ai_exact'].items())[:20]:
            html_content += f'        <span class="term-tag">{pattern} ({count})</span>\\n'
        
        html_content += f"""
    </div>
    
    <h2>ğŸ“ å®Ÿéš›ã®ãƒãƒƒãƒãƒ†ã‚­ã‚¹ãƒˆï¼ˆä¸Šä½20ï¼‰</h2>
    <div style="display: flex; flex-wrap: wrap; gap: 5px;">"""
        
        for text, count in list(statistics['matched_text_frequency'].items())[:20]:
            html_content += f'        <span class="term-tag">{text} ({count})</span>\\n'
        
        html_content += f"""
    </div>
    
    <div style="margin-top: 40px; text-align: center; color: #666;">
        Generated by Improved AI Searcher
    </div>
</body>
</html>"""
        
        html_path = self.output_dir / 'improved_search_report.html'
        with open(html_path, 'w', encoding='utf-8') as f:
            f.write(html_content)
        print(f"  Saved: {html_path}")
    
    def run(self):
        """æ”¹å–„ã•ã‚ŒãŸAIæ¤œç´¢ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ"""
        print("=" * 60)
        print("ğŸ” Improved AI Search System")
        print("=" * 60)
        
        total_start = time.time()
        
        # 1. Featherãƒ†ãƒ¼ãƒ–ãƒ«èª­ã¿è¾¼ã¿
        self.load_feather_tables()
        
        if not self.tables_data:
            print("No tables loaded. Exiting.")
            return
        
        # 2. æ¤œç´¢ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«
        print("\\nCompiling improved search patterns...")
        exact_patterns = self.compile_search_patterns(self.ai_exact_patterns)
        compound_patterns = self.compile_search_patterns(self.ai_compound_patterns)
        all_patterns = self.compile_search_patterns(self.all_ai_patterns)
        
        print(f"  AI exact patterns: {len(exact_patterns)}")
        print(f"  AI compound patterns: {len(compound_patterns)}")
        print(f"  All AI patterns: {len(all_patterns)}")
        
        # 3. AI exactæ¤œç´¢
        print("\\n" + "="*50)
        print("ğŸ¯ AI EXACT SEARCH (Improved)")
        print("="*50)
        exact_results = self.comprehensive_ai_search(exact_patterns)
        exact_enhanced = self.merge_with_project_master(exact_results)
        
        # 4. AIè¤‡åˆèªæ¤œç´¢
        print("\\n" + "="*50)
        print("ğŸ”§ AI COMPOUND SEARCH")
        print("="*50)
        compound_results = self.comprehensive_ai_search(compound_patterns)
        compound_enhanced = self.merge_with_project_master(compound_results)
        
        # 5. AIåŒ…æ‹¬æ¤œç´¢
        print("\\n" + "="*50)
        print("ğŸš€ AI ALL COMPREHENSIVE SEARCH")
        print("="*50)
        all_results = self.comprehensive_ai_search(all_patterns)
        all_enhanced = self.merge_with_project_master(all_results)
        
        # 6. çµ±è¨ˆç”Ÿæˆ
        statistics = self.generate_search_statistics(exact_enhanced, compound_enhanced, all_enhanced)
        
        # 7. çµæœä¿å­˜
        self.save_results(exact_enhanced, compound_enhanced, all_enhanced, statistics)
        
        total_elapsed = time.time() - total_start
        
        # æœ€çµ‚çµæœè¡¨ç¤º
        print(f"\\n{'='*60}")
        print("ğŸ‰ æ”¹å–„ã•ã‚ŒãŸæ¤œç´¢å®Œäº†!")
        print(f"{'='*60}")
        print(f"â±ï¸  å®Ÿè¡Œæ™‚é–“: {total_elapsed:.1f}ç§’")
        print(f"ğŸ¯ AI Exact: {len(exact_enhanced):,}ä»¶ (æ—§:57ä»¶ â†’ æ”¹å–„:+{len(exact_enhanced)-57}ä»¶)")
        print(f"ğŸ”§ AIè¤‡åˆèª: {len(compound_enhanced):,}ä»¶")
        print(f"ğŸš€ AIåŒ…æ‹¬: {len(all_enhanced):,}ä»¶")
        print(f"ğŸ“Š æ”¹å–„ç‡: {((len(exact_enhanced)-57)/57*100):.1f}%" if len(exact_enhanced) > 57 else "0%")
        print(f"ğŸ“ å‡ºåŠ›å…ˆ: {self.output_dir}")
        print(f"{'='*60}")
        
        return exact_enhanced, compound_enhanced, all_enhanced, statistics


if __name__ == "__main__":
    searcher = ImprovedAISearcher()
    searcher.run()