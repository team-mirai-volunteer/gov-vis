#!/usr/bin/env python3
"""
Featherå½¢å¼ãƒ‡ãƒ¼ã‚¿ã‚’ä½¿ã£ãŸé«˜é€ŸAIæ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ 
æ­£è¦åŒ–ã•ã‚ŒãŸãƒ†ãƒ¼ãƒ–ãƒ«æ§‹é€ ã§åŒ…æ‹¬çš„ãªAIé–¢é€£äº‹æ¥­æ¤œç´¢
"""
import pandas as pd
import json
import re
from pathlib import Path
from typing import Dict, List, Set, Any
from collections import defaultdict, Counter
import time


class FeatherAISearcher:
    """Featherå½¢å¼ãƒ‡ãƒ¼ã‚¿ã§ã®AIæ¤œç´¢ã‚¯ãƒ©ã‚¹"""
    
    def __init__(self, feather_dir: str = "data/normalized_feather"):
        self.feather_dir = Path(feather_dir)
        self.output_dir = Path("data/ai_analysis_feather")
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        # AIé–¢é€£ç”¨èªå®šç¾©ï¼ˆåŒ…æ‹¬çš„ï¼‰
        self.ai_broad_terms = [
            # åŸºæœ¬AIç”¨èª
            r'\bAI\b', r'\bA\.I\.\b', r'äººå·¥çŸ¥èƒ½', r'ã˜ã‚“ã“ã†ã¡ã®ã†',
            
            # æ©Ÿæ¢°å­¦ç¿’é–¢é€£
            r'æ©Ÿæ¢°å­¦ç¿’', r'ãã‹ã„ãŒãã—ã‚…ã†', r'ãƒã‚·ãƒ³ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°', r'\bML\b',
            r'æ·±å±¤å­¦ç¿’', r'ã—ã‚“ãã†ãŒãã—ã‚…ã†', r'ãƒ‡ã‚£ãƒ¼ãƒ—ãƒ©ãƒ¼ãƒ‹ãƒ³ã‚°', r'Deep Learning',
            r'ãƒ‹ãƒ¥ãƒ¼ãƒ©ãƒ«ãƒãƒƒãƒˆãƒ¯ãƒ¼ã‚¯', r'Neural Network', r'\bNN\b',
            
            # è‡ªç„¶è¨€èªå‡¦ç†
            r'è‡ªç„¶è¨€èªå‡¦ç†', r'ã—ãœã‚“ã’ã‚“ã”ã—ã‚‡ã‚Š', r'\bNLP\b', r'Natural Language Processing',
            r'ãƒ†ã‚­ã‚¹ãƒˆãƒã‚¤ãƒ‹ãƒ³ã‚°', r'Text Mining',
            
            # ãƒ‡ãƒ¼ã‚¿åˆ†æãƒ»äºˆæ¸¬
            r'ãƒ“ãƒƒã‚°ãƒ‡ãƒ¼ã‚¿', r'Big Data', r'ãƒ“ãƒƒã‚°ãƒ»ãƒ‡ãƒ¼ã‚¿',
            r'ãƒ‡ãƒ¼ã‚¿ãƒã‚¤ãƒ‹ãƒ³ã‚°', r'Data Mining', r'ãƒ‡ãƒ¼ã‚¿è§£æ', r'ãƒ‡ãƒ¼ã‚¿åˆ†æ',
            r'äºˆæ¸¬åˆ†æ', r'äºˆæ¸¬ãƒ¢ãƒ‡ãƒ«', r'ã‚¢ãƒ«ã‚´ãƒªã‚ºãƒ ', r'Algorithm',
            r'çµ±è¨ˆçš„å­¦ç¿’', r'ãƒ‘ã‚¿ãƒ¼ãƒ³èªè­˜',
            
            # è‡ªå‹•åŒ–ãƒ»ãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹
            r'RPA', r'Robotic Process Automation', r'ãƒ­ãƒœãƒ†ã‚£ãƒƒã‚¯ãƒ»ãƒ—ãƒ­ã‚»ã‚¹ãƒ»ã‚ªãƒ¼ãƒˆãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³',
            r'è‡ªå‹•åŒ–', r'ã˜ã©ã†ã‹', r'ã‚ªãƒ¼ãƒˆãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³', r'Automation',
            r'ãƒ­ãƒœãƒƒãƒˆ', r'Robot', r'ãƒ­ãƒœãƒ†ã‚£ã‚¯ã‚¹', r'Robotics',
            
            # IoTãƒ»ã‚¹ãƒãƒ¼ãƒˆæŠ€è¡“
            r'IoT', r'Internet of Things', r'ãƒ¢ãƒã®ã‚¤ãƒ³ã‚¿ãƒ¼ãƒãƒƒãƒˆ',
            r'ã‚¹ãƒãƒ¼ãƒˆ', r'Smart', r'ã‚¤ãƒ³ãƒ†ãƒªã‚¸ã‚§ãƒ³ãƒˆ', r'Intelligent',
            r'ã‚»ãƒ³ã‚µãƒ¼', r'Sensor', r'ã‚»ãƒ³ã‚·ãƒ³ã‚°',
            
            # DXãƒ»ãƒ‡ã‚¸ã‚¿ãƒ«å¤‰é©
            r'DX', r'ãƒ‡ã‚¸ã‚¿ãƒ«ãƒˆãƒ©ãƒ³ã‚¹ãƒ•ã‚©ãƒ¼ãƒ¡ãƒ¼ã‚·ãƒ§ãƒ³', r'Digital Transformation', 
            r'ãƒ‡ã‚¸ã‚¿ãƒ«å¤‰é©', r'ãƒ‡ã‚¸ã‚¿ãƒ«åŒ–',
            
            # AIå¿œç”¨åˆ†é‡
            r'ç”»åƒèªè­˜', r'ãŒãã†ã«ã‚“ã—ã', r'Image Recognition', r'ã‚³ãƒ³ãƒ”ãƒ¥ãƒ¼ã‚¿ãƒ“ã‚¸ãƒ§ãƒ³', r'Computer Vision',
            r'éŸ³å£°èªè­˜', r'ãŠã‚“ã›ã„ã«ã‚“ã—ã', r'Voice Recognition', r'Speech Recognition',
            r'ãƒãƒ£ãƒƒãƒˆãƒœãƒƒãƒˆ', r'Chatbot', r'ãƒœãƒƒãƒˆ', r'\bBot\b',
            r'ãƒ¬ã‚³ãƒ¡ãƒ³ãƒ‰', r'Recommendation', r'æ¨è–¦ã‚·ã‚¹ãƒ†ãƒ ',
            
            # æœ€æ–°AIæŠ€è¡“
            r'ç”ŸæˆAI', r'Generative AI', r'ChatGPT', r'GPT', r'LLM', r'å¤§è¦æ¨¡è¨€èªãƒ¢ãƒ‡ãƒ«',
            r'Transformer', r'BERT', r'æ©Ÿæ¢°ç¿»è¨³', r'Machine Translation'
        ]
        
        self.ai_only_terms = [r'\bAI\b', r'\bA\.I\.\b']
        
        # ãƒ†ãƒ¼ãƒ–ãƒ«ãƒ»æ¤œç´¢ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰è¨­å®š
        self.search_config = {}
        self.tables_data = {}
        self.load_metadata()
    
    def load_metadata(self):
        """ãƒ¡ã‚¿ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿æ¤œç´¢è¨­å®šã‚’åˆæœŸåŒ–"""
        metadata_path = self.feather_dir / 'ai_search_metadata.json'
        if metadata_path.exists():
            with open(metadata_path, 'r', encoding='utf-8') as f:
                metadata = json.load(f)
            self.search_config = metadata.get('ai_search_fields', {})
        else:
            # ãƒ‡ãƒ•ã‚©ãƒ«ãƒˆè¨­å®š
            self.search_config = {
                'projects': ['äº‹æ¥­å', 'äº‹æ¥­ã®ç›®çš„', 'äº‹æ¥­ã®æ¦‚è¦', 'ç¾çŠ¶ãƒ»èª²é¡Œ'],
                'expenditure_info': ['æ”¯å‡ºå…ˆå', 'å¥‘ç´„æ¦‚è¦', 'è²»ç›®', 'ä½¿é€”'],
                'goals_performance': ['ã‚¢ã‚¯ãƒ†ã‚£ãƒ“ãƒ†ã‚£ï¼æ´»å‹•ç›®æ¨™ï¼æˆæœç›®æ¨™', 'æ´»å‹•æŒ‡æ¨™ï¼æˆæœæŒ‡æ¨™'],
                'expenditure_connections': ['æ”¯å‡ºå…ˆã®æ”¯å‡ºå…ˆãƒ–ãƒ­ãƒƒã‚¯å', 'è³‡é‡‘ã®æµã‚Œã®è£œè¶³æƒ…å ±'],
                'contracts': ['å¥‘ç´„å…ˆåï¼ˆå›½åº«å‚µå‹™è² æ‹…è¡Œç‚ºç­‰ã«ã‚ˆã‚‹å¥‘ç´„ï¼‰', 'å¥‘ç´„æ¦‚è¦ï¼ˆå¥‘ç´„åï¼‰ï¼ˆå›½åº«å‚µå‹™è² æ‹…è¡Œç‚ºç­‰ã«ã‚ˆã‚‹å¥‘ç´„ï¼‰']
            }
    
    def load_feather_tables(self):
        """Featherãƒ†ãƒ¼ãƒ–ãƒ«ã‚’èª­ã¿è¾¼ã¿"""
        print("Loading Feather tables...")
        
        for table_name in self.search_config.keys():
            feather_path = self.feather_dir / f"{table_name}.feather"
            if feather_path.exists():
                print(f"  Loading: {table_name}")
                try:
                    df = pd.read_feather(feather_path)
                    self.tables_data[table_name] = df
                    print(f"    Records: {len(df):,}, Columns: {len(df.columns)}")
                except Exception as e:
                    print(f"    Error loading {table_name}: {e}")
            else:
                print(f"  Warning: {feather_path} not found")
        
        print(f"Loaded {len(self.tables_data)} tables")
    
    def compile_search_patterns(self, terms: List[str]) -> List[re.Pattern]:
        """æ¤œç´¢ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚’ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«ï¼ˆé«˜é€ŸåŒ–ï¼‰"""
        compiled_patterns = []
        for term in terms:
            try:
                pattern = re.compile(term, re.IGNORECASE)
                compiled_patterns.append((term, pattern))
            except re.error as e:
                print(f"Warning: Invalid regex pattern '{term}': {e}")
        return compiled_patterns
    
    def search_text_with_patterns(self, text: str, compiled_patterns: List[tuple]) -> List[str]:
        """ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«æ¸ˆã¿ãƒ‘ã‚¿ãƒ¼ãƒ³ã§ãƒ†ã‚­ã‚¹ãƒˆæ¤œç´¢"""
        if not text or pd.isna(text):
            return []
        
        text_str = str(text)
        found_terms = []
        
        for term_name, pattern in compiled_patterns:
            if pattern.search(text_str):
                found_terms.append(term_name)
        
        return found_terms
    
    def search_table_for_ai(self, table_name: str, df: pd.DataFrame, compiled_patterns: List[tuple]) -> Dict[int, Dict]:
        """ãƒ†ãƒ¼ãƒ–ãƒ«å†…ã§AIé–¢é€£ç”¨èªã‚’æ¤œç´¢"""
        print(f"  Searching in {table_name}...")
        start_time = time.time()
        
        search_fields = self.search_config.get(table_name, [])
        available_fields = [f for f in search_fields if f in df.columns]
        
        if not available_fields:
            print(f"    No searchable fields in {table_name}")
            return {}
        
        results = {}
        processed_records = 0
        
        # äºˆç®—äº‹æ¥­IDã§ã‚°ãƒ«ãƒ¼ãƒ—åŒ–ã—ã¦æ¤œç´¢
        if 'äºˆç®—äº‹æ¥­ID' in df.columns:
            for project_id, group in df.groupby('äºˆç®—äº‹æ¥­ID'):
                project_matches = {}
                total_matches = 0
                all_found_terms = set()
                
                # ã‚°ãƒ«ãƒ¼ãƒ—å†…ã®å„ãƒ¬ã‚³ãƒ¼ãƒ‰ã‚’æ¤œç´¢
                for idx, record in group.iterrows():
                    for field in available_fields:
                        text = record.get(field, '')
                        found_terms = self.search_text_with_patterns(text, compiled_patterns)
                        
                        if found_terms:
                            if field not in project_matches:
                                project_matches[field] = []
                            
                            project_matches[field].append({
                                'text': str(text)[:300],  # æœ€åˆã®300æ–‡å­—
                                'found_terms': found_terms,
                                'record_index': idx
                            })
                            
                            total_matches += len(found_terms)
                            all_found_terms.update(found_terms)
                
                if project_matches:
                    results[int(project_id)] = {
                        'project_id': int(project_id),
                        'table_name': table_name,
                        'matches': project_matches,
                        'total_matches': total_matches,
                        'matched_fields': list(project_matches.keys()),
                        'all_found_terms': list(all_found_terms),
                        'record_count': len(group)
                    }
                
                processed_records += len(group)
        
        elapsed = time.time() - start_time
        print(f"    Found {len(results)} projects with AI terms in {elapsed:.2f}s")
        
        return results
    
    def comprehensive_ai_search(self, compiled_patterns: List[tuple]) -> Dict[int, Dict]:
        """å…¨ãƒ†ãƒ¼ãƒ–ãƒ«ã‚’å¯¾è±¡ã¨ã—ãŸåŒ…æ‹¬çš„AIæ¤œç´¢"""
        print("\nComprehensive AI search across all tables...")
        
        all_results = defaultdict(lambda: {
            'project_id': 0,
            'tables_found': [],
            'total_matches': 0,
            'all_found_terms': set(),
            'table_details': {}
        })
        
        # å„ãƒ†ãƒ¼ãƒ–ãƒ«ã§æ¤œç´¢
        for table_name, df in self.tables_data.items():
            table_results = self.search_table_for_ai(table_name, df, compiled_patterns)
            
            for project_id, result in table_results.items():
                # ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆçµæœã‚’çµ±åˆ
                all_results[project_id]['project_id'] = project_id
                all_results[project_id]['tables_found'].append(table_name)
                all_results[project_id]['total_matches'] += result['total_matches']
                all_results[project_id]['all_found_terms'].update(result['all_found_terms'])
                all_results[project_id]['table_details'][table_name] = result
        
        # set ã‚’ list ã«å¤‰æ›
        for project_id in all_results:
            all_results[project_id]['all_found_terms'] = list(all_results[project_id]['all_found_terms'])
        
        return dict(all_results)
    
    def merge_with_project_master(self, search_results: Dict[int, Dict]) -> Dict[int, Dict]:
        """ãƒ—ãƒ­ã‚¸ã‚§ã‚¯ãƒˆãƒã‚¹ã‚¿ãƒ¼æƒ…å ±ã¨çµ±åˆ"""
        print("Merging with project master data...")
        
        if 'projects' not in self.tables_data:
            print("  Warning: Projects master table not available")
            return search_results
        
        projects_df = self.tables_data['projects']
        
        # ã‚¤ãƒ³ãƒ‡ãƒƒã‚¯ã‚¹ã‚’äºˆç®—äº‹æ¥­IDã«è¨­å®šï¼ˆå¿…è¦ã«å¿œã˜ã¦ï¼‰
        if 'äºˆç®—äº‹æ¥­ID' in projects_df.columns:
            projects_indexed = projects_df.set_index('äºˆç®—äº‹æ¥­ID')
        else:
            projects_indexed = projects_df
        
        enhanced_results = {}
        
        for project_id, result in search_results.items():
            enhanced_result = result.copy()
            
            # ãƒã‚¹ã‚¿ãƒ¼æƒ…å ±ã‚’è¿½åŠ 
            if project_id in projects_indexed.index:
                master_info = projects_indexed.loc[project_id]
                enhanced_result['master_info'] = {
                    'äº‹æ¥­å': master_info.get('äº‹æ¥­å', ''),
                    'åºœçœåº': master_info.get('åºœçœåº', ''),
                    'å±€ãƒ»åº': master_info.get('å±€ãƒ»åº', ''),
                    'äº‹æ¥­ã®ç›®çš„': master_info.get('äº‹æ¥­ã®ç›®çš„', ''),
                    'äº‹æ¥­ã®æ¦‚è¦': master_info.get('äº‹æ¥­ã®æ¦‚è¦', ''),
                    'ç¾çŠ¶ãƒ»èª²é¡Œ': master_info.get('ç¾çŠ¶ãƒ»èª²é¡Œ', '')
                }
            else:
                enhanced_result['master_info'] = {}
            
            enhanced_results[project_id] = enhanced_result
        
        return enhanced_results
    
    def generate_search_statistics(self, broad_results: Dict, only_results: Dict) -> Dict:
        """æ¤œç´¢çµ±è¨ˆã‚’ç”Ÿæˆ"""
        print("Generating search statistics...")
        
        # åŸºæœ¬çµ±è¨ˆ
        total_projects = len(self.tables_data.get('projects', pd.DataFrame()))
        
        # åºœçœåºåˆ¥çµ±è¨ˆ
        ministry_stats_broad = Counter()
        ministry_stats_only = Counter()
        
        for result in broad_results.values():
            ministry = result.get('master_info', {}).get('åºœçœåº', 'ä¸æ˜')
            ministry_stats_broad[ministry] += 1
        
        for result in only_results.values():
            ministry = result.get('master_info', {}).get('åºœçœåº', 'ä¸æ˜')
            ministry_stats_only[ministry] += 1
        
        # ç”¨èªåˆ¥çµ±è¨ˆ
        term_stats_broad = Counter()
        term_stats_only = Counter()
        
        for result in broad_results.values():
            for term in result['all_found_terms']:
                term_stats_broad[term] += 1
        
        for result in only_results.values():
            for term in result['all_found_terms']:
                term_stats_only[term] += 1
        
        # ãƒ†ãƒ¼ãƒ–ãƒ«åˆ¥çµ±è¨ˆ
        table_stats_broad = Counter()
        table_stats_only = Counter()
        
        for result in broad_results.values():
            for table in result['tables_found']:
                table_stats_broad[table] += 1
        
        for result in only_results.values():
            for table in result['tables_found']:
                table_stats_only[table] += 1
        
        statistics = {
            'summary': {
                'total_projects': total_projects,
                'ai_broad_projects': len(broad_results),
                'ai_only_projects': len(only_results),
                'ai_broad_percentage': (len(broad_results) / total_projects * 100) if total_projects > 0 else 0,
                'ai_only_percentage': (len(only_results) / total_projects * 100) if total_projects > 0 else 0
            },
            'ministry_distribution': {
                'ai_broad': dict(ministry_stats_broad.most_common(20)),
                'ai_only': dict(ministry_stats_only.most_common(20))
            },
            'term_frequency': {
                'ai_broad': dict(term_stats_broad.most_common(30)),
                'ai_only': dict(term_stats_only.most_common(30))
            },
            'table_distribution': {
                'ai_broad': dict(table_stats_broad.most_common()),
                'ai_only': dict(table_stats_only.most_common())
            }
        }
        
        return statistics
    
    def save_results(self, broad_results: Dict, only_results: Dict, statistics: Dict):
        """çµæœã‚’ä¿å­˜"""
        print("Saving search results...")
        
        # AIé–¢é€£äº‹æ¥­ï¼ˆåºƒç¯„å›²ï¼‰
        broad_path = self.output_dir / 'ai_related_projects_feather.json'
        with open(broad_path, 'w', encoding='utf-8') as f:
            json.dump(broad_results, f, ensure_ascii=False, indent=2, default=str)
        print(f"  Saved: {broad_path} ({len(broad_results):,} projects)")
        
        # AIé–¢é€£äº‹æ¥­ï¼ˆé™å®šï¼‰
        only_path = self.output_dir / 'ai_only_projects_feather.json'
        with open(only_path, 'w', encoding='utf-8') as f:
            json.dump(only_results, f, ensure_ascii=False, indent=2, default=str)
        print(f"  Saved: {only_path} ({len(only_results):,} projects)")
        
        # çµ±è¨ˆãƒ¬ãƒãƒ¼ãƒˆ
        stats_path = self.output_dir / 'feather_search_statistics.json'
        with open(stats_path, 'w', encoding='utf-8') as f:
            json.dump(statistics, f, ensure_ascii=False, indent=2, default=str)
        print(f"  Saved: {stats_path}")
        
        # HTMLãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        self.generate_html_report(statistics)
    
    def generate_html_report(self, statistics: Dict):
        """HTMLãƒ¬ãƒãƒ¼ãƒˆã‚’ç”Ÿæˆ"""
        html_content = f"""<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <title>Feather AIæ¤œç´¢çµæœãƒ¬ãƒãƒ¼ãƒˆ</title>
    <style>
        body {{ font-family: 'Segoe UI', Arial, sans-serif; margin: 20px; line-height: 1.6; }}
        h1 {{ color: #2c5aa0; text-align: center; }}
        .summary {{ background-color: #e8f4f8; padding: 20px; border-radius: 8px; }}
        .number {{ font-weight: bold; color: #2c5aa0; font-size: 1.2em; }}
        .improvement {{ color: #28a745; font-weight: bold; }}
        table {{ border-collapse: collapse; width: 100%; margin: 20px 0; }}
        th, td {{ border: 1px solid #ddd; padding: 8px; text-align: left; }}
        th {{ background-color: #f2f2f2; }}
        .term-tag {{ background-color: #e1ecf4; padding: 2px 8px; border-radius: 12px; margin: 2px; display: inline-block; }}
    </style>
</head>
<body>
    <h1>ğŸš€ Feather AIæ¤œç´¢çµæœãƒ¬ãƒãƒ¼ãƒˆ</h1>
    
    <div class="summary">
        <h2>æ¤œç´¢çµæœã‚µãƒãƒªãƒ¼</h2>
        <p><strong>ç·äº‹æ¥­æ•°:</strong> <span class="number">{statistics['summary']['total_projects']:,}</span></p>
        <p><strong>AIé–¢é€£äº‹æ¥­ï¼ˆåºƒç¯„å›²ï¼‰:</strong> <span class="number improvement">{statistics['summary']['ai_broad_projects']:,}</span> 
           <span class="improvement">({statistics['summary']['ai_broad_percentage']:.2f}%)</span></p>
        <p><strong>AIé–¢é€£äº‹æ¥­ï¼ˆé™å®šï¼‰:</strong> <span class="number improvement">{statistics['summary']['ai_only_projects']:,}</span> 
           <span class="improvement">({statistics['summary']['ai_only_percentage']:.2f}%)</span></p>
    </div>
    
    <h2>åºœçœåºåˆ¥åˆ†å¸ƒï¼ˆAIé–¢é€£ãƒ»åºƒç¯„å›²ï¼‰</h2>
    <table>
        <tr><th>åºœçœåº</th><th>äº‹æ¥­æ•°</th></tr>
"""
        
        for ministry, count in list(statistics['ministry_distribution']['ai_broad'].items())[:15]:
            html_content += f"        <tr><td>{ministry}</td><td>{count}</td></tr>\n"
        
        html_content += """
    </table>
    
    <h2>AIç”¨èªæ¤œå‡ºé »åº¦ï¼ˆä¸Šä½20ï¼‰</h2>
    <div style="display: flex; flex-wrap: wrap; gap: 5px;">
"""
        
        for term, count in list(statistics['term_frequency']['ai_broad'].items())[:20]:
            html_content += f'        <span class="term-tag">{term} ({count})</span>\n'
        
        html_content += f"""
    </div>
    
    <h2>ãƒ†ãƒ¼ãƒ–ãƒ«åˆ¥æ¤œå‡ºåˆ†å¸ƒ</h2>
    <table>
        <tr><th>ãƒ†ãƒ¼ãƒ–ãƒ«</th><th>æ¤œå‡ºäº‹æ¥­æ•°</th></tr>
"""
        
        for table, count in statistics['table_distribution']['ai_broad'].items():
            html_content += f"        <tr><td>{table}</td><td>{count}</td></tr>\n"
        
        html_content += """
    </table>
    
    <div style="margin-top: 40px; text-align: center; color: #666;">
        Generated by Feather AI Searcher
    </div>
</body>
</html>"""
        
        html_path = self.output_dir / 'feather_search_report.html'
        with open(html_path, 'w', encoding='utf-8') as f:
            f.write(html_content)
        print(f"  Saved: {html_path}")
    
    def run(self):
        """åŒ…æ‹¬çš„AIæ¤œç´¢ãƒ‘ã‚¤ãƒ—ãƒ©ã‚¤ãƒ³å®Ÿè¡Œ"""
        print("=" * 60)
        print("ğŸ” Featheré«˜é€ŸAIæ¤œç´¢ã‚·ã‚¹ãƒ†ãƒ ")
        print("=" * 60)
        
        total_start = time.time()
        
        # 1. Featherãƒ†ãƒ¼ãƒ–ãƒ«èª­ã¿è¾¼ã¿
        self.load_feather_tables()
        
        if not self.tables_data:
            print("No tables loaded. Exiting.")
            return
        
        # 2. æ¤œç´¢ãƒ‘ã‚¿ãƒ¼ãƒ³ã‚³ãƒ³ãƒ‘ã‚¤ãƒ«
        print("\nCompiling search patterns...")
        broad_patterns = self.compile_search_patterns(self.ai_broad_terms)
        only_patterns = self.compile_search_patterns(self.ai_only_terms)
        print(f"  Broad search: {len(broad_patterns)} patterns")
        print(f"  AI-only search: {len(only_patterns)} patterns")
        
        # 3. åŒ…æ‹¬çš„AIæ¤œç´¢ï¼ˆåºƒç¯„å›²ï¼‰
        print("\n" + "="*50)
        print("ğŸ” BROAD AI SEARCH")
        print("="*50)
        broad_results = self.comprehensive_ai_search(broad_patterns)
        broad_enhanced = self.merge_with_project_master(broad_results)
        
        # 4. AIé™å®šæ¤œç´¢
        print("\n" + "="*50)
        print("ğŸ¯ AI-ONLY SEARCH")
        print("="*50)
        only_results = self.comprehensive_ai_search(only_patterns)
        only_enhanced = self.merge_with_project_master(only_results)
        
        # 5. çµ±è¨ˆç”Ÿæˆ
        statistics = self.generate_search_statistics(broad_enhanced, only_enhanced)
        
        # 6. çµæœä¿å­˜
        self.save_results(broad_enhanced, only_enhanced, statistics)
        
        total_elapsed = time.time() - total_start
        
        # æœ€çµ‚çµæœè¡¨ç¤º
        print(f"\n{'='*60}")
        print("ğŸ‰ æ¤œç´¢å®Œäº†!")
        print(f"{'='*60}")
        print(f"â±ï¸  å®Ÿè¡Œæ™‚é–“: {total_elapsed:.1f}ç§’")
        print(f"ğŸ” AIé–¢é€£äº‹æ¥­ï¼ˆåºƒç¯„å›²ï¼‰: {len(broad_enhanced):,}ä»¶")
        print(f"ğŸ¯ AIé–¢é€£äº‹æ¥­ï¼ˆé™å®šï¼‰: {len(only_enhanced):,}ä»¶")
        print(f"ğŸ“Š æ¤œç´¢å¯¾è±¡ãƒ†ãƒ¼ãƒ–ãƒ«: {len(self.tables_data)}")
        print(f"ğŸ“ å‡ºåŠ›å…ˆ: {self.output_dir}")
        print(f"{'='*60}")
        
        return broad_enhanced, only_enhanced, statistics


if __name__ == "__main__":
    searcher = FeatherAISearcher()
    searcher.run()