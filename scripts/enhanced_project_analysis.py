#!/usr/bin/env python3
"""
å¼·åŒ–ç‰ˆäº‹æ¥­ãƒã‚¹ã‚¿ãƒ¼ãƒªã‚¹ãƒˆè¨˜è¿°çµ±è¨ˆåˆ†æ
æ·±ã„æ´å¯Ÿã¨ãƒã‚°ä¿®æ­£ã‚’å«ã‚€åŒ…æ‹¬çš„ãªåˆ†æ
"""
import pandas as pd
import numpy as np
import json
from pathlib import Path
from typing import Dict, List, Any, Tuple
import warnings
import re
from collections import Counter
warnings.filterwarnings('ignore')

# å¯è¦–åŒ–ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®æ¡ä»¶ä»˜ãã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    import matplotlib.pyplot as plt
    import seaborn as sns
    plt.rcParams['font.family'] = 'DejaVu Sans'
    sns.set_style("whitegrid")
    sns.set_palette("husl")
    VISUALIZATION_AVAILABLE = True
except ImportError:
    VISUALIZATION_AVAILABLE = False
    print("âš ï¸ å¯è¦–åŒ–ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚ãƒ†ã‚­ã‚¹ãƒˆãƒ™ãƒ¼ã‚¹ã®åˆ†æã®ã¿å®Ÿè¡Œã—ã¾ã™ã€‚")


class EnhancedProjectAnalyzer:
    """å¼·åŒ–ç‰ˆäº‹æ¥­ãƒã‚¹ã‚¿ãƒ¼ãƒªã‚¹ãƒˆåˆ†æã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.data_dir = Path("data")
        self.project_master_path = self.data_dir / "project_master" / "rs_project_master_with_details.feather"
        self.output_dir = self.data_dir / "enhanced_project_analysis"
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        self.df = None
        self.analysis_results = {}
        self.insights = []
        
        # åˆ†æå¯¾è±¡ã®åˆ—å®šç¾©
        self.count_cols = [
            'budget_summary_count', 'budget_items_count', 'goals_performance_count',
            'goal_connections_count', 'evaluations_count', 'expenditure_info_count',
            'expenditure_connections_count', 'expenditure_details_count', 'contracts_count'
        ]
        
        self.json_cols = [
            'budget_summary_json', 'budget_items_json', 'goals_performance_json',
            'goal_connections_json', 'evaluations_json', 'expenditure_info_json',
            'expenditure_connections_json', 'expenditure_details_json', 'contracts_json'
        ]
    
    def load_data(self):
        """ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿"""
        print("\n" + "="*80)
        print("å¼·åŒ–ç‰ˆãƒ‡ãƒ¼ã‚¿åˆ†æé–‹å§‹")
        print("="*80)
        
        if not self.project_master_path.exists():
            raise FileNotFoundError(f"äº‹æ¥­ãƒã‚¹ã‚¿ãƒ¼ãƒªã‚¹ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {self.project_master_path}")
        
        try:
            self.df = pd.read_feather(self.project_master_path)
            print(f"âœ“ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†: {len(self.df):,}è¡Œ Ã— {len(self.df.columns)}åˆ—")
            print(f"  - äº‹æ¥­æ•°: {len(self.df):,}")
            print(f"  - åˆ—æ•°: {len(self.df.columns)}")
            print(f"  - ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {self.df.memory_usage(deep=True).sum() / 1024**2:.1f} MB")
            
            return True
            
        except Exception as e:
            print(f"âœ— ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def basic_statistics(self):
        """ä¿®æ­£ã•ã‚ŒãŸåŸºæœ¬çµ±è¨ˆåˆ†æ"""
        print("\n" + "="*80)
        print("1. åŸºæœ¬çµ±è¨ˆåˆ†æï¼ˆä¿®æ­£ç‰ˆï¼‰")
        print("="*80)
        
        basic_stats = {
            'total_projects': len(self.df),
            'total_columns': len(self.df.columns),
            'missing_values': self.df.isnull().sum().sum(),
            'data_completeness': (1 - self.df.isnull().sum().sum() / (len(self.df) * len(self.df.columns))) * 100
        }
        
        print(f"åŸºæœ¬çµ±è¨ˆ:")
        print(f"  - ç·äº‹æ¥­æ•°: {basic_stats['total_projects']:,}")
        print(f"  - ç·åˆ—æ•°: {basic_stats['total_columns']}")
        print(f"  - æ¬ æå€¤æ•°: {basic_stats['missing_values']:,}")
        print(f"  - ãƒ‡ãƒ¼ã‚¿å®Œå…¨æ€§: {basic_stats['data_completeness']:.1f}%")
        
        self.analysis_results['basic_statistics'] = basic_stats
        return basic_stats
    
    def ministry_analysis_fixed(self):
        """ä¿®æ­£ã•ã‚ŒãŸåºœçœåºåˆ¥åˆ†æ"""
        print("\nåºœçœåºåˆ¥åˆ†æï¼ˆä¿®æ­£ç‰ˆï¼‰:")
        
        ministry_counts = self.df['åºœçœåº'].value_counts()
        
        analysis = {
            'total_ministries': len(ministry_counts),
            'total_projects': len(self.df),  # ä¿®æ­£: æ­£ç¢ºãªäº‹æ¥­ç·æ•°
            'ministry_distribution': ministry_counts.to_dict(),
            'top_10_ministries': ministry_counts.head(10).to_dict(),
            'ministry_stats': {
                'mean': ministry_counts.mean(),
                'median': ministry_counts.median(),
                'std': ministry_counts.std(),
                'max': ministry_counts.max(),
                'min': ministry_counts.min(),
                'concentration_ratio_top3': (ministry_counts.head(3).sum() / len(self.df)) * 100,
                'concentration_ratio_top5': (ministry_counts.head(5).sum() / len(self.df)) * 100
            }
        }
        
        print(f"  - åºœçœåºæ•°: {analysis['total_ministries']}")
        print(f"  - å¹³å‡äº‹æ¥­æ•°/åºœçœåº: {analysis['ministry_stats']['mean']:.1f}")
        print(f"  - ä¸Šä½3åºœçœåºé›†ä¸­ç‡: {analysis['ministry_stats']['concentration_ratio_top3']:.1f}%")
        print(f"  - ä¸Šä½5åºœçœåºé›†ä¸­ç‡: {analysis['ministry_stats']['concentration_ratio_top5']:.1f}%")
        
        print("  ä¸Šä½10åºœçœåºï¼ˆä¿®æ­£ç‰ˆï¼‰:")
        for i, (ministry, count) in enumerate(ministry_counts.head(10).items(), 1):
            percentage = (count / len(self.df)) * 100  # ä¿®æ­£: æ­£ã—ã„åˆ†æ¯
            print(f"    {i:2d}. {ministry}: {count:,}äº‹æ¥­ ({percentage:.1f}%)")
        
        self.analysis_results['ministry_analysis'] = analysis
        
        # ä¿®æ­£ã•ã‚ŒãŸInsight
        top_ministry = ministry_counts.index[0]
        top_count = ministry_counts.iloc[0]
        top_percentage = (top_count / len(self.df)) * 100
        
        self.insights.append(f"æœ€å¤šäº‹æ¥­åºœçœåºã¯{top_ministry}ã§{top_count:,}äº‹æ¥­({top_percentage:.1f}%)ã‚’å ã‚ã‚‹")
        self.insights.append(f"ä¸Šä½3åºœçœåºã§å…¨äº‹æ¥­ã®{analysis['ministry_stats']['concentration_ratio_top3']:.1f}%ã‚’å æœ‰ï¼ˆé›†ä¸­åº¦é«˜ï¼‰")
        
        return analysis
    
    def data_density_analysis_fixed(self):
        """ä¿®æ­£ã•ã‚ŒãŸãƒ‡ãƒ¼ã‚¿å¯†åº¦åˆ†æ"""
        print("\n" + "="*80)
        print("2. ãƒ‡ãƒ¼ã‚¿å¯†åº¦åˆ†æï¼ˆä¿®æ­£ç‰ˆï¼‰")
        print("="*80)
        
        data_availability = {}
        
        for col in self.count_cols:
            if col in self.df.columns:
                table_name = col.replace('_count', '')
                record_counts = self.df[col]
                has_data = record_counts > 0
                
                data_availability[table_name] = {
                    'projects_with_data': has_data.sum(),
                    'coverage_rate': (has_data.sum() / len(self.df)) * 100,
                    'avg_records_per_project': record_counts.mean(),
                    'median_records_per_project': record_counts.median(),
                    'max_records': record_counts.max(),
                    'std_records': record_counts.std(),
                    'total_records': record_counts.sum()
                }
        
        # Total related recordsã®åˆ†æ
        total_records_stats = {}
        if 'total_related_records' in self.df.columns:
            total_records = self.df['total_related_records']
            total_records_stats = {
                'mean': total_records.mean(),
                'median': total_records.median(),
                'std': total_records.std(),
                'min': total_records.min(),
                'max': total_records.max(),
                'percentiles': {
                    '25th': total_records.quantile(0.25),
                    '75th': total_records.quantile(0.75),
                    '90th': total_records.quantile(0.90),
                    '95th': total_records.quantile(0.95)
                }
            }
        
        analysis = {
            'data_availability': data_availability,
            'total_records_stats': total_records_stats
        }
        
        print("ãƒ†ãƒ¼ãƒ–ãƒ«åˆ¥ãƒ‡ãƒ¼ã‚¿è©³ç´°ï¼ˆä¿®æ­£ç‰ˆï¼‰:")
        for table_name, stats in data_availability.items():
            print(f"  {table_name}:")
            print(f"    - ãƒ‡ãƒ¼ã‚¿ä¿æœ‰ç‡: {stats['coverage_rate']:.1f}%")
            print(f"    - å¹³å‡ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {stats['avg_records_per_project']:.1f}")
            print(f"    - ä¸­å¤®å€¤: {stats['median_records_per_project']:.1f}")
            print(f"    - ç·ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {stats['total_records']:,}")
        
        self.analysis_results['data_density_analysis'] = analysis
        
        # ä¿®æ­£ã•ã‚ŒãŸInsightï¼šã‚ˆã‚Šæ„å‘³ã®ã‚ã‚‹æ¯”è¼ƒ
        highest_avg = max(data_availability.items(), key=lambda x: x[1]['avg_records_per_project'])
        lowest_avg = min(data_availability.items(), key=lambda x: x[1]['avg_records_per_project'])
        highest_total = max(data_availability.items(), key=lambda x: x[1]['total_records'])
        
        self.insights.append(f"{highest_avg[0]}ãŒæœ€é«˜ã®å¹³å‡ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°/äº‹æ¥­({highest_avg[1]['avg_records_per_project']:.1f})")
        self.insights.append(f"{lowest_avg[0]}ãŒæœ€ä½ã®å¹³å‡ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°/äº‹æ¥­({lowest_avg[1]['avg_records_per_project']:.1f})")
        self.insights.append(f"{highest_total[0]}ãŒæœ€å¤§ã®ç·ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°({highest_total[1]['total_records']:,})")
        
        return analysis
    
    def budget_pattern_analysis(self):
        """äºˆç®—è¦æ¨¡ãƒ»ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ"""
        print("\n" + "="*80)
        print("3. äºˆç®—è¦æ¨¡ãƒ»ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æï¼ˆæ–°è¦ï¼‰")
        print("="*80)
        
        budget_data = []
        budget_projects = []
        
        for idx, json_str in enumerate(self.df['budget_summary_json'].dropna()):
            try:
                if json_str and json_str != 'null':
                    records = json.loads(json_str)
                    if isinstance(records, list):
                        project_budgets = []
                        for record in records:
                            if isinstance(record, dict):
                                # ã‚ˆã‚ŠåŒ…æ‹¬çš„ãªäºˆç®—é¡æŠ½å‡º
                                for key, value in record.items():
                                    if any(budget_key in key for budget_key in 
                                          ['äºˆç®—', 'é‡‘é¡', 'é¡', 'åŸ·è¡Œ', 'è¦æ±‚', 'å½“åˆ', 'è£œæ­£']):
                                        if isinstance(value, (int, float)) and value > 0:
                                            project_budgets.append(value)
                                        elif isinstance(value, str):
                                            # æ•°å€¤æŠ½å‡ºã®æ”¹å–„
                                            numbers = re.findall(r'[\d,]+', str(value).replace(',', ''))
                                            for num_str in numbers:
                                                try:
                                                    num = float(num_str)
                                                    if 1000 <= num <= 1e12:  # ç¾å®Ÿçš„ãªç¯„å›²
                                                        project_budgets.append(num)
                                                except:
                                                    pass
                        
                        if project_budgets:
                            project_total = sum(project_budgets)
                            budget_data.append(project_total)
                            budget_projects.append({
                                'project_id': self.df.iloc[idx]['äºˆç®—äº‹æ¥­ID'],
                                'project_name': self.df.iloc[idx]['äº‹æ¥­å'],
                                'ministry': self.df.iloc[idx]['åºœçœåº'],
                                'total_budget': project_total,
                                'budget_records': len(project_budgets)
                            })
            except:
                continue
        
        if budget_data:
            budget_array = np.array(budget_data)
            # ç•°å¸¸å€¤é™¤å»ï¼ˆä¸Šä½ãƒ»ä¸‹ä½1%ï¼‰
            budget_clean = budget_array[
                (budget_array >= np.percentile(budget_array, 1)) &
                (budget_array <= np.percentile(budget_array, 99))
            ]
            
            analysis = {
                'total_projects_with_budget': len(budget_data),
                'budget_coverage': (len(budget_data) / len(self.df)) * 100,
                'budget_statistics': {
                    'mean': np.mean(budget_clean),
                    'median': np.median(budget_clean),
                    'std': np.std(budget_clean),
                    'min': np.min(budget_clean),
                    'max': np.max(budget_clean),
                    'q25': np.percentile(budget_clean, 25),
                    'q75': np.percentile(budget_clean, 75),
                    'q90': np.percentile(budget_clean, 90),
                    'q95': np.percentile(budget_clean, 95)
                },
                'budget_distribution': {
                    'small_projects': len([b for b in budget_clean if b < 1e8]),  # 1å„„æœªæº€
                    'medium_projects': len([b for b in budget_clean if 1e8 <= b < 1e9]),  # 1-10å„„
                    'large_projects': len([b for b in budget_clean if 1e9 <= b < 1e10]),  # 10-100å„„
                    'mega_projects': len([b for b in budget_clean if b >= 1e10])  # 100å„„ä»¥ä¸Š
                },
                'top_budget_projects': sorted(budget_projects, key=lambda x: x['total_budget'], reverse=True)[:10]
            }
            
            # åºœçœåºåˆ¥äºˆç®—åˆ†æ
            ministry_budgets = {}
            for project in budget_projects:
                ministry = project['ministry']
                if ministry not in ministry_budgets:
                    ministry_budgets[ministry] = []
                ministry_budgets[ministry].append(project['total_budget'])
            
            ministry_budget_stats = {}
            for ministry, budgets in ministry_budgets.items():
                if len(budgets) >= 3:  # 3äº‹æ¥­ä»¥ä¸Š
                    ministry_budget_stats[ministry] = {
                        'count': len(budgets),
                        'total': sum(budgets),
                        'mean': np.mean(budgets),
                        'median': np.median(budgets),
                        'max': max(budgets)
                    }
            
            analysis['ministry_budget_analysis'] = dict(sorted(
                ministry_budget_stats.items(), 
                key=lambda x: x[1]['total'], reverse=True
            )[:10])
            
            print(f"äºˆç®—åˆ†æçµæœ:")
            print(f"  - äºˆç®—ãƒ‡ãƒ¼ã‚¿æœ‰ã‚Š: {analysis['total_projects_with_budget']:,}/{len(self.df):,}äº‹æ¥­ ({analysis['budget_coverage']:.1f}%)")
            print(f"  - å¹³å‡äºˆç®—é¡: {analysis['budget_statistics']['mean']:,.0f}å††")
            print(f"  - ä¸­å¤®å€¤: {analysis['budget_statistics']['median']:,.0f}å††")
            print(f"  - æœ€å¤§: {analysis['budget_statistics']['max']:,.0f}å††")
            
            print(f"\näºˆç®—è¦æ¨¡åˆ¥åˆ†å¸ƒ:")
            print(f"  - å°è¦æ¨¡(1å„„æœªæº€): {analysis['budget_distribution']['small_projects']}äº‹æ¥­")
            print(f"  - ä¸­è¦æ¨¡(1-10å„„): {analysis['budget_distribution']['medium_projects']}äº‹æ¥­")
            print(f"  - å¤§è¦æ¨¡(10-100å„„): {analysis['budget_distribution']['large_projects']}äº‹æ¥­")
            print(f"  - è¶…å¤§è¦æ¨¡(100å„„ä»¥ä¸Š): {analysis['budget_distribution']['mega_projects']}äº‹æ¥­")
            
            print(f"\nåºœçœåºåˆ¥äºˆç®—è¦æ¨¡ï¼ˆä¸Šä½5ï¼‰:")
            for ministry, stats in list(analysis['ministry_budget_analysis'].items())[:5]:
                print(f"  {ministry}: ç·é¡{stats['total']:,.0f}å†† (å¹³å‡{stats['mean']:,.0f}å††, {stats['count']}äº‹æ¥­)")
            
            # Insightè¿½åŠ 
            mega_ratio = (analysis['budget_distribution']['mega_projects'] / len(budget_clean)) * 100
            top_ministry_budget = list(analysis['ministry_budget_analysis'].items())[0]
            
            self.insights.append(f"äºˆç®—ãƒ‡ãƒ¼ã‚¿å–å¾—ç‡{analysis['budget_coverage']:.1f}%ã€å¹³å‡{analysis['budget_statistics']['mean']/1e8:.1f}å„„å††/äº‹æ¥­")
            if mega_ratio > 1:
                self.insights.append(f"è¶…å¤§è¦æ¨¡äº‹æ¥­(100å„„å††ä»¥ä¸Š)ãŒ{mega_ratio:.1f}%å­˜åœ¨")
            self.insights.append(f"äºˆç®—ç·é¡æœ€å¤§ã¯{top_ministry_budget[0]}({top_ministry_budget[1]['total']/1e12:.1f}å…†å††)")
        
        else:
            analysis = {'error': 'äºˆç®—ãƒ‡ãƒ¼ã‚¿ã®æŠ½å‡ºã«å¤±æ•—'}
        
        self.analysis_results['budget_pattern_analysis'] = analysis
        return analysis
    
    def expenditure_diversity_analysis(self):
        """æ”¯å‡ºå¤šæ§˜æ€§ãƒ»è¤‡é›‘æ€§åˆ†æ"""
        print("\n" + "="*80)
        print("4. æ”¯å‡ºå¤šæ§˜æ€§ãƒ»è¤‡é›‘æ€§åˆ†æï¼ˆæ–°è¦ï¼‰")
        print("="*80)
        
        expenditure_diversity = []
        contract_complexity = []
        
        for idx, json_str in enumerate(self.df['expenditure_info_json'].dropna()):
            try:
                if json_str and json_str != 'null':
                    records = json.loads(json_str)
                    if isinstance(records, list):
                        entities = set()
                        amounts = []
                        contract_types = set()
                        
                        for record in records:
                            if isinstance(record, dict):
                                # æ”¯å‡ºå…ˆã®å¤šæ§˜æ€§
                                if 'æ”¯å‡ºå…ˆå' in record and record['æ”¯å‡ºå…ˆå']:
                                    entities.add(str(record['æ”¯å‡ºå…ˆå']).strip())
                                
                                # å¥‘ç´„æ–¹å¼ã®å¤šæ§˜æ€§
                                if 'å¥‘ç´„æ–¹å¼ç­‰' in record and record['å¥‘ç´„æ–¹å¼ç­‰']:
                                    contract_types.add(str(record['å¥‘ç´„æ–¹å¼ç­‰']).strip())
                                
                                # é‡‘é¡ãƒ‡ãƒ¼ã‚¿
                                for key, value in record.items():
                                    if 'é‡‘é¡' in key:
                                        if isinstance(value, (int, float)) and value > 0:
                                            amounts.append(value)
                        
                        if entities:
                            # ãƒãƒ¼ãƒ•ã‚£ãƒ³ãƒ€ãƒ¼ãƒ«æŒ‡æ•°ï¼ˆé›†ä¸­åº¦ï¼‰ã®è¨ˆç®—
                            total_amount = sum(amounts) if amounts else len(entities)
                            if total_amount > 0:
                                entity_weights = [1/len(entities)] * len(entities)  # ç°¡æ˜“ç‰ˆ
                                hhi = sum(w**2 for w in entity_weights)
                            else:
                                hhi = 1.0
                            
                            expenditure_diversity.append({
                                'project_id': self.df.iloc[idx]['äºˆç®—äº‹æ¥­ID'],
                                'project_name': self.df.iloc[idx]['äº‹æ¥­å'],
                                'ministry': self.df.iloc[idx]['åºœçœåº'],
                                'entity_count': len(entities),
                                'contract_type_count': len(contract_types),
                                'hhi': hhi,
                                'total_amount': sum(amounts) if amounts else 0
                            })
            except:
                continue
        
        if expenditure_diversity:
            entity_counts = [item['entity_count'] for item in expenditure_diversity]
            contract_counts = [item['contract_type_count'] for item in expenditure_diversity]
            hhi_values = [item['hhi'] for item in expenditure_diversity]
            
            analysis = {
                'total_analyzed_projects': len(expenditure_diversity),
                'entity_diversity_stats': {
                    'mean': np.mean(entity_counts),
                    'median': np.median(entity_counts),
                    'max': max(entity_counts),
                    'min': min(entity_counts),
                    'std': np.std(entity_counts)
                },
                'contract_diversity_stats': {
                    'mean': np.mean(contract_counts),
                    'median': np.median(contract_counts),
                    'max': max(contract_counts),
                    'std': np.std(contract_counts)
                },
                'concentration_stats': {
                    'mean_hhi': np.mean(hhi_values),
                    'median_hhi': np.median(hhi_values)
                },
                'complexity_categories': {
                    'simple': len([item for item in expenditure_diversity if item['entity_count'] <= 5]),
                    'moderate': len([item for item in expenditure_diversity if 5 < item['entity_count'] <= 20]),
                    'complex': len([item for item in expenditure_diversity if 20 < item['entity_count'] <= 50]),
                    'very_complex': len([item for item in expenditure_diversity if item['entity_count'] > 50])
                },
                'most_diverse_projects': sorted(expenditure_diversity, key=lambda x: x['entity_count'], reverse=True)[:5],
                'most_complex_contracts': sorted(expenditure_diversity, key=lambda x: x['contract_type_count'], reverse=True)[:5]
            }
            
            print(f"æ”¯å‡ºå¤šæ§˜æ€§åˆ†æçµæœ:")
            print(f"  - åˆ†æå¯¾è±¡äº‹æ¥­: {analysis['total_analyzed_projects']:,}")
            print(f"  - å¹³å‡æ”¯å‡ºå…ˆæ•°: {analysis['entity_diversity_stats']['mean']:.1f}")
            print(f"  - æœ€å¤§æ”¯å‡ºå…ˆæ•°: {analysis['entity_diversity_stats']['max']}")
            print(f"  - å¹³å‡å¥‘ç´„æ–¹å¼æ•°: {analysis['contract_diversity_stats']['mean']:.1f}")
            
            print(f"\näº‹æ¥­è¤‡é›‘æ€§åˆ†é¡:")
            total = len(expenditure_diversity)
            for category, count in analysis['complexity_categories'].items():
                percentage = (count / total) * 100
                print(f"  - {category}: {count}äº‹æ¥­ ({percentage:.1f}%)")
            
            print(f"\næœ€å¤šæ”¯å‡ºå…ˆäº‹æ¥­ãƒˆãƒƒãƒ—3:")
            for i, project in enumerate(analysis['most_diverse_projects'][:3], 1):
                print(f"  {i}. {project['project_name'][:50]}... ({project['ministry']}) - {project['entity_count']}å…ˆ")
            
            # Insightè¿½åŠ 
            complex_ratio = (analysis['complexity_categories']['complex'] + analysis['complexity_categories']['very_complex']) / total * 100
            most_diverse = analysis['most_diverse_projects'][0]
            
            self.insights.append(f"æ”¯å‡ºå…ˆæ•°ã®å¹³å‡{analysis['entity_diversity_stats']['mean']:.1f}ã€æœ€å¤§{analysis['entity_diversity_stats']['max']}å…ˆ")
            if complex_ratio > 10:
                self.insights.append(f"è¤‡é›‘ãªæ”¯å‡ºæ§‹é€ (20å…ˆä»¥ä¸Š)ã®äº‹æ¥­ãŒ{complex_ratio:.1f}%å­˜åœ¨")
            self.insights.append(f"æœ€å¤šæ”¯å‡ºå…ˆäº‹æ¥­ã€Œ{most_diverse['project_name'][:30]}...ã€({most_diverse['entity_count']}å…ˆ)")
        
        else:
            analysis = {'error': 'æ”¯å‡ºãƒ‡ãƒ¼ã‚¿ã®æŠ½å‡ºã«å¤±æ•—'}
        
        self.analysis_results['expenditure_diversity_analysis'] = analysis
        return analysis
    
    def temporal_trend_analysis(self):
        """æ™‚ç³»åˆ—ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æã®å¼·åŒ–"""
        print("\n" + "="*80)
        print("5. æ™‚ç³»åˆ—ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æï¼ˆå¼·åŒ–ç‰ˆï¼‰")
        print("="*80)
        
        if 'äº‹æ¥­é–‹å§‹å¹´åº¦' not in self.df.columns:
            print("äº‹æ¥­é–‹å§‹å¹´åº¦ãƒ‡ãƒ¼ã‚¿ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            return {}
        
        start_years = pd.to_numeric(self.df['äº‹æ¥­é–‹å§‹å¹´åº¦'], errors='coerce').dropna()
        
        # åºœçœåºåˆ¥ã®æ™‚ç³»åˆ—ãƒˆãƒ¬ãƒ³ãƒ‰
        ministry_temporal = {}
        for ministry in self.df['åºœçœåº'].value_counts().head(10).index:
            ministry_data = self.df[self.df['åºœçœåº'] == ministry]
            ministry_years = pd.to_numeric(ministry_data['äº‹æ¥­é–‹å§‹å¹´åº¦'], errors='coerce').dropna()
            
            if len(ministry_years) > 0:
                recent_ratio = len(ministry_years[ministry_years >= 2020]) / len(ministry_years) * 100
                ministry_temporal[ministry] = {
                    'total_projects': len(ministry_years),
                    'recent_projects_ratio': recent_ratio,
                    'mean_start_year': ministry_years.mean(),
                    'oldest_project': ministry_years.min(),
                    'newest_project': ministry_years.max()
                }
        
        # ãƒ‡ãƒ¼ã‚¿å¯†åº¦ã®å¹´ä»£å¤‰åŒ–
        density_by_decade = {}
        for decade in range(1990, 2030, 10):
            decade_projects = self.df[
                (pd.to_numeric(self.df['äº‹æ¥­é–‹å§‹å¹´åº¦'], errors='coerce') >= decade) &
                (pd.to_numeric(self.df['äº‹æ¥­é–‹å§‹å¹´åº¦'], errors='coerce') < decade + 10)
            ]
            
            if len(decade_projects) > 0:
                avg_density = decade_projects['total_related_records'].mean()
                density_by_decade[f"{decade}å¹´ä»£"] = {
                    'project_count': len(decade_projects),
                    'avg_data_density': avg_density,
                    'max_data_density': decade_projects['total_related_records'].max()
                }
        
        # äº‹æ¥­åŒºåˆ†ã®æ™‚ç³»åˆ—å¤‰åŒ–
        category_temporal = {}
        if 'äº‹æ¥­åŒºåˆ†' in self.df.columns:
            for category in self.df['äº‹æ¥­åŒºåˆ†'].unique():
                if pd.notna(category):
                    category_data = self.df[self.df['äº‹æ¥­åŒºåˆ†'] == category]
                    category_years = pd.to_numeric(category_data['äº‹æ¥­é–‹å§‹å¹´åº¦'], errors='coerce').dropna()
                    
                    if len(category_years) > 0:
                        category_temporal[category] = {
                            'count': len(category_years),
                            'mean_start_year': category_years.mean(),
                            'recent_ratio': len(category_years[category_years >= 2020]) / len(category_years) * 100
                        }
        
        analysis = {
            'overall_temporal_stats': {
                'min_year': int(start_years.min()),
                'max_year': int(start_years.max()),
                'mean_year': start_years.mean(),
                'recent_projects_ratio': len(start_years[start_years >= 2020]) / len(start_years) * 100,
                'decade_2020s_ratio': len(start_years[start_years >= 2020]) / len(start_years) * 100,
                'decade_2010s_ratio': len(start_years[(start_years >= 2010) & (start_years < 2020)]) / len(start_years) * 100,
                'decade_2000s_ratio': len(start_years[(start_years >= 2000) & (start_years < 2010)]) / len(start_years) * 100
            },
            'ministry_temporal_analysis': ministry_temporal,
            'density_by_decade': density_by_decade,
            'category_temporal_analysis': category_temporal
        }
        
        print(f"æ™‚ç³»åˆ—ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ:")
        print(f"  - äº‹æ¥­é–‹å§‹å¹´åº¦ç¯„å›²: {analysis['overall_temporal_stats']['min_year']}-{analysis['overall_temporal_stats']['max_year']}")
        print(f"  - 2020å¹´ä»£é–‹å§‹äº‹æ¥­: {analysis['overall_temporal_stats']['decade_2020s_ratio']:.1f}%")
        print(f"  - 2010å¹´ä»£é–‹å§‹äº‹æ¥­: {analysis['overall_temporal_stats']['decade_2010s_ratio']:.1f}%")
        
        print(f"\nåºœçœåºåˆ¥æœ€æ–°äº‹æ¥­æ¯”ç‡ï¼ˆ2020å¹´ä»¥é™ï¼‰:")
        sorted_ministries = sorted(ministry_temporal.items(), key=lambda x: x[1]['recent_projects_ratio'], reverse=True)
        for ministry, stats in sorted_ministries[:5]:
            print(f"  {ministry}: {stats['recent_projects_ratio']:.1f}% ({stats['total_projects']}äº‹æ¥­ä¸­)")
        
        print(f"\nå¹´ä»£åˆ¥ãƒ‡ãƒ¼ã‚¿å¯†åº¦å¤‰åŒ–:")
        for decade, stats in density_by_decade.items():
            print(f"  {decade}: å¹³å‡{stats['avg_data_density']:.1f}ãƒ¬ã‚³ãƒ¼ãƒ‰/äº‹æ¥­ ({stats['project_count']}äº‹æ¥­)")
        
        # Insightè¿½åŠ 
        most_recent_ministry = max(ministry_temporal.items(), key=lambda x: x[1]['recent_projects_ratio'])
        most_historic_ministry = min(ministry_temporal.items(), key=lambda x: x[1]['mean_start_year'])
        
        self.insights.append(f"2020å¹´ä»£äº‹æ¥­ãŒ{analysis['overall_temporal_stats']['decade_2020s_ratio']:.1f}%ï¼ˆæ–°è¦äº‹æ¥­ä¸­å¿ƒã®å‚¾å‘ï¼‰")
        self.insights.append(f"{most_recent_ministry[0]}ãŒæœ€ã‚‚æ–°ã—ã„äº‹æ¥­æ§‹æˆ({most_recent_ministry[1]['recent_projects_ratio']:.1f}%ãŒ2020å¹´ä»¥é™)")
        self.insights.append(f"{most_historic_ministry[0]}ãŒæœ€ã‚‚æ­´å²ã®é•·ã„äº‹æ¥­æ§‹æˆ(å¹³å‡{most_historic_ministry[1]['mean_start_year']:.0f}å¹´é–‹å§‹)")
        
        self.analysis_results['temporal_trend_analysis'] = analysis
        return analysis
    
    def anomaly_deep_dive(self):
        """ç‰¹ç•°äº‹æ¥­ã®æ·±æ˜ã‚Šåˆ†æ"""
        print("\n" + "="*80)
        print("6. ç‰¹ç•°äº‹æ¥­æ·±æ˜ã‚Šåˆ†æï¼ˆæ–°è¦ï¼‰")
        print("="*80)
        
        anomalies = {}
        
        # é«˜ãƒ‡ãƒ¼ã‚¿å¯†åº¦äº‹æ¥­ã®ç‰¹å¾´åˆ†æ
        if 'total_related_records' in self.df.columns:
            high_density_threshold = self.df['total_related_records'].quantile(0.95)
            high_density_projects = self.df[self.df['total_related_records'] >= high_density_threshold]
            
            # é«˜å¯†åº¦äº‹æ¥­ã®å…±é€šç‰¹å¾´
            ministry_distribution = high_density_projects['åºœçœåº'].value_counts()
            category_distribution = high_density_projects.get('äº‹æ¥­åŒºåˆ†', pd.Series()).value_counts()
            
            # å®Ÿæ–½æ–¹æ³•ã®ç‰¹å¾´
            implementation_cols = [col for col in self.df.columns if 'å®Ÿæ–½æ–¹æ³•' in col]
            implementation_features = {}
            for col in implementation_cols:
                if col in high_density_projects.columns:
                    ratio = (pd.to_numeric(high_density_projects[col], errors='coerce').fillna(0) > 0).mean()
                    implementation_features[col.replace('å®Ÿæ–½æ–¹æ³•ãƒ¼', '')] = ratio * 100
            
            anomalies['high_density_projects'] = {
                'threshold': high_density_threshold,
                'count': len(high_density_projects),
                'percentage': len(high_density_projects) / len(self.df) * 100,
                'ministry_concentration': ministry_distribution.to_dict(),
                'category_distribution': category_distribution.to_dict(),
                'implementation_methods': implementation_features,
                'top_projects': high_density_projects.nlargest(5, 'total_related_records')[
                    ['äº‹æ¥­å', 'åºœçœåº', 'total_related_records', 'äº‹æ¥­åŒºåˆ†']].to_dict('records')
            }
        
        # é•·æœŸäº‹æ¥­ã®åˆ†æ
        if 'äº‹æ¥­é–‹å§‹å¹´åº¦' in self.df.columns and 'äº‹æ¥­çµ‚äº†ï¼ˆäºˆå®šï¼‰å¹´åº¦' in self.df.columns:
            start_years = pd.to_numeric(self.df['äº‹æ¥­é–‹å§‹å¹´åº¦'], errors='coerce')
            end_years = pd.to_numeric(self.df['äº‹æ¥­çµ‚äº†ï¼ˆäºˆå®šï¼‰å¹´åº¦'], errors='coerce')
            
            project_duration = end_years - start_years
            long_projects = self.df[project_duration >= 20]  # 20å¹´ä»¥ä¸Š
            
            if len(long_projects) > 0:
                anomalies['long_duration_projects'] = {
                    'count': len(long_projects),
                    'percentage': len(long_projects) / len(self.df) * 100,
                    'avg_duration': project_duration[project_duration >= 20].mean(),
                    'max_duration': project_duration.max(),
                    'ministry_distribution': long_projects['åºœçœåº'].value_counts().to_dict(),
                    'examples': long_projects.nlargest(3, project_duration.reindex(long_projects.index))[
                        ['äº‹æ¥­å', 'åºœçœåº', 'äº‹æ¥­é–‹å§‹å¹´åº¦', 'äº‹æ¥­çµ‚äº†ï¼ˆäºˆå®šï¼‰å¹´åº¦']].to_dict('records')
                }
        
        # å¤šç›®æ¨™è¨­å®šäº‹æ¥­
        if 'goals_performance_count' in self.df.columns:
            high_goals_threshold = self.df['goals_performance_count'].quantile(0.9)
            high_goals_projects = self.df[self.df['goals_performance_count'] >= high_goals_threshold]
            
            anomalies['high_goals_projects'] = {
                'threshold': high_goals_threshold,
                'count': len(high_goals_projects),
                'avg_goals': high_goals_projects['goals_performance_count'].mean(),
                'max_goals': high_goals_projects['goals_performance_count'].max(),
                'ministry_distribution': high_goals_projects['åºœçœåº'].value_counts().to_dict(),
                'examples': high_goals_projects.nlargest(3, 'goals_performance_count')[
                    ['äº‹æ¥­å', 'åºœçœåº', 'goals_performance_count']].to_dict('records')
            }
        
        print(f"ç‰¹ç•°äº‹æ¥­åˆ†æ:")
        
        if 'high_density_projects' in anomalies:
            hdp = anomalies['high_density_projects']
            print(f"  é«˜ãƒ‡ãƒ¼ã‚¿å¯†åº¦äº‹æ¥­ï¼ˆ95%ileä»¥ä¸Šï¼‰:")
            print(f"    - è©²å½“äº‹æ¥­: {hdp['count']}äº‹æ¥­ ({hdp['percentage']:.1f}%)")
            print(f"    - é–¾å€¤: {hdp['threshold']:.0f}ãƒ¬ã‚³ãƒ¼ãƒ‰")
            print(f"    - ä¸»è¦åºœçœåº: {list(hdp['ministry_concentration'].keys())[:3]}")
        
        if 'long_duration_projects' in anomalies:
            ldp = anomalies['long_duration_projects']
            print(f"  é•·æœŸäº‹æ¥­ï¼ˆ20å¹´ä»¥ä¸Šï¼‰:")
            print(f"    - è©²å½“äº‹æ¥­: {ldp['count']}äº‹æ¥­ ({ldp['percentage']:.1f}%)")
            print(f"    - å¹³å‡æœŸé–“: {ldp['avg_duration']:.1f}å¹´")
            print(f"    - æœ€é•·: {ldp['max_duration']:.0f}å¹´")
        
        if 'high_goals_projects' in anomalies:
            hgp = anomalies['high_goals_projects']
            print(f"  å¤šç›®æ¨™è¨­å®šäº‹æ¥­ï¼ˆ90%ileä»¥ä¸Šï¼‰:")
            print(f"    - è©²å½“äº‹æ¥­: {hgp['count']}äº‹æ¥­")
            print(f"    - å¹³å‡ç›®æ¨™æ•°: {hgp['avg_goals']:.1f}")
            print(f"    - æœ€å¤§ç›®æ¨™æ•°: {hgp['max_goals']:.0f}")
        
        # Insightè¿½åŠ 
        if 'high_density_projects' in anomalies:
            top_ministry = list(anomalies['high_density_projects']['ministry_concentration'].keys())[0]
            self.insights.append(f"é«˜ãƒ‡ãƒ¼ã‚¿å¯†åº¦äº‹æ¥­ã®{anomalies['high_density_projects']['ministry_concentration'][top_ministry]}äº‹æ¥­ã¯{top_ministry}ãŒå æœ‰")
        
        if 'long_duration_projects' in anomalies:
            self.insights.append(f"20å¹´ä»¥ä¸Šã®é•·æœŸäº‹æ¥­ãŒ{anomalies['long_duration_projects']['percentage']:.1f}%å­˜åœ¨")
        
        self.analysis_results['anomaly_deep_dive'] = anomalies
        return anomalies
    
    def project_clustering_analysis(self):
        """äº‹æ¥­ã®é¡å‹åŒ–ãƒ»ã‚¯ãƒ©ã‚¹ã‚¿ãƒªãƒ³ã‚°åˆ†æ"""
        print("\n" + "="*80)
        print("7. äº‹æ¥­é¡å‹åŒ–ãƒ»è¤‡é›‘æ€§æŒ‡æ¨™åˆ†æï¼ˆæ–°è¦ï¼‰")
        print("="*80)
        
        # è¤‡é›‘æ€§æŒ‡æ¨™ã®è¨ˆç®—
        complexity_features = []
        
        # æ•°å€¤ç‰¹å¾´é‡ã®æŠ½å‡º
        numeric_features = ['total_related_records'] + [col for col in self.count_cols if col in self.df.columns]
        
        # å„äº‹æ¥­ã®è¤‡é›‘æ€§ã‚¹ã‚³ã‚¢è¨ˆç®—
        for idx, row in self.df.iterrows():
            features = {}
            
            # ãƒ‡ãƒ¼ã‚¿å¯†åº¦
            features['data_density'] = row.get('total_related_records', 0)
            
            # æ”¯å‡ºã®è¤‡é›‘æ€§ï¼ˆæ”¯å‡ºå…ˆæ•°ï¼‰
            features['expenditure_complexity'] = row.get('expenditure_info_count', 0)
            
            # ç›®æ¨™ã®è¤‡é›‘æ€§
            features['goals_complexity'] = row.get('goals_performance_count', 0)
            
            # äºˆç®—ã®è¤‡é›‘æ€§
            features['budget_complexity'] = row.get('budget_items_count', 0)
            
            # ç·åˆè¤‡é›‘æ€§ã‚¹ã‚³ã‚¢
            features['total_complexity'] = sum(features.values())
            
            # ãã®ä»–ã®ç‰¹å¾´
            features['ministry'] = row.get('åºœçœåº', '')
            features['category'] = row.get('äº‹æ¥­åŒºåˆ†', '')
            features['project_id'] = row.get('äºˆç®—äº‹æ¥­ID', '')
            features['project_name'] = row.get('äº‹æ¥­å', '')
            
            complexity_features.append(features)
        
        # è¤‡é›‘æ€§ã«ã‚ˆã‚‹åˆ†é¡
        complexity_scores = [item['total_complexity'] for item in complexity_features]
        
        if complexity_scores:
            q25 = np.percentile(complexity_scores, 25)
            q75 = np.percentile(complexity_scores, 75)
            q90 = np.percentile(complexity_scores, 90)
            
            # äº‹æ¥­ã‚¿ã‚¤ãƒ—åˆ†é¡
            simple_projects = [item for item in complexity_features if item['total_complexity'] <= q25]
            moderate_projects = [item for item in complexity_features if q25 < item['total_complexity'] <= q75]
            complex_projects = [item for item in complexity_features if q75 < item['total_complexity'] <= q90]
            very_complex_projects = [item for item in complexity_features if item['total_complexity'] > q90]
            
            # å„ã‚¿ã‚¤ãƒ—ã®ç‰¹å¾´åˆ†æ
            def analyze_group(group, name):
                if not group:
                    return {}
                
                ministry_dist = Counter([item['ministry'] for item in group])
                category_dist = Counter([item['category'] for item in group if item['category']])
                
                return {
                    'count': len(group),
                    'percentage': len(group) / len(complexity_features) * 100,
                    'avg_complexity': np.mean([item['total_complexity'] for item in group]),
                    'avg_data_density': np.mean([item['data_density'] for item in group]),
                    'top_ministries': dict(ministry_dist.most_common(3)),
                    'top_categories': dict(category_dist.most_common(3)),
                    'examples': group[:3]
                }
            
            analysis = {
                'complexity_distribution': {
                    'simple': analyze_group(simple_projects, 'å˜ç´”'),
                    'moderate': analyze_group(moderate_projects, 'ä¸­ç¨‹åº¦'),
                    'complex': analyze_group(complex_projects, 'è¤‡é›‘'),
                    'very_complex': analyze_group(very_complex_projects, 'æ¥µè¤‡é›‘')
                },
                'complexity_thresholds': {
                    'q25': q25,
                    'q75': q75,
                    'q90': q90
                },
                'top_complex_projects': sorted(complexity_features, key=lambda x: x['total_complexity'], reverse=True)[:10]
            }
            
            # åºœçœåºåˆ¥ã®è¤‡é›‘æ€§å‚¾å‘
            ministry_complexity = {}
            for ministry in self.df['åºœçœåº'].value_counts().head(10).index:
                ministry_items = [item for item in complexity_features if item['ministry'] == ministry]
                if ministry_items:
                    avg_complexity = np.mean([item['total_complexity'] for item in ministry_items])
                    ministry_complexity[ministry] = {
                        'avg_complexity': avg_complexity,
                        'project_count': len(ministry_items),
                        'complexity_rank': 0  # å¾Œã§è¨­å®š
                    }
            
            # è¤‡é›‘æ€§ãƒ©ãƒ³ã‚­ãƒ³ã‚°
            sorted_ministries = sorted(ministry_complexity.items(), key=lambda x: x[1]['avg_complexity'], reverse=True)
            for i, (ministry, stats) in enumerate(sorted_ministries):
                ministry_complexity[ministry]['complexity_rank'] = i + 1
            
            analysis['ministry_complexity_ranking'] = dict(sorted_ministries[:10])
            
            print(f"äº‹æ¥­è¤‡é›‘æ€§åˆ†æ:")
            print(f"  è¤‡é›‘æ€§åˆ†é¡:")
            for type_name, stats in analysis['complexity_distribution'].items():
                print(f"    - {type_name}: {stats['count']}äº‹æ¥­ ({stats['percentage']:.1f}%), å¹³å‡è¤‡é›‘æ€§{stats['avg_complexity']:.1f}")
            
            print(f"\nåºœçœåºåˆ¥è¤‡é›‘æ€§ãƒ©ãƒ³ã‚­ãƒ³ã‚°ï¼ˆä¸Šä½5ï¼‰:")
            for i, (ministry, stats) in enumerate(sorted_ministries[:5], 1):
                print(f"    {i}. {ministry}: å¹³å‡è¤‡é›‘æ€§{stats['avg_complexity']:.1f} ({stats['project_count']}äº‹æ¥­)")
            
            print(f"\næœ€è¤‡é›‘äº‹æ¥­ãƒˆãƒƒãƒ—3:")
            for i, project in enumerate(analysis['top_complex_projects'][:3], 1):
                print(f"    {i}. {project['project_name'][:50]}... ({project['ministry']}) - è¤‡é›‘æ€§{project['total_complexity']:.0f}")
            
            # Insightè¿½åŠ 
            very_complex_ratio = analysis['complexity_distribution']['very_complex']['percentage']
            most_complex_ministry = sorted_ministries[0]
            simplest_ministry = sorted_ministries[-1]
            
            self.insights.append(f"æ¥µè¤‡é›‘äº‹æ¥­(ä¸Šä½10%)ãŒ{very_complex_ratio:.1f}%å­˜åœ¨")
            self.insights.append(f"{most_complex_ministry[0]}ãŒæœ€é«˜è¤‡é›‘æ€§(å¹³å‡{most_complex_ministry[1]['avg_complexity']:.1f})")
            self.insights.append(f"{simplest_ministry[0]}ãŒæœ€ä½è¤‡é›‘æ€§(å¹³å‡{simplest_ministry[1]['avg_complexity']:.1f})")
        
        else:
            analysis = {'error': 'è¤‡é›‘æ€§åˆ†æã«å¤±æ•—'}
        
        self.analysis_results['project_clustering_analysis'] = analysis
        return analysis
    
    def correlation_analysis_enhanced(self):
        """å¼·åŒ–ã•ã‚ŒãŸç›¸é–¢ãƒ»ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ"""
        print("\n" + "="*80)
        print("8. ç›¸é–¢ãƒ»ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æï¼ˆå¼·åŒ–ç‰ˆï¼‰")
        print("="*80)
        
        # æ•°å€¤åˆ—ã®æŠ½å‡º
        numeric_cols = []
        for col in self.count_cols + ['total_related_records']:
            if col in self.df.columns:
                numeric_cols.append(col)
        
        correlations = {}
        
        if len(numeric_cols) >= 2:
            # ç›¸é–¢è¡Œåˆ—ã®è¨ˆç®—
            corr_matrix = self.df[numeric_cols].corr()
            
            # å¼·ç›¸é–¢ãƒšã‚¢ã®æŠ½å‡ºï¼ˆé–¾å€¤ã‚’0.3ã«ä¸‹ã’ã¦ã‚ˆã‚Šå¤šãã®é–¢ä¿‚ã‚’ç™ºè¦‹ï¼‰
            strong_correlations = []
            moderate_correlations = []
            
            for i in range(len(corr_matrix.columns)):
                for j in range(i+1, len(corr_matrix.columns)):
                    corr_value = corr_matrix.iloc[i, j]
                    pair = {
                        'var1': corr_matrix.columns[i],
                        'var2': corr_matrix.columns[j],
                        'correlation': corr_value
                    }
                    
                    if abs(corr_value) > 0.7:
                        strong_correlations.append(pair)
                    elif abs(corr_value) > 0.3:
                        moderate_correlations.append(pair)
            
            correlations['correlation_matrix'] = corr_matrix.to_dict()
            correlations['strong_correlations'] = strong_correlations
            correlations['moderate_correlations'] = moderate_correlations
            
            print(f"å¼·ç›¸é–¢ãƒšã‚¢ (|r| > 0.7):")
            for corr in sorted(strong_correlations, key=lambda x: abs(x['correlation']), reverse=True):
                var1_name = corr['var1'].replace('_count', '').replace('_', ' ')
                var2_name = corr['var2'].replace('_count', '').replace('_', ' ')
                print(f"    {var1_name} âŸ· {var2_name}: r = {corr['correlation']:.3f}")
            
            print(f"\nä¸­ç›¸é–¢ãƒšã‚¢ (0.3 < |r| â‰¤ 0.7):")
            for corr in sorted(moderate_correlations, key=lambda x: abs(x['correlation']), reverse=True)[:5]:
                var1_name = corr['var1'].replace('_count', '').replace('_', ' ')
                var2_name = corr['var2'].replace('_count', '').replace('_', ' ')
                print(f"    {var1_name} âŸ· {var2_name}: r = {corr['correlation']:.3f}")
        
        # åºœçœåºã¨ãƒ‡ãƒ¼ã‚¿ç‰¹æ€§ã®è©³ç´°åˆ†æ
        if 'åºœçœåº' in self.df.columns:
            ministry_profiles = {}
            
            for ministry in self.df['åºœçœåº'].value_counts().head(15).index:
                ministry_data = self.df[self.df['åºœçœåº'] == ministry]
                
                if len(ministry_data) >= 5:  # æœ€å°5äº‹æ¥­
                    profile = {
                        'project_count': len(ministry_data),
                        'avg_data_density': ministry_data['total_related_records'].mean(),
                        'data_density_std': ministry_data['total_related_records'].std(),
                        'specialization_scores': {}
                    }
                    
                    # å„ãƒ‡ãƒ¼ã‚¿ã‚¿ã‚¤ãƒ—ã®ç‰¹åŒ–åº¦è¨ˆç®—
                    for col in self.count_cols:
                        if col in ministry_data.columns:
                            ministry_avg = ministry_data[col].mean()
                            overall_avg = self.df[col].mean()
                            specialization = ministry_avg / overall_avg if overall_avg > 0 else 0
                            profile['specialization_scores'][col.replace('_count', '')] = specialization
                    
                    ministry_profiles[ministry] = profile
            
            correlations['ministry_profiles'] = ministry_profiles
            
            # åºœçœåºã®ç‰¹åŒ–åˆ†æ
            print(f"\nåºœçœåºåˆ¥ç‰¹åŒ–åˆ†æï¼ˆç‰¹åŒ–åº¦1.5ä»¥ä¸Šï¼‰:")
            for ministry, profile in ministry_profiles.items():
                specializations = [(k, v) for k, v in profile['specialization_scores'].items() if v >= 1.5]
                if specializations:
                    top_spec = sorted(specializations, key=lambda x: x[1], reverse=True)[:2]
                    spec_text = ", ".join([f"{spec[0]}({spec[1]:.1f}å€)" for spec in top_spec])
                    print(f"    {ministry}: {spec_text}")
        
        self.analysis_results['correlation_analysis_enhanced'] = correlations
        
        # æ–°ã—ã„Insight
        if strong_correlations:
            strongest = max(strong_correlations, key=lambda x: abs(x['correlation']))
            self.insights.append(f"æœ€å¼·ç›¸é–¢: {strongest['var1']}ã¨{strongest['var2']} (r={strongest['correlation']:.3f})")
        
        return correlations
    
    def generate_comprehensive_insights(self):
        """åŒ…æ‹¬çš„Insightç”Ÿæˆ"""
        print("\n" + "="*80)
        print("ğŸ” åŒ…æ‹¬çš„Insightç·æ‹¬")
        print("="*80)
        
        # ã‚«ãƒ†ã‚´ãƒªåˆ¥ã«Insightã‚’æ•´ç†
        categorized_insights = {
            'çµ„ç¹”ãƒ»è¦æ¨¡': [],
            'ãƒ‡ãƒ¼ã‚¿ç‰¹æ€§': [],
            'äºˆç®—ãƒ»æ”¯å‡º': [],
            'æ™‚ç³»åˆ—ãƒ»ãƒˆãƒ¬ãƒ³ãƒ‰': [],
            'è¤‡é›‘æ€§ãƒ»ç‰¹ç•°æ€§': [],
            'ç›¸é–¢ãƒ»ãƒ‘ã‚¿ãƒ¼ãƒ³': []
        }
        
        # æ—¢å­˜ã®Insightã‚’åˆ†é¡
        for insight in self.insights:
            if any(word in insight for word in ['åºœçœåº', 'çµ„ç¹”', 'é›†ä¸­', 'äº‹æ¥­æ•°']):
                categorized_insights['çµ„ç¹”ãƒ»è¦æ¨¡'].append(insight)
            elif any(word in insight for word in ['ãƒ‡ãƒ¼ã‚¿', 'ãƒ¬ã‚³ãƒ¼ãƒ‰', 'å¯†åº¦', 'ä¿æœ‰']):
                categorized_insights['ãƒ‡ãƒ¼ã‚¿ç‰¹æ€§'].append(insight)
            elif any(word in insight for word in ['äºˆç®—', 'æ”¯å‡º', 'å„„å††', 'å…†å††']):
                categorized_insights['äºˆç®—ãƒ»æ”¯å‡º'].append(insight)
            elif any(word in insight for word in ['å¹´', 'å¹´ä»£', 'ãƒˆãƒ¬ãƒ³ãƒ‰', 'æ–°è¦']):
                categorized_insights['æ™‚ç³»åˆ—ãƒ»ãƒˆãƒ¬ãƒ³ãƒ‰'].append(insight)
            elif any(word in insight for word in ['è¤‡é›‘', 'ç‰¹ç•°', 'ç•°å¸¸', 'æœ€å¤§', 'æœ€å°']):
                categorized_insights['è¤‡é›‘æ€§ãƒ»ç‰¹ç•°æ€§'].append(insight)
            elif any(word in insight for word in ['ç›¸é–¢', 'ãƒ‘ã‚¿ãƒ¼ãƒ³', 'é–¢ä¿‚']):
                categorized_insights['ç›¸é–¢ãƒ»ãƒ‘ã‚¿ãƒ¼ãƒ³'].append(insight)
            else:
                categorized_insights['ãƒ‡ãƒ¼ã‚¿ç‰¹æ€§'].append(insight)
        
        # è¿½åŠ ã®æ·±ã„Insightç”Ÿæˆ
        additional_insights = self.generate_deep_insights()
        
        # å…¨Insightã‚’è¡¨ç¤º
        total_insights = 0
        for category, insights in categorized_insights.items():
            if insights:
                print(f"\nã€{category}ã€‘")
                for i, insight in enumerate(insights, 1):
                    print(f"  {total_insights + i}. {insight}")
                total_insights += len(insights)
        
        if additional_insights:
            print(f"\nã€è¿½åŠ ç™ºè¦‹ã€‘")
            for i, insight in enumerate(additional_insights, total_insights + 1):
                print(f"  {i}. {insight}")
        
        self.insights.extend(additional_insights)
        return categorized_insights
    
    def generate_deep_insights(self):
        """æ·±ã„Insightã®ç”Ÿæˆ"""
        deep_insights = []
        
        # åˆ†æçµæœã‹ã‚‰æ·±ã„Insightã‚’æŠ½å‡º
        if 'budget_pattern_analysis' in self.analysis_results:
            budget_analysis = self.analysis_results['budget_pattern_analysis']
            if 'budget_statistics' in budget_analysis:
                median = budget_analysis['budget_statistics']['median']
                mean = budget_analysis['budget_statistics']['mean']
                if mean > median * 2:
                    deep_insights.append("äºˆç®—åˆ†å¸ƒãŒå³ã«æ­ªã‚“ã§ãŠã‚Šå°‘æ•°ã®å¤§è¦æ¨¡äº‹æ¥­ãŒå¹³å‡ã‚’æŠ¼ã—ä¸Šã’ã¦ã„ã‚‹")
        
        if 'expenditure_diversity_analysis' in self.analysis_results:
            exp_analysis = self.analysis_results['expenditure_diversity_analysis']
            if 'complexity_categories' in exp_analysis:
                total = sum(exp_analysis['complexity_categories'].values())
                simple_ratio = exp_analysis['complexity_categories']['simple'] / total * 100
                if simple_ratio > 60:
                    deep_insights.append(f"æ”¯å‡ºæ§‹é€ ãŒå˜ç´”ãªäº‹æ¥­ãŒ{simple_ratio:.1f}%ã‚’å ã‚åŠ¹ç‡çš„ãªåŸ·è¡Œä½“åˆ¶")
        
        if 'temporal_trend_analysis' in self.analysis_results:
            temporal_analysis = self.analysis_results['temporal_trend_analysis']
            if 'density_by_decade' in temporal_analysis:
                decades = list(temporal_analysis['density_by_decade'].keys())
                if len(decades) >= 2:
                    latest = temporal_analysis['density_by_decade'][decades[-1]]['avg_data_density']
                    previous = temporal_analysis['density_by_decade'][decades[-2]]['avg_data_density']
                    if latest > previous * 1.2:
                        deep_insights.append("æœ€æ–°å¹´ä»£ã®äº‹æ¥­ã§ãƒ‡ãƒ¼ã‚¿ç®¡ç†ã®é«˜åº¦åŒ–ãŒé€²ã‚“ã§ã„ã‚‹")
        
        if 'project_clustering_analysis' in self.analysis_results:
            cluster_analysis = self.analysis_results['project_clustering_analysis']
            if 'ministry_complexity_ranking' in cluster_analysis:
                ranking = list(cluster_analysis['ministry_complexity_ranking'].items())
                if len(ranking) >= 3:
                    top3_avg = np.mean([stats['avg_complexity'] for _, stats in ranking[:3]])
                    bottom3_avg = np.mean([stats['avg_complexity'] for _, stats in ranking[-3:]])
                    if top3_avg > bottom3_avg * 2:
                        deep_insights.append("åºœçœåºé–“ã§äº‹æ¥­è¤‡é›‘æ€§ã«å¤§ããªæ ¼å·®ãŒã‚ã‚Šå°‚é–€æ€§ã®é•ã„ã‚’ç¤ºå”†")
        
        if 'correlation_analysis_enhanced' in self.analysis_results:
            corr_analysis = self.analysis_results['correlation_analysis_enhanced']
            if 'ministry_profiles' in corr_analysis:
                profiles = corr_analysis['ministry_profiles']
                high_specialization = []
                for ministry, profile in profiles.items():
                    max_spec = max(profile['specialization_scores'].values()) if profile['specialization_scores'] else 0
                    if max_spec > 2.0:
                        high_specialization.append(ministry)
                
                if len(high_specialization) >= 3:
                    deep_insights.append(f"{len(high_specialization)}åºœçœåºãŒç‰¹å®šåˆ†é‡ã§é«˜ã„ç‰¹åŒ–ã‚’ç¤ºã—å½¹å‰²åˆ†æ‹…ãŒæ˜ç¢º")
        
        return deep_insights
    
    def save_enhanced_results(self):
        """å¼·åŒ–ã•ã‚ŒãŸçµæœä¿å­˜"""
        print("\n" + "="*80)
        print("çµæœä¿å­˜ï¼ˆå¼·åŒ–ç‰ˆï¼‰")
        print("="*80)
        
        # JSONçµæœä¿å­˜
        results_path = self.output_dir / "enhanced_analysis_results.json"
        with open(results_path, 'w', encoding='utf-8') as f:
            json.dump(self.analysis_results, f, ensure_ascii=False, indent=2, default=str)
        print(f"âœ“ å¼·åŒ–åˆ†æçµæœä¿å­˜: {results_path}")
        
        # Insightä¿å­˜
        insights_path = self.output_dir / "comprehensive_insights.txt"
        with open(insights_path, 'w', encoding='utf-8') as f:
            f.write("äº‹æ¥­ãƒã‚¹ã‚¿ãƒ¼ãƒªã‚¹ãƒˆå¼·åŒ–åˆ†æ - åŒ…æ‹¬çš„Insight\n")
            f.write("="*60 + "\n\n")
            for i, insight in enumerate(self.insights, 1):
                f.write(f"{i:2d}. {insight}\n")
        print(f"âœ“ åŒ…æ‹¬çš„Insightä¿å­˜: {insights_path}")
        
        # å¼·åŒ–HTMLãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        self.generate_enhanced_html_report()
        
        return True
    
    def generate_enhanced_html_report(self):
        """å¼·åŒ–HTMLãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        html_content = f"""<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <title>äº‹æ¥­ãƒã‚¹ã‚¿ãƒ¼ãƒªã‚¹ãƒˆå¼·åŒ–åˆ†æãƒ¬ãƒãƒ¼ãƒˆ</title>
    <style>
        body {{ font-family: 'Segoe UI', Arial, sans-serif; margin: 20px; background: #f8fafc; color: #1a202c; }}
        .container {{ max-width: 1400px; margin: 0 auto; background: #ffffff; padding: 40px; border-radius: 12px; box-shadow: 0 4px 20px rgba(0,0,0,0.1); }}
        h1 {{ color: #2d3748; text-align: center; border-bottom: 4px solid #4299e1; padding-bottom: 20px; margin-bottom: 30px; }}
        h2 {{ color: #2d3748; margin-top: 40px; border-left: 6px solid #4299e1; padding-left: 15px; }}
        h3 {{ color: #4a5568; margin-top: 30px; }}
        .summary {{ background: linear-gradient(135deg, #667eea 0%, #764ba2 100%); color: white; padding: 30px; border-radius: 10px; margin: 25px 0; }}
        .metric {{ display: inline-block; margin: 15px 25px; text-align: center; }}
        .metric-value {{ font-size: 2.5em; font-weight: bold; display: block; }}
        .metric-label {{ font-size: 1em; opacity: 0.9; }}
        table {{ width: 100%; border-collapse: collapse; margin: 25px 0; }}
        th {{ background: #edf2f7; color: #2d3748; padding: 15px; text-align: left; border-bottom: 2px solid #cbd5e0; }}
        td {{ padding: 12px 15px; border-bottom: 1px solid #e2e8f0; color: #4a5568; }}
        tr:hover {{ background: #f7fafc; }}
        .insight {{ background: #e6fffa; border-left: 5px solid #38b2ac; padding: 20px; margin: 15px 0; color: #234e52; border-radius: 5px; }}
        .section {{ margin: 40px 0; padding: 30px; background: #f7fafc; border-radius: 8px; }}
        .highlight {{ background: #fed7d7; color: #742a2a; padding: 3px 6px; border-radius: 3px; }}
        .success {{ background: #c6f6d5; color: #22543d; padding: 3px 6px; border-radius: 3px; }}
        .grid {{ display: grid; grid-template-columns: repeat(auto-fit, minmax(300px, 1fr)); gap: 20px; margin: 20px 0; }}
        .card {{ background: white; padding: 20px; border-radius: 8px; box-shadow: 0 2px 10px rgba(0,0,0,0.05); }}
    </style>
</head>
<body>
    <div class="container">
        <h1>ğŸš€ äº‹æ¥­ãƒã‚¹ã‚¿ãƒ¼ãƒªã‚¹ãƒˆå¼·åŒ–åˆ†æãƒ¬ãƒãƒ¼ãƒˆ</h1>
        
        <div class="summary">
            <h2 style="color: white; margin-top: 0;">åˆ†ææ¦‚è¦</h2>
"""
        
        # åŸºæœ¬çµ±è¨ˆã®è¡¨ç¤º
        if 'basic_statistics' in self.analysis_results:
            stats = self.analysis_results['basic_statistics']
            html_content += f"""
            <div class="metric">
                <span class="metric-value">{stats['total_projects']:,}</span>
                <span class="metric-label">ç·äº‹æ¥­æ•°</span>
            </div>
            <div class="metric">
                <span class="metric-value">{stats['total_columns']}</span>
                <span class="metric-label">ç·åˆ—æ•°</span>
            </div>
            <div class="metric">
                <span class="metric-value">{stats['data_completeness']:.1f}%</span>
                <span class="metric-label">ãƒ‡ãƒ¼ã‚¿å®Œå…¨æ€§</span>
            </div>
            <div class="metric">
                <span class="metric-value">{len(self.insights)}</span>
                <span class="metric-label">ç™ºè¦‹Insightæ•°</span>
            </div>
"""
        
        html_content += """
        </div>
        
        <h2>ğŸ¯ ä¸»è¦Insight</h2>
        <div class="grid">
"""
        
        # Insightã‚’ã‚«ãƒ¼ãƒ‰å½¢å¼ã§è¡¨ç¤º
        for i, insight in enumerate(self.insights[:12], 1):  # æœ€åˆã®12å€‹ã‚’è¡¨ç¤º
            html_content += f'            <div class="card"><div class="insight">{i}. {insight}</div></div>\n'
        
        html_content += """
        </div>
"""
        
        # åºœçœåºåˆ†æï¼ˆä¿®æ­£ç‰ˆï¼‰
        if 'ministry_analysis' in self.analysis_results:
            ministry_data = self.analysis_results['ministry_analysis']
            html_content += """
        <div class="section">
            <h2>ğŸ›ï¸ åºœçœåºåˆ†æï¼ˆä¿®æ­£ç‰ˆï¼‰</h2>
            <table>
                <tr>
                    <th>é †ä½</th>
                    <th>åºœçœåº</th>
                    <th>äº‹æ¥­æ•°</th>
                    <th>å‰²åˆ</th>
                    <th>é›†ä¸­åº¦</th>
                </tr>
"""
            total_projects = ministry_data['total_projects']
            for i, (ministry, count) in enumerate(ministry_data['top_10_ministries'].items(), 1):
                percentage = (count / total_projects) * 100  # ä¿®æ­£ã•ã‚ŒãŸè¨ˆç®—
                concentration = "é«˜" if percentage > 10 else "ä¸­" if percentage > 5 else "ä½"
                html_content += f"""
                <tr>
                    <td>{i}</td>
                    <td><strong>{ministry}</strong></td>
                    <td>{count:,}</td>
                    <td><span class="{'highlight' if percentage > 15 else 'success' if percentage > 10 else ''}">{percentage:.1f}%</span></td>
                    <td>{concentration}</td>
                </tr>
"""
            html_content += """
            </table>
            <p><strong>é›†ä¸­åº¦åˆ†æ:</strong> 
            ä¸Šä½3åºœçœåºã§{:.1f}%ã€ä¸Šä½5åºœçœåºã§{:.1f}%ã‚’å æœ‰</p>
        </div>
""".format(
            ministry_data['ministry_stats']['concentration_ratio_top3'],
            ministry_data['ministry_stats']['concentration_ratio_top5']
        )
        
        # äºˆç®—åˆ†æ
        if 'budget_pattern_analysis' in self.analysis_results:
            budget_data = self.analysis_results['budget_pattern_analysis']
            if 'budget_statistics' in budget_data:
                html_content += f"""
        <div class="section">
            <h2>ğŸ’° äºˆç®—è¦æ¨¡åˆ†æ</h2>
            <div class="grid">
                <div class="card">
                    <h3>åŸºæœ¬çµ±è¨ˆ</h3>
                    <p>å¹³å‡äºˆç®—: <strong>{budget_data['budget_statistics']['mean']/1e8:.1f}å„„å††</strong></p>
                    <p>ä¸­å¤®å€¤: <strong>{budget_data['budget_statistics']['median']/1e8:.1f}å„„å††</strong></p>
                    <p>æœ€å¤§äºˆç®—: <strong>{budget_data['budget_statistics']['max']/1e8:.1f}å„„å††</strong></p>
                </div>
                <div class="card">
                    <h3>è¦æ¨¡åˆ¥åˆ†å¸ƒ</h3>
                    <p>å°è¦æ¨¡(1å„„æœªæº€): {budget_data['budget_distribution']['small_projects']}äº‹æ¥­</p>
                    <p>ä¸­è¦æ¨¡(1-10å„„): {budget_data['budget_distribution']['medium_projects']}äº‹æ¥­</p>
                    <p>å¤§è¦æ¨¡(10-100å„„): {budget_data['budget_distribution']['large_projects']}äº‹æ¥­</p>
                    <p>è¶…å¤§è¦æ¨¡(100å„„ä»¥ä¸Š): <span class="highlight">{budget_data['budget_distribution']['mega_projects']}äº‹æ¥­</span></p>
                </div>
            </div>
        </div>
"""
        
        # è¤‡é›‘æ€§åˆ†æ
        if 'project_clustering_analysis' in self.analysis_results:
            cluster_data = self.analysis_results['project_clustering_analysis']
            if 'complexity_distribution' in cluster_data:
                html_content += """
        <div class="section">
            <h2>ğŸ”¬ äº‹æ¥­è¤‡é›‘æ€§åˆ†æ</h2>
            <table>
                <tr>
                    <th>è¤‡é›‘æ€§ãƒ¬ãƒ™ãƒ«</th>
                    <th>äº‹æ¥­æ•°</th>
                    <th>å‰²åˆ</th>
                    <th>å¹³å‡è¤‡é›‘æ€§ã‚¹ã‚³ã‚¢</th>
                </tr>
"""
                for level, stats in cluster_data['complexity_distribution'].items():
                    level_name = {'simple': 'å˜ç´”', 'moderate': 'ä¸­ç¨‹åº¦', 'complex': 'è¤‡é›‘', 'very_complex': 'æ¥µè¤‡é›‘'}[level]
                    html_content += f"""
                <tr>
                    <td>{level_name}</td>
                    <td>{stats['count']:,}</td>
                    <td>{stats['percentage']:.1f}%</td>
                    <td>{stats['avg_complexity']:.1f}</td>
                </tr>
"""
                html_content += """
            </table>
        </div>
"""
        
        # æ™‚ç³»åˆ—ãƒˆãƒ¬ãƒ³ãƒ‰
        if 'temporal_trend_analysis' in self.analysis_results:
            temporal_data = self.analysis_results['temporal_trend_analysis']
            html_content += f"""
        <div class="section">
            <h2>ğŸ“ˆ æ™‚ç³»åˆ—ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æ</h2>
            <div class="grid">
                <div class="card">
                    <h3>å¹´ä»£åˆ¥åˆ†å¸ƒ</h3>
                    <p>2020å¹´ä»£é–‹å§‹: <span class="highlight">{temporal_data['overall_temporal_stats']['decade_2020s_ratio']:.1f}%</span></p>
                    <p>2010å¹´ä»£é–‹å§‹: {temporal_data['overall_temporal_stats']['decade_2010s_ratio']:.1f}%</p>
                    <p>2000å¹´ä»£é–‹å§‹: {temporal_data['overall_temporal_stats']['decade_2000s_ratio']:.1f}%</p>
                </div>
                <div class="card">
                    <h3>æœ€æ–°äº‹æ¥­æ¯”ç‡ï¼ˆ2020å¹´ä»¥é™é–‹å§‹ï¼‰</h3>
"""
            
            if 'ministry_temporal_analysis' in temporal_data:
                sorted_recent = sorted(temporal_data['ministry_temporal_analysis'].items(), 
                                     key=lambda x: x[1]['recent_projects_ratio'], reverse=True)
                for ministry, stats in sorted_recent[:5]:
                    html_content += f"                    <p>{ministry}: {stats['recent_projects_ratio']:.1f}%</p>\n"
            
            html_content += """
                </div>
            </div>
        </div>
"""
        
        html_content += """
        <div style="text-align: center; margin-top: 50px; color: #718096; font-size: 0.9em;">
            äº‹æ¥­ãƒã‚¹ã‚¿ãƒ¼ãƒªã‚¹ãƒˆå¼·åŒ–åˆ†æãƒ¬ãƒãƒ¼ãƒˆ - RS Visualization System<br>
            æ·±ã„æ´å¯Ÿã«ã‚ˆã‚‹æ”¿åºœäº‹æ¥­ã®åŒ…æ‹¬çš„ç†è§£
        </div>
    </div>
</body>
</html>
"""
        
        report_path = self.output_dir / "enhanced_analysis_report.html"
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(html_content)
        print(f"âœ“ å¼·åŒ–HTMLãƒ¬ãƒãƒ¼ãƒˆä¿å­˜: {report_path}")
    
    def run_enhanced_analysis(self):
        """å¼·åŒ–åˆ†æå®Ÿè¡Œãƒ¡ã‚¤ãƒ³"""
        print("\n" + "="*80)
        print("ğŸš€ äº‹æ¥­ãƒã‚¹ã‚¿ãƒ¼ãƒªã‚¹ãƒˆå¼·åŒ–åˆ†æé–‹å§‹")
        print("="*80)
        print("ç›®æ¨™: æ·±ã„æ´å¯Ÿã¨ãƒã‚°ä¿®æ­£ã«ã‚ˆã‚‹åŒ…æ‹¬çš„åˆ†æ")
        
        try:
            # 1. ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
            if not self.load_data():
                return False
            
            # 2. ä¿®æ­£ã•ã‚ŒãŸåŸºæœ¬åˆ†æ
            self.basic_statistics()
            self.ministry_analysis_fixed()
            self.data_density_analysis_fixed()
            
            # 3. æ–°è¦æ·±ã„åˆ†æ
            self.budget_pattern_analysis()
            self.expenditure_diversity_analysis()
            self.temporal_trend_analysis()
            self.anomaly_deep_dive()
            self.project_clustering_analysis()
            self.correlation_analysis_enhanced()
            
            # 4. åŒ…æ‹¬çš„Insightç”Ÿæˆ
            self.generate_comprehensive_insights()
            
            # 5. çµæœä¿å­˜
            self.save_enhanced_results()
            
            print("\n" + "="*80)
            print("âœ… å¼·åŒ–åˆ†æå®Œäº†ï¼")
            print("="*80)
            print(f"ğŸ“Š {len(self.insights)}å€‹ã®æ·±ã„Insightã‚’ç™ºè¦‹")
            print(f"ğŸ“ çµæœä¿å­˜å…ˆ: {self.output_dir}/")
            print("  - enhanced_analysis_results.json")
            print("  - enhanced_analysis_report.html")
            print("  - comprehensive_insights.txt")
            print("\nğŸ¯ ä¸»è¦æ”¹å–„ç‚¹:")
            print("  âœ“ Insighté‡è¤‡å•é¡Œã‚’ä¿®æ­£")
            print("  âœ“ åºœçœåºåˆ†æã®å‰²åˆè¨ˆç®—ãƒã‚°ã‚’ä¿®æ­£")
            print("  âœ“ äºˆç®—ãƒ»æ”¯å‡ºãƒ‘ã‚¿ãƒ¼ãƒ³ã®æ·±ã„åˆ†æã‚’è¿½åŠ ")
            print("  âœ“ äº‹æ¥­è¤‡é›‘æ€§ãƒ»é¡å‹åŒ–åˆ†æã‚’è¿½åŠ ")
            print("  âœ“ æ™‚ç³»åˆ—ãƒˆãƒ¬ãƒ³ãƒ‰åˆ†æã‚’å¼·åŒ–")
            print("  âœ“ ç‰¹ç•°äº‹æ¥­ã®æ·±æ˜ã‚Šåˆ†æã‚’è¿½åŠ ")
            
            return True
            
        except Exception as e:
            print(f"\nâŒ å¼·åŒ–åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            traceback.print_exc()
            return False


def main():
    analyzer = EnhancedProjectAnalyzer()
    analyzer.run_enhanced_analysis()


if __name__ == "__main__":
    main()