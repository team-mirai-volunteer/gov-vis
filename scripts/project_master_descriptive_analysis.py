#!/usr/bin/env python3
"""
äº‹æ¥­ãƒã‚¹ã‚¿ãƒ¼ãƒªã‚¹ãƒˆè¨˜è¿°çµ±è¨ˆåˆ†æ
5,664äº‹æ¥­Ã—95åˆ—ã®ãƒ‡ãƒ¼ã‚¿ã‹ã‚‰insightã‚’æŠ½å‡ºã™ã‚‹åŒ…æ‹¬çš„ãªåˆ†æ
"""
import pandas as pd
import numpy as np
import json
from pathlib import Path
from typing import Dict, List, Any, Tuple
import warnings
warnings.filterwarnings('ignore')

# å¯è¦–åŒ–ãƒ©ã‚¤ãƒ–ãƒ©ãƒªã®æ¡ä»¶ä»˜ãã‚¤ãƒ³ãƒãƒ¼ãƒˆ
try:
    import matplotlib.pyplot as plt
    import seaborn as sns
    # æ—¥æœ¬èªãƒ•ã‚©ãƒ³ãƒˆã®è¨­å®š
    plt.rcParams['font.family'] = 'DejaVu Sans'
    sns.set_style("whitegrid")
    sns.set_palette("husl")
    VISUALIZATION_AVAILABLE = True
except ImportError:
    VISUALIZATION_AVAILABLE = False
    print("âš ï¸ å¯è¦–åŒ–ãƒ©ã‚¤ãƒ–ãƒ©ãƒªãŒåˆ©ç”¨ã§ãã¾ã›ã‚“ã€‚ãƒ†ã‚­ã‚¹ãƒˆãƒ™ãƒ¼ã‚¹ã®åˆ†æã®ã¿å®Ÿè¡Œã—ã¾ã™ã€‚")


class ProjectMasterAnalyzer:
    """äº‹æ¥­ãƒã‚¹ã‚¿ãƒ¼ãƒªã‚¹ãƒˆè¨˜è¿°çµ±è¨ˆåˆ†æã‚¯ãƒ©ã‚¹"""
    
    def __init__(self):
        self.data_dir = Path("data")
        self.project_master_path = self.data_dir / "project_master" / "rs_project_master_with_details.feather"
        self.output_dir = self.data_dir / "project_descriptive_analysis"
        self.output_dir.mkdir(parents=True, exist_ok=True)
        
        self.df = None
        self.analysis_results = {}
        self.insights = []
        
        # åˆ†æå¯¾è±¡ã®åˆ—å®šç¾©
        self.basic_info_cols = [
            'åºœçœåº', 'äº‹æ¥­åŒºåˆ†', 'äº‹æ¥­é–‹å§‹å¹´åº¦', 'äº‹æ¥­çµ‚äº†ï¼ˆäºˆå®šï¼‰å¹´åº¦', 
            'ä¸»è¦çµŒè²»', 'æ”¿ç­–', 'æ–½ç­–', 'å®Ÿæ–½æ–¹æ³•ãƒ¼ç›´æ¥å®Ÿæ–½', 'å®Ÿæ–½æ–¹æ³•ãƒ¼è£œåŠ©', 
            'å®Ÿæ–½æ–¹æ³•ãƒ¼è² æ‹…', 'å®Ÿæ–½æ–¹æ³•ãƒ¼äº¤ä»˜', 'å®Ÿæ–½æ–¹æ³•ãƒ¼åˆ†æ‹…é‡‘ãƒ»æ‹ å‡ºé‡‘'
        ]
        
        self.count_cols = [
            'budget_summary_count', 'budget_items_count', 'goals_performance_count',
            'goal_connections_count', 'evaluations_count', 'expenditure_info_count',
            'expenditure_connections_count', 'expenditure_details_count', 'contracts_count'
        ]
        
        self.json_cols = [
            'budget_summary_json', 'budget_items_json', 'goals_performance_json',
            'goal_connections_json', 'evaluations_json', 'expenditure_info_json',
            'expenditure_connections_json', 'expenditure_details_json', 'contracts_json'
        ]
    
    def load_data(self):
        """ãƒ‡ãƒ¼ã‚¿ã‚’èª­ã¿è¾¼ã¿"""
        print("\n" + "="*80)
        print("ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿é–‹å§‹")
        print("="*80)
        
        if not self.project_master_path.exists():
            raise FileNotFoundError(f"äº‹æ¥­ãƒã‚¹ã‚¿ãƒ¼ãƒªã‚¹ãƒˆãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“: {self.project_master_path}")
        
        try:
            self.df = pd.read_feather(self.project_master_path)
            print(f"âœ“ ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿å®Œäº†: {len(self.df):,}è¡Œ Ã— {len(self.df.columns)}åˆ—")
            
            # åŸºæœ¬æƒ…å ±ã‚’è¡¨ç¤º
            print(f"  - äº‹æ¥­æ•°: {len(self.df):,}")
            print(f"  - åˆ—æ•°: {len(self.df.columns)}")
            print(f"  - ãƒ‡ãƒ¼ã‚¿ã‚µã‚¤ã‚º: {self.df.memory_usage(deep=True).sum() / 1024**2:.1f} MB")
            
            return True
            
        except Exception as e:
            print(f"âœ— ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿ã‚¨ãƒ©ãƒ¼: {e}")
            return False
    
    def basic_statistics(self):
        """åŸºæœ¬çµ±è¨ˆåˆ†æ"""
        print("\n" + "="*80)
        print("åŸºæœ¬çµ±è¨ˆåˆ†æ")
        print("="*80)
        
        basic_stats = {
            'total_projects': len(self.df),
            'total_columns': len(self.df.columns),
            'missing_values': self.df.isnull().sum().sum(),
            'data_completeness': (1 - self.df.isnull().sum().sum() / (len(self.df) * len(self.df.columns))) * 100
        }
        
        print(f"åŸºæœ¬çµ±è¨ˆ:")
        print(f"  - ç·äº‹æ¥­æ•°: {basic_stats['total_projects']:,}")
        print(f"  - ç·åˆ—æ•°: {basic_stats['total_columns']}")
        print(f"  - æ¬ æå€¤æ•°: {basic_stats['missing_values']:,}")
        print(f"  - ãƒ‡ãƒ¼ã‚¿å®Œå…¨æ€§: {basic_stats['data_completeness']:.1f}%")
        
        self.analysis_results['basic_statistics'] = basic_stats
        
        return basic_stats
    
    def ministry_analysis(self):
        """åºœçœåºåˆ¥åˆ†æ"""
        print("\nåºœçœåºåˆ¥åˆ†æ:")
        
        # åºœçœåºåˆ¥äº‹æ¥­æ•°
        ministry_counts = self.df['åºœçœåº'].value_counts()
        
        analysis = {
            'total_ministries': len(ministry_counts),
            'ministry_distribution': ministry_counts.to_dict(),
            'top_10_ministries': ministry_counts.head(10).to_dict(),
            'ministry_stats': {
                'mean': ministry_counts.mean(),
                'median': ministry_counts.median(),
                'std': ministry_counts.std(),
                'max': ministry_counts.max(),
                'min': ministry_counts.min()
            }
        }
        
        print(f"  - åºœçœåºæ•°: {analysis['total_ministries']}")
        print(f"  - å¹³å‡äº‹æ¥­æ•°/åºœçœåº: {analysis['ministry_stats']['mean']:.1f}")
        print(f"  - æœ€å¤§äº‹æ¥­æ•°: {analysis['ministry_stats']['max']}")
        print(f"  - æœ€å°äº‹æ¥­æ•°: {analysis['ministry_stats']['min']}")
        
        print("  ä¸Šä½10åºœçœåº:")
        for i, (ministry, count) in enumerate(ministry_counts.head(10).items(), 1):
            percentage = (count / len(self.df)) * 100
            print(f"    {i:2d}. {ministry}: {count:,}äº‹æ¥­ ({percentage:.1f}%)")
        
        self.analysis_results['ministry_analysis'] = analysis
        
        # InsightæŠ½å‡º
        top_ministry = ministry_counts.index[0]
        top_count = ministry_counts.iloc[0]
        top_percentage = (top_count / len(self.df)) * 100
        
        self.insights.append(f"æœ€å¤šäº‹æ¥­åºœçœåºã¯{top_ministry}ã§{top_count:,}äº‹æ¥­({top_percentage:.1f}%)ã‚’å ã‚ã‚‹")
        
        if analysis['ministry_stats']['std'] > analysis['ministry_stats']['mean']:
            self.insights.append("åºœçœåºé–“ã®äº‹æ¥­æ•°æ ¼å·®ãŒå¤§ãã„ï¼ˆæ¨™æº–åå·® > å¹³å‡å€¤ï¼‰")
        
        return analysis
    
    def project_category_analysis(self):
        """äº‹æ¥­åŒºåˆ†åˆ†æ"""
        print("\näº‹æ¥­åŒºåˆ†åˆ†æ:")
        
        if 'äº‹æ¥­åŒºåˆ†' in self.df.columns:
            category_counts = self.df['äº‹æ¥­åŒºåˆ†'].value_counts()
            
            analysis = {
                'total_categories': len(category_counts),
                'category_distribution': category_counts.to_dict(),
                'category_stats': {
                    'mean': category_counts.mean(),
                    'median': category_counts.median()
                }
            }
            
            print(f"  - äº‹æ¥­åŒºåˆ†æ•°: {analysis['total_categories']}")
            print("  äº‹æ¥­åŒºåˆ†åˆ¥åˆ†å¸ƒ:")
            for category, count in category_counts.head(10).items():
                percentage = (count / len(self.df)) * 100
                print(f"    {category}: {count:,}äº‹æ¥­ ({percentage:.1f}%)")
            
            self.analysis_results['project_category_analysis'] = analysis
        else:
            print("  äº‹æ¥­åŒºåˆ†åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
            self.analysis_results['project_category_analysis'] = {}
    
    def temporal_analysis(self):
        """æ™‚ç³»åˆ—åˆ†æ"""
        print("\næ™‚ç³»åˆ—åˆ†æ:")
        
        # äº‹æ¥­é–‹å§‹å¹´åº¦ã®åˆ†æ
        if 'äº‹æ¥­é–‹å§‹å¹´åº¦' in self.df.columns:
            start_years = pd.to_numeric(self.df['äº‹æ¥­é–‹å§‹å¹´åº¦'], errors='coerce').dropna()
            
            analysis = {
                'start_year_stats': {
                    'min': int(start_years.min()) if not start_years.empty else None,
                    'max': int(start_years.max()) if not start_years.empty else None,
                    'mean': start_years.mean() if not start_years.empty else None,
                    'median': start_years.median() if not start_years.empty else None,
                    'mode': start_years.mode().iloc[0] if not start_years.empty and not start_years.mode().empty else None
                },
                'decade_distribution': {},
                'recent_trend': {}
            }
            
            # å¹´ä»£åˆ¥åˆ†å¸ƒ
            if not start_years.empty:
                decades = (start_years // 10) * 10
                decade_counts = decades.value_counts().sort_index()
                analysis['decade_distribution'] = decade_counts.to_dict()
                
                # æœ€è¿‘ã®å‚¾å‘ï¼ˆ2000å¹´ä»¥é™ï¼‰
                recent_years = start_years[start_years >= 2000]
                if not recent_years.empty:
                    recent_counts = recent_years.value_counts().sort_index()
                    analysis['recent_trend'] = recent_counts.tail(10).to_dict()
            
            print(f"  - äº‹æ¥­é–‹å§‹å¹´åº¦ç¯„å›²: {analysis['start_year_stats']['min']} - {analysis['start_year_stats']['max']}")
            print(f"  - å¹³å‡é–‹å§‹å¹´åº¦: {analysis['start_year_stats']['mean']:.1f}")
            print(f"  - æœ€é »é–‹å§‹å¹´åº¦: {analysis['start_year_stats']['mode']}")
            
            # å¹´ä»£åˆ¥åˆ†å¸ƒè¡¨ç¤º
            print("  å¹´ä»£åˆ¥äº‹æ¥­æ•°:")
            for decade, count in sorted(analysis['decade_distribution'].items()):
                percentage = (count / len(start_years)) * 100
                print(f"    {int(decade)}å¹´ä»£: {count}äº‹æ¥­ ({percentage:.1f}%)")
            
            self.analysis_results['temporal_analysis'] = analysis
            
            # InsightæŠ½å‡º
            if analysis['start_year_stats']['mode'] and analysis['start_year_stats']['mode'] >= 2000:
                self.insights.append(f"{int(analysis['start_year_stats']['mode'])}å¹´ãŒäº‹æ¥­é–‹å§‹ã®æœ€é »å¹´åº¦")
        else:
            print("  äº‹æ¥­é–‹å§‹å¹´åº¦åˆ—ãŒè¦‹ã¤ã‹ã‚Šã¾ã›ã‚“")
    
    def data_density_analysis(self):
        """ãƒ‡ãƒ¼ã‚¿å¯†åº¦åˆ†æ"""
        print("\n" + "="*80)
        print("ãƒ‡ãƒ¼ã‚¿å¯†åº¦åˆ†æ")
        print("="*80)
        
        # å„ãƒ†ãƒ¼ãƒ–ãƒ«ã®ãƒ‡ãƒ¼ã‚¿ä¿æœ‰ç‡
        data_availability = {}
        total_records_stats = {}
        
        for col in self.count_cols:
            if col in self.df.columns:
                table_name = col.replace('_count', '')
                has_data = self.df[col] > 0
                
                data_availability[table_name] = {
                    'projects_with_data': has_data.sum(),
                    'coverage_rate': (has_data.sum() / len(self.df)) * 100,
                    'avg_records_per_project': self.df[col].mean(),
                    'max_records': self.df[col].max(),
                    'std_records': self.df[col].std()
                }
        
        # Total related recordsã®åˆ†æ
        if 'total_related_records' in self.df.columns:
            total_records = self.df['total_related_records']
            total_records_stats = {
                'mean': total_records.mean(),
                'median': total_records.median(),
                'std': total_records.std(),
                'min': total_records.min(),
                'max': total_records.max(),
                'percentiles': {
                    '25th': total_records.quantile(0.25),
                    '75th': total_records.quantile(0.75),
                    '90th': total_records.quantile(0.90),
                    '95th': total_records.quantile(0.95)
                }
            }
        
        analysis = {
            'data_availability': data_availability,
            'total_records_stats': total_records_stats
        }
        
        print("ãƒ†ãƒ¼ãƒ–ãƒ«åˆ¥ãƒ‡ãƒ¼ã‚¿ä¿æœ‰çŠ¶æ³:")
        for table_name, stats in data_availability.items():
            print(f"  {table_name}:")
            print(f"    - ãƒ‡ãƒ¼ã‚¿æœ‰ã‚Šäº‹æ¥­: {stats['projects_with_data']:,}/{len(self.df):,} ({stats['coverage_rate']:.1f}%)")
            print(f"    - å¹³å‡ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°/äº‹æ¥­: {stats['avg_records_per_project']:.1f}")
            print(f"    - æœ€å¤§ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {stats['max_records']}")
        
        if total_records_stats:
            print(f"\né–¢é€£ãƒ¬ã‚³ãƒ¼ãƒ‰ç·æ•°çµ±è¨ˆ:")
            print(f"  - å¹³å‡: {total_records_stats['mean']:.1f}ãƒ¬ã‚³ãƒ¼ãƒ‰/äº‹æ¥­")
            print(f"  - ä¸­å¤®å€¤: {total_records_stats['median']:.1f}")
            print(f"  - 90ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«: {total_records_stats['percentiles']['90th']:.1f}")
            print(f"  - 95ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«: {total_records_stats['percentiles']['95th']:.1f}")
            print(f"  - æœ€å¤§å€¤: {total_records_stats['max']}")
        
        self.analysis_results['data_density_analysis'] = analysis
        
        # InsightæŠ½å‡º
        highest_coverage = max(data_availability.items(), key=lambda x: x[1]['coverage_rate'])
        lowest_coverage = min(data_availability.items(), key=lambda x: x[1]['coverage_rate'])
        
        self.insights.append(f"{highest_coverage[0]}ãŒæœ€é«˜ã®ãƒ‡ãƒ¼ã‚¿ä¿æœ‰ç‡({highest_coverage[1]['coverage_rate']:.1f}%)")
        self.insights.append(f"{lowest_coverage[0]}ãŒæœ€ä½ã®ãƒ‡ãƒ¼ã‚¿ä¿æœ‰ç‡({lowest_coverage[1]['coverage_rate']:.1f}%)")
        
        if total_records_stats and total_records_stats['max'] > total_records_stats['mean'] * 3:
            self.insights.append(f"ãƒ‡ãƒ¼ã‚¿å¯†åº¦ã«å¤§ããªã°ã‚‰ã¤ãã‚ã‚Šï¼ˆæœ€å¤§{total_records_stats['max']}vså¹³å‡{total_records_stats['mean']:.1f}ï¼‰")
        
        return analysis
    
    def implementation_method_analysis(self):
        """å®Ÿæ–½æ–¹æ³•åˆ†æ"""
        print("\nå®Ÿæ–½æ–¹æ³•åˆ†æ:")
        
        implementation_cols = [
            'å®Ÿæ–½æ–¹æ³•ãƒ¼ç›´æ¥å®Ÿæ–½', 'å®Ÿæ–½æ–¹æ³•ãƒ¼è£œåŠ©', 'å®Ÿæ–½æ–¹æ³•ãƒ¼è² æ‹…', 
            'å®Ÿæ–½æ–¹æ³•ãƒ¼äº¤ä»˜', 'å®Ÿæ–½æ–¹æ³•ãƒ¼åˆ†æ‹…é‡‘ãƒ»æ‹ å‡ºé‡‘', 'å®Ÿæ–½æ–¹æ³•ãƒ¼ãã®ä»–'
        ]
        
        implementation_stats = {}
        
        for col in implementation_cols:
            if col in self.df.columns:
                # ãƒ–ãƒ¼ãƒ«å€¤ã¨ã—ã¦è§£é‡ˆï¼ˆ1/0 ã¾ãŸã¯ True/Falseï¼‰
                values = pd.to_numeric(self.df[col], errors='coerce').fillna(0)
                count = (values > 0).sum()
                percentage = (count / len(self.df)) * 100
                
                method_name = col.replace('å®Ÿæ–½æ–¹æ³•ãƒ¼', '')
                implementation_stats[method_name] = {
                    'count': count,
                    'percentage': percentage
                }
                
                print(f"  {method_name}: {count:,}äº‹æ¥­ ({percentage:.1f}%)")
        
        self.analysis_results['implementation_method_analysis'] = implementation_stats
        
        # InsightæŠ½å‡º
        if implementation_stats:
            most_common = max(implementation_stats.items(), key=lambda x: x[1]['count'])
            self.insights.append(f"{most_common[0]}ãŒæœ€ã‚‚å¤šã„å®Ÿæ–½æ–¹æ³•({most_common[1]['count']:,}äº‹æ¥­)")
        
        return implementation_stats
    
    def json_data_analysis(self):
        """JSONè©³ç´°ãƒ‡ãƒ¼ã‚¿åˆ†æ"""
        print("\n" + "="*80)
        print("JSONè©³ç´°ãƒ‡ãƒ¼ã‚¿åˆ†æ")
        print("="*80)
        
        json_insights = {}
        
        # äºˆç®—æƒ…å ±ã®åˆ†æï¼ˆbudget_summary_jsonï¼‰
        if 'budget_summary_json' in self.df.columns:
            budget_analysis = self.analyze_budget_json()
            json_insights['budget'] = budget_analysis
        
        # æ”¯å‡ºæƒ…å ±ã®åˆ†æï¼ˆexpenditure_info_jsonï¼‰
        if 'expenditure_info_json' in self.df.columns:
            expenditure_analysis = self.analyze_expenditure_json()
            json_insights['expenditure'] = expenditure_analysis
        
        # ç›®æ¨™æƒ…å ±ã®åˆ†æï¼ˆgoals_performance_jsonï¼‰
        if 'goals_performance_json' in self.df.columns:
            goals_analysis = self.analyze_goals_json()
            json_insights['goals'] = goals_analysis
        
        self.analysis_results['json_data_analysis'] = json_insights
        return json_insights
    
    def analyze_budget_json(self):
        """äºˆç®—JSONãƒ‡ãƒ¼ã‚¿ã®åˆ†æ"""
        print("\näºˆç®—æƒ…å ±åˆ†æ:")
        
        budget_data = []
        budget_amounts = []
        
        for idx, json_str in enumerate(self.df['budget_summary_json'].dropna()):
            try:
                if json_str and json_str != 'null':
                    records = json.loads(json_str)
                    if isinstance(records, list):
                        for record in records:
                            if isinstance(record, dict):
                                # äºˆç®—é¡ã®æŠ½å‡ºã‚’è©¦è¡Œ
                                for key, value in record.items():
                                    if any(budget_key in key for budget_key in ['äºˆç®—', 'é‡‘é¡', 'é¡']):
                                        if isinstance(value, (int, float)):
                                            budget_amounts.append(value)
                                        elif isinstance(value, str):
                                            # æ•°å€¤ã®æŠ½å‡ºã‚’è©¦è¡Œ
                                            import re
                                            numbers = re.findall(r'[\d,]+', str(value).replace(',', ''))
                                            for num_str in numbers:
                                                try:
                                                    budget_amounts.append(float(num_str))
                                                except:
                                                    pass
                        budget_data.append(len(records))
            except:
                continue
        
        analysis = {
            'projects_with_budget_data': len(budget_data),
            'avg_budget_records_per_project': np.mean(budget_data) if budget_data else 0,
            'budget_amounts_found': len(budget_amounts),
            'budget_stats': {}
        }
        
        if budget_amounts:
            # ç•°å¸¸ã«å¤§ããªå€¤ã‚’é™¤å¤–ï¼ˆä¸Šä½1%ã‚’é™¤å»ï¼‰
            budget_amounts = np.array(budget_amounts)
            budget_amounts = budget_amounts[budget_amounts <= np.percentile(budget_amounts, 99)]
            
            if len(budget_amounts) > 0:
                analysis['budget_stats'] = {
                    'mean': np.mean(budget_amounts),
                    'median': np.median(budget_amounts),
                    'std': np.std(budget_amounts),
                    'min': np.min(budget_amounts),
                    'max': np.max(budget_amounts),
                    'count': len(budget_amounts)
                }
        
        print(f"  - äºˆç®—ãƒ‡ãƒ¼ã‚¿æœ‰ã‚Šäº‹æ¥­: {analysis['projects_with_budget_data']:,}")
        print(f"  - å¹³å‡äºˆç®—ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°: {analysis['avg_budget_records_per_project']:.1f}")
        print(f"  - æŠ½å‡ºã•ã‚ŒãŸäºˆç®—é¡æ•°: {analysis['budget_amounts_found']:,}")
        
        if analysis['budget_stats']:
            stats = analysis['budget_stats']
            print(f"  - äºˆç®—é¡çµ±è¨ˆ (n={stats['count']:,}):")
            print(f"    å¹³å‡: {stats['mean']:,.0f}")
            print(f"    ä¸­å¤®å€¤: {stats['median']:,.0f}")
            print(f"    æœ€å¤§: {stats['max']:,.0f}")
            print(f"    æœ€å°: {stats['min']:,.0f}")
        
        return analysis
    
    def analyze_expenditure_json(self):
        """æ”¯å‡ºJSONãƒ‡ãƒ¼ã‚¿ã®åˆ†æ"""
        print("\næ”¯å‡ºæƒ…å ±åˆ†æ:")
        
        expenditure_entities = []
        expenditure_amounts = []
        
        for idx, json_str in enumerate(self.df['expenditure_info_json'].dropna()):
            try:
                if json_str and json_str != 'null':
                    records = json.loads(json_str)
                    if isinstance(records, list):
                        unique_entities = set()
                        for record in records:
                            if isinstance(record, dict):
                                # æ”¯å‡ºå…ˆåã®æŠ½å‡º
                                if 'æ”¯å‡ºå…ˆå' in record and record['æ”¯å‡ºå…ˆå']:
                                    unique_entities.add(record['æ”¯å‡ºå…ˆå'])
                                
                                # é‡‘é¡ã®æŠ½å‡º
                                for key, value in record.items():
                                    if 'é‡‘é¡' in key or 'é¡' in key:
                                        if isinstance(value, (int, float)):
                                            expenditure_amounts.append(value)
                        
                        expenditure_entities.append(len(unique_entities))
            except:
                continue
        
        analysis = {
            'projects_with_expenditure_data': len(expenditure_entities),
            'avg_expenditure_entities_per_project': np.mean(expenditure_entities) if expenditure_entities else 0,
            'expenditure_amounts_found': len(expenditure_amounts),
            'expenditure_diversity_stats': {}
        }
        
        if expenditure_entities:
            analysis['expenditure_diversity_stats'] = {
                'mean': np.mean(expenditure_entities),
                'median': np.median(expenditure_entities),
                'max': np.max(expenditure_entities),
                'min': np.min(expenditure_entities),
                'std': np.std(expenditure_entities)
            }
        
        print(f"  - æ”¯å‡ºãƒ‡ãƒ¼ã‚¿æœ‰ã‚Šäº‹æ¥­: {analysis['projects_with_expenditure_data']:,}")
        print(f"  - å¹³å‡æ”¯å‡ºå…ˆæ•°/äº‹æ¥­: {analysis['avg_expenditure_entities_per_project']:.1f}")
        
        if analysis['expenditure_diversity_stats']:
            stats = analysis['expenditure_diversity_stats']
            print(f"  - æ”¯å‡ºå…ˆå¤šæ§˜æ€§çµ±è¨ˆ:")
            print(f"    å¹³å‡æ”¯å‡ºå…ˆæ•°: {stats['mean']:.1f}")
            print(f"    æœ€å¤§æ”¯å‡ºå…ˆæ•°: {stats['max']}")
            print(f"    æ¨™æº–åå·®: {stats['std']:.1f}")
        
        return analysis
    
    def analyze_goals_json(self):
        """ç›®æ¨™JSONãƒ‡ãƒ¼ã‚¿ã®åˆ†æ"""
        print("\nç›®æ¨™ãƒ»å®Ÿç¸¾åˆ†æ:")
        
        goals_counts = []
        performance_data = []
        
        for idx, json_str in enumerate(self.df['goals_performance_json'].dropna()):
            try:
                if json_str and json_str != 'null':
                    records = json.loads(json_str)
                    if isinstance(records, list):
                        goals_counts.append(len(records))
                        
                        for record in records:
                            if isinstance(record, dict):
                                # ç›®æ¨™ãƒ»å®Ÿç¸¾ãƒ‡ãƒ¼ã‚¿ã®æŠ½å‡º
                                for key, value in record.items():
                                    if any(goal_key in key for goal_key in ['ç›®æ¨™', 'å®Ÿç¸¾', 'é”æˆç‡']):
                                        performance_data.append(key)
            except:
                continue
        
        analysis = {
            'projects_with_goals_data': len(goals_counts),
            'avg_goals_per_project': np.mean(goals_counts) if goals_counts else 0,
            'goals_stats': {},
            'performance_fields_found': len(performance_data)
        }
        
        if goals_counts:
            analysis['goals_stats'] = {
                'mean': np.mean(goals_counts),
                'median': np.median(goals_counts),
                'max': np.max(goals_counts),
                'min': np.min(goals_counts),
                'std': np.std(goals_counts)
            }
        
        print(f"  - ç›®æ¨™ãƒ‡ãƒ¼ã‚¿æœ‰ã‚Šäº‹æ¥­: {analysis['projects_with_goals_data']:,}")
        print(f"  - å¹³å‡ç›®æ¨™æ•°/äº‹æ¥­: {analysis['avg_goals_per_project']:.1f}")
        print(f"  - å®Ÿç¸¾ãƒ•ã‚£ãƒ¼ãƒ«ãƒ‰ç™ºè¦‹æ•°: {analysis['performance_fields_found']:,}")
        
        if analysis['goals_stats']:
            stats = analysis['goals_stats']
            print(f"  - ç›®æ¨™è¨­å®šçµ±è¨ˆ:")
            print(f"    æœ€å¤§ç›®æ¨™æ•°: {stats['max']}")
            print(f"    å¹³å‡ç›®æ¨™æ•°: {stats['mean']:.1f}")
        
        return analysis
    
    def outlier_detection(self):
        """ç•°å¸¸å€¤æ¤œå‡ºãƒ»ç‰¹æ®Šäº‹æ¥­ã®æŠ½å‡º"""
        print("\n" + "="*80)
        print("ç•°å¸¸å€¤æ¤œå‡ºãƒ»ç‰¹æ®Šäº‹æ¥­åˆ†æ")
        print("="*80)
        
        outliers = {}
        
        # ãƒ‡ãƒ¼ã‚¿å¯†åº¦ã®ç•°å¸¸å€¤
        if 'total_related_records' in self.df.columns:
            total_records = self.df['total_related_records']
            q95 = total_records.quantile(0.95)
            q99 = total_records.quantile(0.99)
            
            high_density_projects = self.df[total_records >= q95]
            ultra_high_density = self.df[total_records >= q99]
            
            outliers['high_data_density'] = {
                'q95_threshold': q95,
                'q99_threshold': q99,
                'high_density_count': len(high_density_projects),
                'ultra_high_density_count': len(ultra_high_density),
                'top_projects': high_density_projects.nlargest(5, 'total_related_records')[
                    ['äº‹æ¥­å', 'åºœçœåº', 'total_related_records']].to_dict('records')
            }
            
            print(f"é«˜ãƒ‡ãƒ¼ã‚¿å¯†åº¦äº‹æ¥­:")
            print(f"  - 95ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«ä»¥ä¸Š: {len(high_density_projects)}äº‹æ¥­ (é–¾å€¤: {q95:.0f})")
            print(f"  - 99ãƒ‘ãƒ¼ã‚»ãƒ³ã‚¿ã‚¤ãƒ«ä»¥ä¸Š: {len(ultra_high_density)}äº‹æ¥­ (é–¾å€¤: {q99:.0f})")
            print(f"  ãƒ‡ãƒ¼ã‚¿å¯†åº¦ãƒˆãƒƒãƒ—5:")
            for i, project in enumerate(outliers['high_data_density']['top_projects'], 1):
                print(f"    {i}. {project['äº‹æ¥­å'][:50]}... ({project['åºœçœåº']}) - {project['total_related_records']}ãƒ¬ã‚³ãƒ¼ãƒ‰")
        
        # å„ãƒ†ãƒ¼ãƒ–ãƒ«åˆ¥ç•°å¸¸å€¤
        for col in self.count_cols:
            if col in self.df.columns:
                table_name = col.replace('_count', '')
                values = self.df[col]
                q95 = values.quantile(0.95)
                
                if q95 > 0:
                    high_count_projects = self.df[values >= q95]
                    outliers[f'{table_name}_high_count'] = {
                        'threshold': q95,
                        'count': len(high_count_projects),
                        'top_projects': high_count_projects.nlargest(3, col)[
                            ['äº‹æ¥­å', 'åºœçœåº', col]].to_dict('records')
                    }
        
        self.analysis_results['outlier_detection'] = outliers
        
        # InsightæŠ½å‡º
        if 'high_data_density' in outliers:
            top_project = outliers['high_data_density']['top_projects'][0]
            self.insights.append(f"æœ€é«˜ãƒ‡ãƒ¼ã‚¿å¯†åº¦äº‹æ¥­: ã€Œ{top_project['äº‹æ¥­å'][:30]}...ã€({top_project['total_related_records']}ãƒ¬ã‚³ãƒ¼ãƒ‰)")
        
        return outliers
    
    def correlation_analysis(self):
        """ç›¸é–¢ãƒ»ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ"""
        print("\n" + "="*80)
        print("ç›¸é–¢ãƒ»ãƒ‘ã‚¿ãƒ¼ãƒ³åˆ†æ")
        print("="*80)
        
        correlations = {}
        
        # æ•°å€¤åˆ—ã®æŠ½å‡º
        numeric_cols = []
        for col in self.count_cols + ['total_related_records']:
            if col in self.df.columns:
                numeric_cols.append(col)
        
        if len(numeric_cols) >= 2:
            # ç›¸é–¢è¡Œåˆ—ã®è¨ˆç®—
            corr_matrix = self.df[numeric_cols].corr()
            
            # é«˜ç›¸é–¢ãƒšã‚¢ã®æŠ½å‡º
            high_correlations = []
            for i in range(len(corr_matrix.columns)):
                for j in range(i+1, len(corr_matrix.columns)):
                    corr_value = corr_matrix.iloc[i, j]
                    if abs(corr_value) > 0.5:  # ç›¸é–¢ä¿‚æ•°ã®é–¾å€¤
                        high_correlations.append({
                            'var1': corr_matrix.columns[i],
                            'var2': corr_matrix.columns[j],
                            'correlation': corr_value
                        })
            
            correlations['correlation_matrix'] = corr_matrix.to_dict()
            correlations['high_correlations'] = high_correlations
            
            print(f"é«˜ç›¸é–¢ãƒšã‚¢ (|r| > 0.5):")
            for corr in sorted(high_correlations, key=lambda x: abs(x['correlation']), reverse=True):
                var1_name = corr['var1'].replace('_count', '').replace('_', ' ')
                var2_name = corr['var2'].replace('_count', '').replace('_', ' ')
                print(f"  {var1_name} âŸ· {var2_name}: r = {corr['correlation']:.3f}")
        
        # åºœçœåºã¨ãƒ‡ãƒ¼ã‚¿å¯†åº¦ã®é–¢ä¿‚
        if 'åºœçœåº' in self.df.columns and 'total_related_records' in self.df.columns:
            ministry_density = self.df.groupby('åºœçœåº')['total_related_records'].agg(['mean', 'std', 'count']).round(2)
            ministry_density = ministry_density[ministry_density['count'] >= 10].sort_values('mean', ascending=False)
            
            correlations['ministry_data_density'] = ministry_density.head(10).to_dict()
            
            print(f"\nåºœçœåºåˆ¥ãƒ‡ãƒ¼ã‚¿å¯†åº¦ (10äº‹æ¥­ä»¥ä¸Š):")
            for ministry, stats in ministry_density.head(10).iterrows():
                print(f"  {ministry}: å¹³å‡{stats['mean']:.1f}ãƒ¬ã‚³ãƒ¼ãƒ‰ (Ïƒ={stats['std']:.1f}, n={stats['count']})")
        
        self.analysis_results['correlation_analysis'] = correlations
        
        # InsightæŠ½å‡º
        if high_correlations:
            strongest = max(high_correlations, key=lambda x: abs(x['correlation']))
            self.insights.append(f"æœ€å¼·ã®ç›¸é–¢: {strongest['var1']} ã¨ {strongest['var2']} (r={strongest['correlation']:.3f})")
        
        return correlations
    
    def generate_insights_summary(self):
        """Insightç·æ‹¬"""
        print("\n" + "="*80)
        print("ğŸ” ç™ºè¦‹ã•ã‚ŒãŸInsight")
        print("="*80)
        
        for i, insight in enumerate(self.insights, 1):
            print(f"{i:2d}. {insight}")
        
        # è¿½åŠ çš„ãªInsightç”Ÿæˆ
        additional_insights = []
        
        # ãƒ‡ãƒ¼ã‚¿å®Œå…¨æ€§ã«é–¢ã™ã‚‹Insight
        if 'basic_statistics' in self.analysis_results:
            completeness = self.analysis_results['basic_statistics']['data_completeness']
            if completeness > 90:
                additional_insights.append(f"é«˜ã„ãƒ‡ãƒ¼ã‚¿å®Œå…¨æ€§ã‚’å®Ÿç¾({completeness:.1f}%)")
            elif completeness < 70:
                additional_insights.append(f"ãƒ‡ãƒ¼ã‚¿æ¬ æãŒå¤šã„çŠ¶æ³({completeness:.1f}%)")
        
        # è¦æ¨¡ã«é–¢ã™ã‚‹Insight
        if 'ministry_analysis' in self.analysis_results:
            total_ministries = self.analysis_results['ministry_analysis']['total_ministries']
            if total_ministries > 20:
                additional_insights.append(f"å¤šæ•°ã®åºœçœåºãŒå‚ç”»({total_ministries}åºœçœåº)")
        
        # JSONæ´»ç”¨ã«é–¢ã™ã‚‹Insight
        if 'json_data_analysis' in self.analysis_results:
            json_analysis = self.analysis_results['json_data_analysis']
            if 'budget' in json_analysis and json_analysis['budget']['projects_with_budget_data'] > 1000:
                additional_insights.append("äºˆç®—è©³ç´°ãƒ‡ãƒ¼ã‚¿ã®å……å®Ÿåº¦ãŒé«˜ã„")
        
        # è¿½åŠ Insightã®è¡¨ç¤º
        if additional_insights:
            print("\nè¿½åŠ ç™ºè¦‹:")
            for i, insight in enumerate(additional_insights, len(self.insights) + 1):
                print(f"{i:2d}. {insight}")
        
        self.insights.extend(additional_insights)
        
        return self.insights
    
    def save_results(self):
        """çµæœä¿å­˜"""
        print("\n" + "="*80)
        print("çµæœä¿å­˜")
        print("="*80)
        
        # JSONçµæœä¿å­˜
        results_path = self.output_dir / "descriptive_analysis_results.json"
        with open(results_path, 'w', encoding='utf-8') as f:
            json.dump(self.analysis_results, f, ensure_ascii=False, indent=2, default=str)
        print(f"âœ“ åˆ†æçµæœä¿å­˜: {results_path}")
        
        # Insightä¿å­˜
        insights_path = self.output_dir / "key_insights.txt"
        with open(insights_path, 'w', encoding='utf-8') as f:
            f.write("äº‹æ¥­ãƒã‚¹ã‚¿ãƒ¼ãƒªã‚¹ãƒˆåˆ†æ - ä¸»è¦Insight\n")
            f.write("="*50 + "\n\n")
            for i, insight in enumerate(self.insights, 1):
                f.write(f"{i:2d}. {insight}\n")
        print(f"âœ“ Insightä¿å­˜: {insights_path}")
        
        # HTMLãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ
        self.generate_html_report()
        
        return True
    
    def generate_html_report(self):
        """HTMLãƒ¬ãƒãƒ¼ãƒˆç”Ÿæˆ"""
        html_content = f"""<!DOCTYPE html>
<html lang="ja">
<head>
    <meta charset="UTF-8">
    <title>äº‹æ¥­ãƒã‚¹ã‚¿ãƒ¼ãƒªã‚¹ãƒˆè¨˜è¿°çµ±è¨ˆåˆ†æãƒ¬ãƒãƒ¼ãƒˆ</title>
    <style>
        body {{ font-family: 'Segoe UI', Arial, sans-serif; margin: 20px; background: #f9fafb; color: #111827; }}
        .container {{ max-width: 1200px; margin: 0 auto; background: #ffffff; padding: 30px; border-radius: 10px; box-shadow: 0 4px 6px rgba(0,0,0,0.1); }}
        h1 {{ color: #1f2937; text-align: center; border-bottom: 3px solid #3b82f6; padding-bottom: 15px; }}
        h2 {{ color: #1f2937; margin-top: 30px; border-left: 5px solid #3b82f6; padding-left: 10px; }}
        .summary {{ background: #3b82f6; color: white; padding: 20px; border-radius: 8px; margin: 20px 0; }}
        .metric {{ display: inline-block; margin: 10px 20px; }}
        .metric-value {{ font-size: 2em; font-weight: bold; }}
        .metric-label {{ font-size: 0.9em; opacity: 0.9; }}
        table {{ width: 100%; border-collapse: collapse; margin: 20px 0; }}
        th {{ background: #f3f4f6; color: #1f2937; padding: 12px; text-align: left; border-bottom: 2px solid #e5e7eb; }}
        td {{ padding: 10px; border-bottom: 1px solid #e5e7eb; color: #374151; }}
        tr:hover {{ background: #f9fafb; }}
        .insight {{ background: #eff6ff; border-left: 4px solid #3b82f6; padding: 15px; margin: 10px 0; color: #1e40af; }}
        .code {{ background: #f3f4f6; padding: 10px; border-radius: 5px; font-family: monospace; color: #111827; }}
        .chart-placeholder {{ background: #f3f4f6; padding: 40px; text-align: center; border: 2px dashed #d1d5db; margin: 20px 0; }}
    </style>
</head>
<body>
    <div class="container">
        <h1>ğŸ“Š äº‹æ¥­ãƒã‚¹ã‚¿ãƒ¼ãƒªã‚¹ãƒˆè¨˜è¿°çµ±è¨ˆåˆ†æãƒ¬ãƒãƒ¼ãƒˆ</h1>
        
        <div class="summary">
            <h2 style="color: white; margin-top: 0;">åˆ†ææ¦‚è¦</h2>
"""
        
        # åŸºæœ¬çµ±è¨ˆã®è¡¨ç¤º
        if 'basic_statistics' in self.analysis_results:
            stats = self.analysis_results['basic_statistics']
            html_content += f"""
            <div class="metric">
                <div class="metric-value">{stats['total_projects']:,}</div>
                <div class="metric-label">ç·äº‹æ¥­æ•°</div>
            </div>
            <div class="metric">
                <div class="metric-value">{stats['total_columns']}</div>
                <div class="metric-label">ç·åˆ—æ•°</div>
            </div>
            <div class="metric">
                <div class="metric-value">{stats['data_completeness']:.1f}%</div>
                <div class="metric-label">ãƒ‡ãƒ¼ã‚¿å®Œå…¨æ€§</div>
            </div>
"""
        
        html_content += """
        </div>
        
        <h2>ğŸ¯ ä¸»è¦Insight</h2>
"""
        
        # Insightè¡¨ç¤º
        for i, insight in enumerate(self.insights, 1):
            html_content += f'        <div class="insight">{i}. {insight}</div>\n'
        
        # åºœçœåºåˆ†æ
        if 'ministry_analysis' in self.analysis_results:
            ministry_data = self.analysis_results['ministry_analysis']
            html_content += """
        <h2>ğŸ›ï¸ åºœçœåºåˆ†æ</h2>
        <table>
            <tr>
                <th>é †ä½</th>
                <th>åºœçœåº</th>
                <th>äº‹æ¥­æ•°</th>
                <th>å‰²åˆ</th>
            </tr>
"""
            for i, (ministry, count) in enumerate(ministry_data['top_10_ministries'].items(), 1):
                percentage = (count / ministry_data.get('total_ministries', 1)) * 100
                html_content += f"""
            <tr>
                <td>{i}</td>
                <td>{ministry}</td>
                <td>{count:,}</td>
                <td>{percentage:.1f}%</td>
            </tr>
"""
            html_content += "        </table>"
        
        # ãƒ‡ãƒ¼ã‚¿å¯†åº¦åˆ†æ
        if 'data_density_analysis' in self.analysis_results:
            density_data = self.analysis_results['data_density_analysis']
            html_content += """
        <h2>ğŸ“ˆ ãƒ‡ãƒ¼ã‚¿å¯†åº¦åˆ†æ</h2>
        <table>
            <tr>
                <th>ãƒ†ãƒ¼ãƒ–ãƒ«å</th>
                <th>ãƒ‡ãƒ¼ã‚¿ä¿æœ‰ç‡</th>
                <th>å¹³å‡ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°/äº‹æ¥­</th>
                <th>æœ€å¤§ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°</th>
            </tr>
"""
            for table_name, stats in density_data['data_availability'].items():
                html_content += f"""
            <tr>
                <td>{table_name}</td>
                <td>{stats['coverage_rate']:.1f}%</td>
                <td>{stats['avg_records_per_project']:.1f}</td>
                <td>{stats['max_records']}</td>
            </tr>
"""
            html_content += "        </table>"
        
        # ç•°å¸¸å€¤æƒ…å ±
        if 'outlier_detection' in self.analysis_results and 'high_data_density' in self.analysis_results['outlier_detection']:
            outlier_data = self.analysis_results['outlier_detection']['high_data_density']
            html_content += """
        <h2>âš¡ ç‰¹æ®Šäº‹æ¥­ï¼ˆé«˜ãƒ‡ãƒ¼ã‚¿å¯†åº¦ï¼‰</h2>
        <table>
            <tr>
                <th>äº‹æ¥­å</th>
                <th>åºœçœåº</th>
                <th>é–¢é€£ãƒ¬ã‚³ãƒ¼ãƒ‰æ•°</th>
            </tr>
"""
            for project in outlier_data['top_projects']:
                html_content += f"""
            <tr>
                <td>{project['äº‹æ¥­å'][:60]}...</td>
                <td>{project['åºœçœåº']}</td>
                <td>{project['total_related_records']:,}</td>
            </tr>
"""
            html_content += "        </table>"
        
        html_content += """
        <div style="text-align: center; margin-top: 40px; color: #7f8c8d; font-size: 0.9em;">
            äº‹æ¥­ãƒã‚¹ã‚¿ãƒ¼ãƒªã‚¹ãƒˆè¨˜è¿°çµ±è¨ˆåˆ†æãƒ¬ãƒãƒ¼ãƒˆ - RS Visualization System
        </div>
    </div>
</body>
</html>
"""
        
        report_path = self.output_dir / "descriptive_analysis_report.html"
        with open(report_path, 'w', encoding='utf-8') as f:
            f.write(html_content)
        print(f"âœ“ HTMLãƒ¬ãƒãƒ¼ãƒˆä¿å­˜: {report_path}")
    
    def run_analysis(self):
        """åˆ†æå®Ÿè¡Œãƒ¡ã‚¤ãƒ³"""
        print("\n" + "="*80)
        print("äº‹æ¥­ãƒã‚¹ã‚¿ãƒ¼ãƒªã‚¹ãƒˆè¨˜è¿°çµ±è¨ˆåˆ†æé–‹å§‹")
        print("="*80)
        print("ç›®æ¨™: 5,664äº‹æ¥­Ã—95åˆ—ã‹ã‚‰ã®InsightæŠ½å‡º")
        
        try:
            # 1. ãƒ‡ãƒ¼ã‚¿èª­ã¿è¾¼ã¿
            if not self.load_data():
                return False
            
            # 2. åŸºæœ¬çµ±è¨ˆ
            self.basic_statistics()
            
            # 3. åˆ†å¸ƒåˆ†æ
            self.ministry_analysis()
            self.project_category_analysis()
            self.temporal_analysis()
            self.implementation_method_analysis()
            
            # 4. ãƒ‡ãƒ¼ã‚¿å¯†åº¦åˆ†æ
            self.data_density_analysis()
            
            # 5. JSONè©³ç´°ãƒ‡ãƒ¼ã‚¿åˆ†æ
            self.json_data_analysis()
            
            # 6. ç•°å¸¸å€¤æ¤œå‡º
            self.outlier_detection()
            
            # 7. ç›¸é–¢åˆ†æ
            self.correlation_analysis()
            
            # 8. Insightç·æ‹¬
            self.generate_insights_summary()
            
            # 9. çµæœä¿å­˜
            self.save_results()
            
            print("\n" + "="*80)
            print("âœ… è¨˜è¿°çµ±è¨ˆåˆ†æå®Œäº†ï¼")
            print("="*80)
            print(f"ğŸ“Š {len(self.insights)}å€‹ã®Insightã‚’ç™ºè¦‹")
            print(f"ğŸ“ çµæœä¿å­˜å…ˆ: {self.output_dir}/")
            print("  - descriptive_analysis_results.json")
            print("  - descriptive_analysis_report.html")
            print("  - key_insights.txt")
            
            return True
            
        except Exception as e:
            print(f"\nâŒ åˆ†æã‚¨ãƒ©ãƒ¼: {e}")
            import traceback
            traceback.print_exc()
            return False


def main():
    analyzer = ProjectMasterAnalyzer()
    analyzer.run_analysis()


if __name__ == "__main__":
    main()
